{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from experiments.dataset_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All_Beauty': 0,\n",
       " 'Toys_and_Games': 1,\n",
       " 'Cell_Phones_and_Accessories': 2,\n",
       " 'Industrial_and_Scientific': 3,\n",
       " 'Gift_Cards': 4,\n",
       " 'Musical_Instruments': 5,\n",
       " 'Electronics': 6,\n",
       " 'Handmade_Products': 7,\n",
       " 'Arts_Crafts_and_Sewing': 8,\n",
       " 'Baby_Products': 9,\n",
       " 'Health_and_Household': 10,\n",
       " 'Office_Products': 11,\n",
       " 'Digital_Music': 12,\n",
       " 'Grocery_and_Gourmet_Food': 13,\n",
       " 'Sports_and_Outdoors': 14,\n",
       " 'Home_and_Kitchen': 15,\n",
       " 'Subscription_Boxes': 16,\n",
       " 'Tools_and_Home_Improvement': 17,\n",
       " 'Pet_Supplies': 18,\n",
       " 'Video_Games': 19,\n",
       " 'Kindle_Store': 20,\n",
       " 'Clothing_Shoes_and_Jewelry': 21,\n",
       " 'Patio_Lawn_and_Garden': 22,\n",
       " 'Unknown': 23,\n",
       " 'Books': 24,\n",
       " 'Automotive': 25,\n",
       " 'CDs_and_Vinyl': 26,\n",
       " 'Beauty_and_Personal_Care': 27,\n",
       " 'Amazon_Fashion': 28,\n",
       " 'Magazine_Subscriptions': 29,\n",
       " 'Software': 30,\n",
       " 'Health_and_Personal_Care': 31,\n",
       " 'Appliances': 32,\n",
       " 'Movies_and_TV': 33}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect different datasets within amazon_reviews\n",
    "# dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_All_Beauty\", trust_remote_code=True)\n",
    "# dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\n",
    "# dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"0core_rating_only_All_Beauty\", trust_remote_code=True)\n",
    "# dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"0core_last_out_All_Beauty\", trust_remote_code=True)\n",
    "# dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"0core_timestamp_w_his_All_Beauty\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_beauty = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True, streaming=True)\n",
    "ds_beauty = iter(dataset_beauty[\"full\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': 5.0,\n",
       " 'title': 'Such a lovely scent but not overpowering.',\n",
       " 'text': \"This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want. I have a lot of hair, medium thickness. I am comparing to other brands with yucky chemicals so I'm gonna stick with this. Try it!\",\n",
       " 'images': [],\n",
       " 'asin': 'B00YQ6X8EO',\n",
       " 'parent_asin': 'B00YQ6X8EO',\n",
       " 'user_id': 'AGKHLEW2SOWHNMFQIJGBECAF7INQ',\n",
       " 'timestamp': 1588687728923,\n",
       " 'helpful_vote': 0,\n",
       " 'verified_purchase': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ds_beauty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_electronics = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", trust_remote_code=True, streaming=True)\n",
    "ds_electronics = iter(dataset_electronics[\"full\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': 3.0,\n",
       " 'title': 'Smells like gasoline! Going back!',\n",
       " 'text': 'First & most offensive: they reek of gasoline so if you are sensitive/allergic to petroleum products like I am you will want to pass on these.  Second: the phone adapter is useless as-is. Mine was not drilled far enough to be able to tighten it into place for my iPhone 12 max. It just slipped & slid all over. Stupid me putting the adapter together first without picking up the binoculars to smell them bc I wasted 15 minutes trying to figure out how to put the adapter together bc it does not come with instructions!  I had to come back here to the website which was a total pain. Third: the tripod is also useless. I would not trust the iOS to hold my $1600 phone nor even a Mattel Barbie for that matter. It’s just inefficient for the job imo.  Third: in order to try to give an honest review I did don gloves & eyewear to check the binoculars out.  They seemed average except for mine seemed to be missing about 10% of the film costing in the lower edge of one of the lenses which would have ruined every video & photograph unplanned to take so for me these are a very huge hard pass.  I expect the accessories that come with the main product to be as good or better than the product I’m buying. Otherwise I would just buy the product as a stand alone.  Sadly, I found a decent pair of binoculars last year with a much better quality phone adapter & tripod, but they had a defect too.  Guess I’m going to have to pay more.  Ugh.',\n",
       " 'images': [{'small_image_url': 'https://m.media-amazon.com/images/I/71YN+Qk3kCL._SL256_.jpg',\n",
       "   'medium_image_url': 'https://m.media-amazon.com/images/I/71YN+Qk3kCL._SL800_.jpg',\n",
       "   'large_image_url': 'https://m.media-amazon.com/images/I/71YN+Qk3kCL._SL1600_.jpg',\n",
       "   'attachment_type': 'IMAGE'}],\n",
       " 'asin': 'B083NRGZMM',\n",
       " 'parent_asin': 'B083NRGZMM',\n",
       " 'user_id': 'AFKZENTNBQ7A7V7UXW5JJI6UGRYQ',\n",
       " 'timestamp': 1658185117948,\n",
       " 'helpful_vote': 0,\n",
       " 'verified_purchase': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ds_electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_electronics = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", trust_remote_code=True, streaming=True)\n",
    "\n",
    "\n",
    "# Load balanced dataset of 10_000 samples for each 0.0 / 5.0 rating vs All_beauty / Electronics\n",
    "# three columns per sample: f'Title: {title}\\nReview: {review}'[:1000], rating, category\n",
    "\n",
    "# write code using dataset.select()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing electronics dataset...\n",
      "Processing beauty dataset...\n",
      "100000 40000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "\n",
    "def process_sample(sample, category):\n",
    "    return {\n",
    "        'text': f'Title: {sample[\"title\"]}\\nReview: {sample[\"text\"]}'[:1000],\n",
    "        'rating': sample['rating'],\n",
    "        'category': category,\n",
    "    }\n",
    "\n",
    "def filter_and_sample(dataset, ratings, category, n_samples):\n",
    "    rating_counter = {rating: 0 for rating in ratings}\n",
    "    samples_dict = defaultdict(list)\n",
    "    for sample in dataset:\n",
    "        # print(rating_counter)\n",
    "        r = sample['rating'] \n",
    "        if r in rating_counter:\n",
    "            samples_dict[r].append(process_sample(sample, category))\n",
    "            rating_counter[r] += 1\n",
    "            if rating_counter[r] >= n_samples:\n",
    "                rating_counter.pop(r) # desired number of samples reached\n",
    "        if len(rating_counter) == 0:\n",
    "            break\n",
    "    return samples_dict\n",
    "\n",
    "def split_samples_dict(samples_dict, n_train_samples_per_rating, n_test_samples_per_rating):\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    for samples in samples_dict.values():\n",
    "        train_samples.extend(samples[:n_train_samples_per_rating])\n",
    "        test_samples.extend(samples[n_train_samples_per_rating:n_train_samples_per_rating+n_test_samples_per_rating])\n",
    "    return train_samples, test_samples # contains multiple rating_scores\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "dataset_electronics = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", trust_remote_code=True, streaming=True)\n",
    "dataset_beauty = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True, streaming=True)\n",
    "dataset_dict = {\n",
    "    'electronics': dataset_electronics['full'],\n",
    "    'beauty': dataset_beauty['full'],\n",
    "}\n",
    "ratings = (1.0, 5.0) # There's no 0 star rating in the dataset\n",
    "n_train_samples_per_rating = 25000\n",
    "n_test_samples_per_rating = 10000\n",
    "n_total_samples_per_rating = n_train_samples_per_rating + n_test_samples_per_rating\n",
    "\n",
    "train_samples = []\n",
    "test_samples = []\n",
    "for category, dataset in dataset_dict.items():\n",
    "    print(f\"Processing {category} dataset...\")\n",
    "    samples_dict = filter_and_sample(dataset, ratings, category, n_total_samples_per_rating)\n",
    "    train_samples_category, test_samples_category = split_samples_dict(samples_dict, n_train_samples_per_rating, n_test_samples_per_rating)\n",
    "    train_samples.extend(train_samples_category)\n",
    "    test_samples.extend(test_samples_category)\n",
    "\n",
    "balanced_dataset = DatasetDict({\n",
    "    'train': Dataset.from_list(train_samples),\n",
    "    'test': Dataset.from_list(test_samples),\n",
    "})\n",
    "\n",
    "print(len(balanced_dataset['train']), len(balanced_dataset['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5a87d011974db69b9d07f2d76a2356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1829a45f986f4d73933b3a6479b256d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee06268f44d84768811a39dee21dce52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916271b9d2924f2382b5a196971b0266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/40 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/canrager/amazon_reviews_mcauley/commit/7686472154fe779356485f175567c4de1268bdde', commit_message='Upload dataset', commit_description='', oid='7686472154fe779356485f175567c4de1268bdde', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to huggingface\n",
    "\n",
    "# ratings_part = \"_\".join(str(rating) for rating in ratings)\n",
    "# categories_part = \"_\".join(dataset_dict.keys())\n",
    "\n",
    "# fname = f\"dataset_{ratings_part}_{categories_part}_{n_total_samples_per_rating}\"\n",
    "\n",
    "# balanced_dataset.push_to_hub(repo_id = f\"canrager/amazon_reviews_mcauley\", data_dir=f\"{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect how bib is formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.probe_training import load_and_prepare_dataset\n",
    "\n",
    "\n",
    "bib_train_df, bib_test_df = load_and_prepare_dataset('bias_in_bios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hard_text</th>\n",
       "      <th>profession</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He specializes in development economics, house...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He started out as a DJ and music producer in t...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She is averse to all things scary or sad, so s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prior to joining USC, she was a mobile news ed...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Previously, she served as an assistant profess...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           hard_text  profession  gender\n",
       "0  He specializes in development economics, house...          21       0\n",
       "1  He started out as a DJ and music producer in t...           5       0\n",
       "2  She is averse to all things scary or sad, so s...           4       1\n",
       "3  Prior to joining USC, she was a mobile news ed...          21       1\n",
       "4  Previously, she served as an assistant profess...          21       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257478, 99069)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bib_train_df), len(bib_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running stuff with this dataset: replicate test_interventions.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
