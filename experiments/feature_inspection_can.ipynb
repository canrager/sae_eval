{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from bib_intervention import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For select_unique_class_features()\n",
    "T_effects_unique_class = [1e-2, 5e-3, 1e-8]\n",
    "T_max_sideeffect = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and dictionaries\n",
    "DEVICE = \"cuda:0\"\n",
    "# TODO: improve scoping of probe layer int\n",
    "layer = 4  # model layer for attaching linear classification head\n",
    "SEED = 42\n",
    "activation_dim = 512\n",
    "verbose = False\n",
    "select_unique_features = True\n",
    "\n",
    "submodule_trainers = {\n",
    "    \"resid_post_layer_4\": {\"trainer_ids\": [10]},\n",
    "}\n",
    "\n",
    "model_name_lookup = {\"pythia70m\": \"EleutherAI/pythia-70m-deduped\"}\n",
    "dictionaries_path = \"../dictionary_learning/dictionaries\"\n",
    "\n",
    "model_location = \"pythia70m\"\n",
    "sweep_name = \"_sweep0711\"\n",
    "model_name = model_name_lookup[model_location]\n",
    "model = LanguageModel(model_name, device_map=DEVICE, dispatch=True)\n",
    "submodule = utils.get_submodule(model, list(submodule_trainers.keys())[0], layer)\n",
    "\n",
    "probe_train_set_size = 5000\n",
    "probe_test_set_size = 1000\n",
    "probe_act_submodule = utils.get_submodule(model, list(submodule_trainers.keys())[0], layer)\n",
    "probe_layer = class_probing.probe_layer_lookup[model_name]\n",
    "\n",
    "# Load datset and probes\n",
    "train_set_size = 1000\n",
    "test_set_size = 1000\n",
    "probe_batch_size = 500\n",
    "llm_batch_size = 10\n",
    "\n",
    "# Attribution patching variables\n",
    "N_EVAL_BATCHES = 5\n",
    "patching_batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_group_paths = utils.get_ae_group_paths(\n",
    "    dictionaries_path, model_location, sweep_name, submodule_trainers\n",
    ")\n",
    "ae_paths = utils.get_ae_paths(ae_group_paths)\n",
    "\n",
    "context_length = utils.get_ctx_length(ae_paths)\n",
    "\n",
    "dataset, _ = load_and_prepare_dataset()\n",
    "train_bios, test_bios = get_train_test_data(dataset, train_set_size, test_set_size)\n",
    "\n",
    "train_bios = utils.trim_bios_to_context_length(train_bios, context_length)\n",
    "test_bios = utils.trim_bios_to_context_length(test_bios, context_length)\n",
    "\n",
    "probe_path = f\"trained_bib_probes/probes_ctx_len_{context_length}.pt\"\n",
    "\n",
    "if not os.path.exists(probe_path):\n",
    "    print(\"Probes not found, training probes\")\n",
    "    probes = class_probing.train_probes(\n",
    "        train_set_size=probe_train_set_size,\n",
    "        test_set_size=probe_test_set_size,\n",
    "        context_length=context_length,\n",
    "        probe_batch_size=probe_batch_size,\n",
    "        llm_batch_size=llm_batch_size,\n",
    "        device=DEVICE,\n",
    "        llm_model_name=model_name,\n",
    "        epochs=10,\n",
    "    )\n",
    "\n",
    "probes = t.load(probe_path)\n",
    "all_classes_list = list(probes.keys())\n",
    "\n",
    "### Get activations for original model, all classes\n",
    "print(\"Getting activations for original model\")\n",
    "test_acts = {}\n",
    "for class_idx in tqdm(all_classes_list, desc=\"Getting activations per evaluated class\"):\n",
    "    class_test_acts = get_all_activations(test_bios[class_idx], model, submodule, llm_batch_size, probe_layer)\n",
    "    test_acts[class_idx] = class_test_acts\n",
    "\n",
    "test_accuracies = class_probing.get_probe_test_accuracy(\n",
    "    probes, all_classes_list, test_acts, probe_batch_size, verbose, device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get activations for ablated models\n",
    "# ablating the top features for each class\n",
    "print(\"Getting activations for ablated models\")\n",
    "\n",
    "unique_feats = {}\n",
    "\n",
    "for ae_path in ae_paths:\n",
    "    print(f\"Running ablation for {ae_path}\")\n",
    "    submodules = []\n",
    "    dictionaries = {}\n",
    "    submodule, dictionary, config = utils.load_dictionary(model, model_name, ae_path, DEVICE)\n",
    "    submodules.append(submodule)\n",
    "    dictionaries[submodule] = dictionary\n",
    "    dict_size = config[\"trainer\"][\"dict_size\"]\n",
    "    context_length = config[\"buffer\"][\"ctx_len\"]\n",
    "\n",
    "    # ae_name_lookup is useful if we are using attribution patching on multiple submodules\n",
    "    ae_name_lookup = {submodule: ae_path}\n",
    "\n",
    "    node_effects = {}\n",
    "    class_accuracies = test_accuracies.copy()\n",
    "\n",
    "    for ablated_class_idx in all_classes_list:\n",
    "        node_effects[ablated_class_idx] = {}\n",
    "\n",
    "        node_effects[ablated_class_idx] = get_effects_per_class(\n",
    "            model,\n",
    "            submodules,\n",
    "            dictionaries,\n",
    "            probes,\n",
    "            probe_act_submodule,\n",
    "            ablated_class_idx,\n",
    "            train_bios,\n",
    "            N_EVAL_BATCHES,\n",
    "            batch_size=patching_batch_size,\n",
    "            patching_method=\"attrib\",\n",
    "            steps=10,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "\n",
    "    node_effects_cpu = utils.to_device(node_effects, \"cpu\")\n",
    "    # Replace submodule keys with submodule_ae_path\n",
    "    for abl_class_idx in node_effects_cpu.keys():\n",
    "        node_effects_cpu[abl_class_idx] = {\n",
    "            ae_name_lookup[submodule]: effects\n",
    "            for submodule, effects in node_effects_cpu[abl_class_idx].items()\n",
    "        }\n",
    "    with open(ae_path + \"node_effects.pkl\", \"wb\") as f:\n",
    "        pickle.dump(node_effects_cpu, f)\n",
    "    del node_effects_cpu\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    if select_unique_features:\n",
    "        T_effects = T_effects_unique_class\n",
    "        for T_effect in T_effects:\n",
    "            unique_feats[T_effect] = select_unique_class_features(\n",
    "                node_effects,\n",
    "                dict_size,\n",
    "                T_effect=T_effect,\n",
    "                T_max_sideeffect=T_max_sideeffect,\n",
    "                verbose=verbose,\n",
    "                device=DEVICE,\n",
    "            )\n",
    "    else:\n",
    "        T_effects = T_effects_all_classes\n",
    "        for T_effect in T_effects:\n",
    "            unique_feats[T_effect] = select_significant_features(\n",
    "                node_effects, dict_size, T_effect=T_effect, verbose=verbose\n",
    "            )\n",
    "\n",
    "    # for ablated_class_idx in all_classes_list:\n",
    "    #     class_accuracies[ablated_class_idx] = {}\n",
    "    #     print(f\"evaluating class {ablated_class_idx}\")\n",
    "\n",
    "    #     for T_effect in T_effects:\n",
    "    #         feats = unique_feats[T_effect][ablated_class_idx]\n",
    "\n",
    "    #         if len(feats) == 0:\n",
    "    #             print(f\"No features selected for T_effect = {T_effect}\")\n",
    "    #             continue\n",
    "\n",
    "    #         class_accuracies[ablated_class_idx][T_effect] = {}\n",
    "    #         if verbose:\n",
    "    #             print(f\"Running ablation for T_effect = {T_effect}\")\n",
    "    #         test_acts_ablated = {}\n",
    "    #         for evaluated_class_idx in all_classes_list:\n",
    "    #             test_acts_ablated[evaluated_class_idx] = get_all_acts_ablated(\n",
    "    #                 test_bios[evaluated_class_idx],\n",
    "    #                 model,\n",
    "    #                 submodules,\n",
    "    #                 dictionaries,\n",
    "    #                 feats,\n",
    "    #                 llm_batch_size,\n",
    "    #             )\n",
    "\n",
    "    #         for evaluated_class_idx in all_classes_list:\n",
    "    #             batch_test_acts, batch_test_labels = prepare_probe_data(\n",
    "    #                 test_acts_ablated, evaluated_class_idx, probe_batch_size, device=DEVICE\n",
    "    #             )\n",
    "    #             test_acc_probe = test_probe(\n",
    "    #                 batch_test_acts,\n",
    "    #                 batch_test_labels,\n",
    "    #                 probes[evaluated_class_idx],\n",
    "    #                 precomputed_acts=True,\n",
    "    #             )\n",
    "    #             if verbose:\n",
    "    #                 print(\n",
    "    #                     f\"Ablated {ablated_class_idx}, evaluated {evaluated_class_idx} test accuracy: {test_acc_probe}\"\n",
    "    #                 )\n",
    "    #             class_accuracies[ablated_class_idx][T_effect][evaluated_class_idx] = test_acc_probe\n",
    "\n",
    "    #         del test_acts_ablated\n",
    "    #         del batch_test_acts\n",
    "    #         del batch_test_labels\n",
    "    #         t.cuda.empty_cache()\n",
    "    #         gc.collect()\n",
    "\n",
    "    # class_accuracies = utils.to_device(class_accuracies, \"cpu\")\n",
    "    # with open(ae_path + \"class_accuracies.pkl\", \"wb\") as f:\n",
    "    #     pickle.dump(class_accuracies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect that single feature\n",
    "submodule, dictionary, config = utils.load_dictionary(model, model_name, ae_path, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning.interp import examine_dimension\n",
    "from dictionary_learning.utils import hf_dataset_to_generator\n",
    "from dictionary_learning.buffer import ActivationBuffer\n",
    "\n",
    "# interpret some features\n",
    "data = hf_dataset_to_generator(\"monology/pile-uncopyrighted\")\n",
    "buffer = ActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    submodule,\n",
    "    d_submodule=512,\n",
    "    refresh_batch_size=128, # decrease to fit on smaller GPUs\n",
    "    n_ctxs=512, # decrease to fit on smaller GPUs\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load /share/u/can/sae_eval/dictionary_learning/dictionaries/pythia70m_sweep0711/resid_post_layer_4/trainer_10/node_effects.pkl\n",
    "file_name = '/share/u/can/sae_eval/dictionary_learning/dictionaries/pythia70m_sweep0711/resid_post_layer_4/trainer_10/node_effects.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    node_effects = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f't_effect_inscope: {T_effects_unique_class}')\n",
    "print(f't_max_sideeffect: {T_max_sideeffect}')\n",
    "T_effect_inscope = T_effects_unique_class[1]\n",
    "print(f'chosen effect: {T_effect_inscope}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bib_intervention import select_unique_class_features\n",
    "\n",
    "unique_feats= select_unique_class_features(\n",
    "    node_effects,\n",
    "    dict_size,\n",
    "    T_effect=T_effect_inscope,\n",
    "    T_max_sideeffect=T_max_sideeffect,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profession dictionary\n",
    "profession_dict = {\n",
    "    \"accountant\": 0,\n",
    "    \"architect\": 1,\n",
    "    \"attorney\": 2,\n",
    "    \"chiropractor\": 3,\n",
    "    \"comedian\": 4,\n",
    "    \"composer\": 5,\n",
    "    \"dentist\": 6,\n",
    "    \"dietitian\": 7,\n",
    "    \"dj\": 8,\n",
    "    \"filmmaker\": 9,\n",
    "    \"interior_designer\": 10,\n",
    "    \"journalist\": 11,\n",
    "    \"model\": 12,\n",
    "    \"nurse\": 13,\n",
    "    \"painter\": 14,\n",
    "    \"paralegal\": 15,\n",
    "    \"pastor\": 16,\n",
    "    \"personal_trainer\": 17,\n",
    "    \"photographer\": 18,\n",
    "    \"physician\": 19,\n",
    "    \"poet\": 20,\n",
    "    \"professor\": 21,\n",
    "    \"psychologist\": 22,\n",
    "    \"rapper\": 23,\n",
    "    \"software_engineer\": 24,\n",
    "    \"surgeon\": 25,\n",
    "    \"teacher\": 26,\n",
    "    \"yoga_teacher\": 27,\n",
    "}\n",
    "profession_dict_rev = {v: k for k, v in profession_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profession_idx in unique_feats.keys():\n",
    "    print(f'{profession_idx}. {profession_dict_rev[profession_idx]} has {next(iter(unique_feats[profession_idx].values())).sum()} unique features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspected_prof_idx = 1\n",
    "print(f'Relevant features for {profession_dict_rev[inspected_prof_idx]}')\n",
    "\n",
    "class_feats = unique_feats[inspected_prof_idx]\n",
    "class_feats = list(class_feats.values())[0]\n",
    "class_feats_nonzero = class_feats.nonzero().flatten().tolist()\n",
    "class_feats_nonzero\n",
    "\n",
    "prof_node_effects = list(node_effects[inspected_prof_idx].values())[0]\n",
    "feat_effects = prof_node_effects[class_feats_nonzero].tolist()\n",
    "\n",
    "prof_unique_feats = zip(class_feats_nonzero, feat_effects)\n",
    "sorted_prof_unique_feats = sorted(prof_unique_feats, key=lambda x: x[1], reverse=True)\n",
    "for feat_idx, effect in sorted_prof_unique_feats:\n",
    "    print(f'Feature {feat_idx} has effect {effect}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_idx = 37\n",
    "# feat_idx = 2539\n",
    "# feat_idx = 7303\n",
    "feat_idx = 6972\n",
    "\n",
    "out = examine_dimension(\n",
    "    model,\n",
    "    submodule,\n",
    "    buffer,\n",
    "    dictionary,\n",
    "    max_length=128,\n",
    "    n_inputs=1000,\n",
    "    dim_idx=feat_idx,\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "print(f'\\n\\ntop activating tokens for feature {feat_idx}')\n",
    "for token in out.top_tokens:\n",
    "    print(token)\n",
    "print(f'\\n\\ntop affected tokens for feature {feat_idx}')\n",
    "for token in out.top_affected:\n",
    "    print(token)\n",
    "out.top_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top k node effects (attribution_patching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "prof_idx = 0\n",
    "print(f'{prof_idx}. {profession_dict_rev[prof_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_node_effects = list(node_effects[inspected_prof_idx].values())[0]\n",
    "feat_effects = enumerate(prof_node_effects.tolist())\n",
    "sorted_feat_effects = sorted(feat_effects, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feat_effects[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspected_top_idx = 2\n",
    "\n",
    "\n",
    "feat_idx = sorted_feat_effects[inspected_top_idx][0]\n",
    "print(f'Feature {feat_idx} has effect {sorted_feat_effects[inspected_top_idx][1]}')\n",
    "\n",
    "# feat_idx = 1155 # female\n",
    "# feat_idx = 37 # Jewish\n",
    "\n",
    "out = examine_dimension(\n",
    "    model,\n",
    "    submodule,\n",
    "    buffer,\n",
    "    dictionary,\n",
    "    max_length=128,\n",
    "    n_inputs=1000,\n",
    "    dim_idx=feat_idx,\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "print(f'\\n\\ntop activating tokens for feature {feat_idx}')\n",
    "for token in out.top_tokens:\n",
    "    print(token)\n",
    "print(f'\\n\\ntop affected tokens for feature {feat_idx}')\n",
    "for token in out.top_affected:\n",
    "    print(token)\n",
    "out.top_contexts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting functions\n",
    "\n",
    "\n",
    "def plot_feature_effects_above_threshold(nodes, threshold=0.05):\n",
    "    all_values = []\n",
    "    for key in nodes.keys():\n",
    "        all_values.append(nodes[key].cpu().numpy().reshape(-1))\n",
    "    all_values = [x for sublist in all_values for x in sublist]\n",
    "    all_values = [x for x in all_values if x > threshold]\n",
    "\n",
    "    all_values = sorted(all_values, reverse=True)\n",
    "    plt.scatter(range(len(all_values)), all_values)\n",
    "    plt.title(\"all_values\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
