{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from typing import Optional\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import experiments.utils as utils\n",
    "\n",
    "\n",
    "\n",
    "DICTIONARIES_PATH = \"../dictionary_learning/dictionaries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a potential issue as we currently assume that all SAEs have the same classes.\n",
    "\n",
    "\n",
    "def get_classes(first_path: str) -> list[int]:\n",
    "    class_accuracies_file = f\"{first_path}/class_accuracies.pkl\"\n",
    "    with open(class_accuracies_file, \"rb\") as f:\n",
    "        class_accuracies = pickle.load(f)\n",
    "    return list(class_accuracies[\"clean_acc\"].keys())\n",
    "\n",
    "def get_sparsity_penalty(config: dict, trainer_class: str) -> float:\n",
    "    if trainer_class == \"TrainerTopK\":\n",
    "        return config[\"trainer\"][\"k\"]\n",
    "    elif trainer_class == \"PAnnealTrainer\":\n",
    "        return config[\"trainer\"][\"sparsity_penalty\"]\n",
    "    else:\n",
    "        return config[\"trainer\"][\"l1_penalty\"]\n",
    "\n",
    "def get_l0_frac_recovered(ae_paths: list[str]) -> dict[str, dict[str, float]]:\n",
    "    results = {}\n",
    "    for ae_path in ae_paths:\n",
    "        eval_results_file = f\"{ae_path}/eval_results.json\"\n",
    "        if not os.path.exists(eval_results_file):\n",
    "            print(f\"Warning: {eval_results_file} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        with open(eval_results_file, \"r\") as f:\n",
    "            eval_results = json.load(f)\n",
    "\n",
    "        l0 = eval_results[\"l0\"]\n",
    "        frac_recovered = eval_results[\"frac_recovered\"]\n",
    "\n",
    "        results[ae_path] = {\n",
    "            \"l0\": l0,\n",
    "            \"frac_recovered\": frac_recovered,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def add_ae_config_results(ae_paths: list[str], results: dict[str, dict[str, float]]) -> dict[str, dict[str, float]]:\n",
    "\n",
    "    for ae_path in ae_paths:\n",
    "        config_file = f\"{ae_path}/config.json\"\n",
    "\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        trainer_class = config[\"trainer\"][\"trainer_class\"]\n",
    "        results[ae_path][\"trainer_class\"] = trainer_class\n",
    "        results[ae_path][\"l1_penalty\"] = get_sparsity_penalty(config, trainer_class)\n",
    "\n",
    "        results[ae_path][\"lr\"] = config[\"trainer\"][\"lr\"]\n",
    "        results[ae_path][\"dict_size\"] = config[\"trainer\"][\"dict_size\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_ablation_diff_plotting_dict(\n",
    "    ae_paths: list[str],\n",
    "    results: dict[str, dict[str, float]],\n",
    "    threshold: float,\n",
    "    intended_filter_class_ids: list[int],\n",
    "    unintended_filter_class_ids: list[int],\n",
    "    filename_counter: str,\n",
    "    acc_key: str = \"acc\",\n",
    ") -> dict:\n",
    "\n",
    "    for ae_path in ae_paths:\n",
    "\n",
    "        intended_diffs = []\n",
    "        unintended_diffs = []\n",
    "\n",
    "        class_accuracies_file = f\"{ae_path}/class_accuracies{filename_counter}.pkl\"\n",
    "\n",
    "        if not os.path.exists(class_accuracies_file):\n",
    "            print(\n",
    "                f\"Warning: {class_accuracies_file} does not exist. Removing this path from results.\"\n",
    "            )\n",
    "            del results[ae_path]\n",
    "            continue\n",
    "\n",
    "        with open(class_accuracies_file, \"rb\") as f:\n",
    "            class_accuracies = pickle.load(f)\n",
    "\n",
    "        classes = list(class_accuracies[\"clean_acc\"].keys())\n",
    "\n",
    "        # print(class_accuracies)\n",
    "        # for class_id in classes:\n",
    "        #     print(class_accuracies[\"clean_acc\"][class_id][\"acc\"])\n",
    "\n",
    "        for class_id in classes:\n",
    "\n",
    "            if isinstance(class_id, str) and \" probe on \" in class_id:\n",
    "                continue\n",
    "\n",
    "            if intended_filter_class_ids and class_id not in intended_filter_class_ids:\n",
    "                continue\n",
    "\n",
    "            clean = class_accuracies[\"clean_acc\"][class_id][\"acc\"]\n",
    "            # print(ae_path)\n",
    "            # print(class_accuracies[class_id])\n",
    "            patched = class_accuracies[class_id][threshold][class_id][acc_key]\n",
    "\n",
    "            diff = clean - patched\n",
    "            intended_diffs.append(diff)\n",
    "\n",
    "        for intended_class_id in classes:\n",
    "\n",
    "            if isinstance(intended_class_id, str) and \" probe on \" in intended_class_id:\n",
    "                continue\n",
    "\n",
    "            if intended_filter_class_ids and intended_class_id not in intended_filter_class_ids:\n",
    "                continue\n",
    "\n",
    "            for unintended_class_id in classes:\n",
    "                if intended_class_id == unintended_class_id:\n",
    "                    continue\n",
    "\n",
    "                if (\n",
    "                    unintended_filter_class_ids\n",
    "                    and unintended_class_id not in unintended_filter_class_ids\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                if isinstance(unintended_class_id, str) and \" probe on \" in unintended_class_id:\n",
    "                    continue\n",
    "\n",
    "                clean = class_accuracies[\"clean_acc\"][unintended_class_id][\"acc\"]\n",
    "                patched = class_accuracies[intended_class_id][threshold][unintended_class_id][acc_key]\n",
    "                diff = clean - patched\n",
    "                unintended_diffs.append(diff)\n",
    "\n",
    "        average_intended_diff = sum(intended_diffs) / len(intended_diffs)\n",
    "        average_unintended_diff = sum(unintended_diffs) / len(unintended_diffs)\n",
    "        average_diff = average_intended_diff - average_unintended_diff\n",
    "\n",
    "        results[ae_path][\"average_diff\"] = average_diff\n",
    "        results[ae_path][\"average_intended_diff\"] = average_intended_diff\n",
    "        results[ae_path][\"average_unintended_diff\"] = average_unintended_diff\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_l0_threshold(results: dict, l0_threshold: Optional[int]) -> dict:\n",
    "    if l0_threshold is not None:\n",
    "        filtered_results = {\n",
    "            path: data for path, data in results.items() \n",
    "            if data['l0'] <= l0_threshold\n",
    "        }\n",
    "        \n",
    "        # Optional: Print how many results were filtered out\n",
    "        filtered_count = len(results) - len(filtered_results)\n",
    "        print(f\"Filtered out {filtered_count} results with L0 > {l0_threshold}\")\n",
    "        \n",
    "        # Replace the original results with the filtered results\n",
    "        results = filtered_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Gated SAE”, “Gated SAE w/ p-annealing”, “Standard”, “Standard w/ p-annealing”\n",
    "label_lookup = {\n",
    "    \"StandardTrainer\": \"Standard\",\n",
    "    \"PAnnealTrainer\": \"Standard w/ p-annealing\",\n",
    "    \"GatedSAETrainer\": \"Gated SAE\",\n",
    "    # \"GatedAnnealTrainer\": \"Gated SAE w/ p-annealing\",\n",
    "    \"TrainerTopK\": \"Top K\",\n",
    "    # \"Identity\": \"Identity\",\n",
    "}\n",
    "\n",
    "unique_trainers = list(label_lookup.keys())\n",
    "\n",
    "# create a dictionary mapping trainer types to marker shapes\n",
    "trainer_markers = dict(zip(unique_trainers, [\"o\", \"X\", \"^\", \"d\"]))\n",
    "\n",
    "# default text size\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "def plot_3var_graph(\n",
    "    results: dict,\n",
    "    title: str,\n",
    "    custom_metric: str,\n",
    "    xlims: Optional[tuple[float, float]] = None,\n",
    "    ylims: Optional[tuple[float, float]] = None,\n",
    "    colorbar_label: str = \"Average Diff\",\n",
    "    output_filename: Optional[str] = None,\n",
    "    legend_location: str = \"lower right\",\n",
    "):\n",
    "    # Extract data from results\n",
    "    l0_values = [data['l0'] for data in results.values()]\n",
    "    frac_recovered_values = [data['frac_recovered'] for data in results.values()]\n",
    "    average_diff_values = [data[custom_metric] for data in results.values()]\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Create a normalize object for color scaling\n",
    "    norm = Normalize(vmin=min(average_diff_values), vmax=max(average_diff_values))\n",
    "\n",
    "    handles, labels = [], []\n",
    "\n",
    "    for trainer, marker in trainer_markers.items():\n",
    "\n",
    "        # Filter data for this trainer\n",
    "        trainer_data = {k: v for k, v in results.items() if v['trainer_class'] == trainer}\n",
    "        \n",
    "        if not trainer_data:\n",
    "            continue  # Skip this trainer if no data points\n",
    "\n",
    "        l0_values = [data['l0'] for data in trainer_data.values()]\n",
    "        frac_recovered_values = [data['frac_recovered'] for data in trainer_data.values()]\n",
    "        average_diff_values = [data[custom_metric] for data in trainer_data.values()]\n",
    "\n",
    "        # Plot data points\n",
    "        scatter = ax.scatter(\n",
    "            l0_values,\n",
    "            frac_recovered_values,\n",
    "            c=average_diff_values,\n",
    "            cmap=\"viridis\",\n",
    "            marker=marker,\n",
    "            s=100,\n",
    "            label=label_lookup[trainer],\n",
    "            norm=norm,\n",
    "            edgecolor=\"black\"\n",
    "        )\n",
    "\n",
    "        # custom legend stuff\n",
    "        _handle, _ = scatter.legend_elements(prop=\"sizes\")\n",
    "        _handle[0].set_markeredgecolor(\"black\")\n",
    "        _handle[0].set_markerfacecolor(\"white\")\n",
    "        _handle[0].set_markersize(10)\n",
    "        if marker == \"d\":\n",
    "            _handle[0].set_markersize(13)\n",
    "        handles += _handle\n",
    "        labels.append(label_lookup[trainer])\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(scatter, ax=ax, label=colorbar_label)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(\"L0\")\n",
    "    ax.set_ylabel(\"Fraction Recovered\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.legend(handles, labels, loc=legend_location)\n",
    "\n",
    "    # Set axis limits\n",
    "    if xlims:\n",
    "        ax.set_xlim(*xlims)\n",
    "    if ylims:\n",
    "        ax.set_ylim(*ylims)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    if output_filename:\n",
    "        plt.savefig(output_filename, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# print(results)\n",
    "# if include_diff:\n",
    "# plot_3var_graph(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "def plot_interactive_3var_graph(\n",
    "    results: Dict[str, Dict[str, float]],\n",
    "    custom_color_metric: str,\n",
    "    xlims: Optional[tuple[float, float]] = None,\n",
    "    y_lims: Optional[tuple[float, float]] = None,\n",
    "    output_filename: Optional[str] = None,\n",
    "):\n",
    "    # Extract data from results\n",
    "    ae_paths = list(results.keys())\n",
    "    l0_values = [data['l0'] for data in results.values()]\n",
    "    frac_recovered_values = [data['frac_recovered'] for data in results.values()]\n",
    "\n",
    "    custom_metric_value = [data[custom_color_metric] for data in results.values()]\n",
    "\n",
    "    dict_size = [data['dict_size'] for data in results.values()]\n",
    "    lr = [data['lr'] for data in results.values()]\n",
    "    l1_penalty = [data['l1_penalty'] for data in results.values()]\n",
    "    \n",
    "    # Create the scatter plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add trace\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=l0_values,\n",
    "        y=frac_recovered_values,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=custom_metric_value,  # Color points based on frac_recovered\n",
    "            colorscale='Viridis',  # You can change this colorscale\n",
    "            showscale=True\n",
    "        ),\n",
    "        text=[f'AE Path: {ae}<br>L0: {l0:.4f}<br>Frac Recovered: {fr:.4f}<br>Custom Metric: {ad:.4f}<br>Dict Size: {d:.4f}<br>LR: {l:.4f}<br>L1 Penalty: {l1:.4f}' \n",
    "              for ae, l0, fr, ad, d, l, l1 in zip(ae_paths, l0_values, frac_recovered_values, custom_metric_value, dict_size, lr, l1_penalty)],\n",
    "        hoverinfo='text'\n",
    "    ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='L0 vs Fraction Recovered',\n",
    "        xaxis_title='L0',\n",
    "        yaxis_title='Fraction Recovered',\n",
    "        hovermode='closest'\n",
    "    )\n",
    "\n",
    "    # Set axis limits\n",
    "    if xlims:\n",
    "        fig.update_xaxes(range=xlims)\n",
    "    if y_lims:\n",
    "        fig.update_yaxes(range=y_lims)\n",
    "\n",
    "    # Save and show the plot\n",
    "    if output_filename:\n",
    "        fig.write_html(output_filename)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_interactive_3var_graph(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2var_graph(\n",
    "    results: dict,\n",
    "    xlims: Optional[tuple[float, float]] = None,\n",
    "    y_lims: Optional[tuple[float, float]] = None,\n",
    "    output_filename: Optional[str] = None,\n",
    "):\n",
    "    # Extract data from results\n",
    "    l0_values = [data['l0'] for data in results.values()]\n",
    "    frac_recovered_values = [data['frac_recovered'] for data in results.values()]\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot data points\n",
    "    ax.scatter(\n",
    "        l0_values,\n",
    "        frac_recovered_values,\n",
    "        s=100,\n",
    "        edgecolor=\"black\",\n",
    "        c=\"blue\"  # You can change this color as needed\n",
    "    )\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(\"L0\")\n",
    "    ax.set_ylabel(\"Fraction Recovered\")\n",
    "    ax.set_title(\"L0 vs Fraction Recovered\")\n",
    "\n",
    "    # Set axis limits\n",
    "    if xlims:\n",
    "        ax.set_xlim(*xlims)\n",
    "    if y_lims:\n",
    "        ax.set_ylim(*y_lims)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    if output_filename:\n",
    "        plt.savefig(output_filename, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_2var_graph(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to generate graphs, where you manually populate sweep_name and submodule_trainers\n",
    "sweep_name = \"pythia70m_test_sae\"\n",
    "submodule_trainers = {\"resid_post_layer_3\": {\"trainer_ids\": [0]}}\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_standard_ctx128_0712\": {\n",
    "        \"resid_post_layer_3\": {\"trainer_ids\": [1, 7, 11, 18]}\n",
    "    }\n",
    "}\n",
    "\n",
    "trainer_ids = [2, 6, 10, 14, 18]\n",
    "# trainer_ids = None\n",
    "\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_standard_ctx128_0712\": {\n",
    "        # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "        \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "    },\n",
    "    \"pythia70m_sweep_topk_ctx128_0730\": {\n",
    "        # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_3\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "        \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "    },        \n",
    "    \"pythia70m_sweep_gated_ctx128_0730\": {\n",
    "        # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_3\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "        \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "}\n",
    "\n",
    "# ae_sweep_paths = {\n",
    "#     \"pythia70m_sweep_topk_ctx128_0730\": {\n",
    "#         # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "#         # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "#         # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "#         \"resid_post_layer_3\": {\"trainer_ids\": None},\n",
    "#         # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "#     }\n",
    "# }\n",
    "\n",
    "trainer_ids = None\n",
    "# trainer_ids = [0,1,2,3]\n",
    "\n",
    "ae_sweep_paths = {\n",
    "    \"gemma-2-2b_sweep_standard_ctx128_ef8_0824\": {\n",
    "        # \"resid_post_layer_12\": {\"trainer_ids\": trainer_ids},\n",
    "        \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_20\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824\": {\n",
    "        # \"resid_post_layer_12\": {\"trainer_ids\": trainer_ids},\n",
    "        \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_20\": {\"trainer_ids\": trainer_ids},\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "submodule_trainers = ae_sweep_paths[sweep_name]\n",
    "\n",
    "\n",
    "ae_paths = []\n",
    "\n",
    "for sweep_name, submodule_trainers in ae_sweep_paths.items():\n",
    "\n",
    "    ae_group_paths = utils.get_ae_group_paths(\n",
    "        DICTIONARIES_PATH, sweep_name, submodule_trainers\n",
    "    )\n",
    "    ae_paths.extend(utils.get_ae_paths(ae_group_paths))\n",
    "\n",
    "l0_loss_recovered_results = get_l0_frac_recovered(ae_paths)\n",
    "plotting_results = add_ae_config_results(ae_paths, l0_loss_recovered_results)\n",
    "\n",
    "filename_counter = \"\"\n",
    "\n",
    "l0_threshold = 500\n",
    "\n",
    "# plotting_results = filter_by_l0_threshold(plotting_results, l0_threshold)\n",
    "\n",
    "title = \"L0 vs Fraction Recovered vs Sparsity Penalty\"\n",
    "\n",
    "custom_metric = \"l1_penalty\"\n",
    "\n",
    "plot_3var_graph(plotting_results, title, custom_metric)\n",
    "plot_interactive_3var_graph(plotting_results, custom_metric)\n",
    "\n",
    "# At this point, if there's any additional .json files located alongside the ae.pt and eval_results.json\n",
    "# You can easily adapt them to be included in the plotting_results dictionary by using something similar to add_ae_config_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(ae_paths)\n",
    "\n",
    "# If not empty, this will filter to only include the specified class ids\n",
    "intended_filter_class_ids = []\n",
    "unintended_filter_class_ids = []\n",
    "intended_filter_class_ids = [0, 1, 2, 6]\n",
    "# intended_filter_class_ids = [\"male / female\"]\n",
    "# unintended_filter_class_ids = [1]\n",
    "# unintended_filter_class_ids = [-4]\n",
    "\n",
    "threshold = 0.1\n",
    "threshold = 100\n",
    "\n",
    "filename_counter = \"_attrib\"\n",
    "\n",
    "\n",
    "results_acc = add_ablation_diff_plotting_dict(\n",
    "    ae_paths,\n",
    "    plotting_results,\n",
    "    threshold,\n",
    "    intended_filter_class_ids,\n",
    "    unintended_filter_class_ids,\n",
    "    filename_counter,\n",
    "    \"acc\"\n",
    ")\n",
    "# results_acc0 = add_ablation_diff_plotting_dict(\n",
    "#     ae_paths,\n",
    "#     plotting_results,\n",
    "#     threshold,\n",
    "#     intended_filter_class_ids,\n",
    "#     unintended_filter_class_ids,\n",
    "#     filename_counter,\n",
    "#     \"loss\"\n",
    "# )\n",
    "\n",
    "# l0_threshold = None\n",
    "# l0_threshold = 500\n",
    "\n",
    "custom_metric1 = \"average_diff\"\n",
    "custom_metric2 = \"average_intended_diff\"\n",
    "custom_metric3 = \"average_unintended_diff\"\n",
    "\n",
    "title = f\"\"\"Ablating Top {threshold} features from attribution patching.\n",
    "                 Color is (intended class difference - unintended class difference).\"\"\"\n",
    "\n",
    "# results_acc = filter_by_l0_threshold(results_acc, l0_threshold)\n",
    "# results_acc0 = filter_by_l0_threshold(results_acc0, l0_threshold)\n",
    "\n",
    "plot_3var_graph(results_acc, title, custom_metric1)\n",
    "plot_interactive_3var_graph(results_acc, custom_metric1)\n",
    "# plot_3var_graph(results_acc0, title, custom_metric1)\n",
    "# plot_3var_graph(results, title, custom_metric3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spurious_correlation_plotting_dict(\n",
    "    ae_paths: list[str],\n",
    "    threshold: float,\n",
    "    ablated_probe_class_id: str,\n",
    "    eval_probe_class_id: str,\n",
    "    eval_data_class_id: str,\n",
    "    filename_counter: str,\n",
    "    acc_key: str = \"acc\",\n",
    ") -> dict:\n",
    "    results = {}\n",
    "\n",
    "    for ae_path in ae_paths:\n",
    "        eval_results_file = f\"{ae_path}/eval_results.json\"\n",
    "\n",
    "        if not os.path.exists(eval_results_file):\n",
    "            print(f\"Warning: {eval_results_file} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        with open(eval_results_file, \"r\") as f:\n",
    "            eval_results = json.load(f)\n",
    "\n",
    "        l0 = eval_results[\"l0\"]\n",
    "        frac_recovered = eval_results[\"frac_recovered\"]\n",
    "\n",
    "        results[ae_path] = {\n",
    "            \"l0\": l0,\n",
    "            \"frac_recovered\": frac_recovered,\n",
    "        }\n",
    "\n",
    "        config_file = f\"{ae_path}/config.json\"\n",
    "\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        trainer_class = config[\"trainer\"][\"trainer_class\"]\n",
    "        results[ae_path][\"trainer_class\"] = trainer_class\n",
    "        results[ae_path][\"l1_penalty\"] = get_sparsity_penalty(config, trainer_class)\n",
    "\n",
    "        results[ae_path][\"lr\"] = config[\"trainer\"][\"lr\"]\n",
    "        results[ae_path][\"dict_size\"] = config[\"trainer\"][\"dict_size\"]\n",
    "\n",
    "        class_accuracies_file = f\"{ae_path}/class_accuracies{filename_counter}.pkl\"\n",
    "\n",
    "        if not os.path.exists(class_accuracies_file):\n",
    "            print(\n",
    "                f\"Warning: {class_accuracies_file} does not exist. Removing this path from results.\"\n",
    "            )\n",
    "            del results[ae_path]\n",
    "            continue\n",
    "\n",
    "        with open(class_accuracies_file, \"rb\") as f:\n",
    "            class_accuracies = pickle.load(f)\n",
    "\n",
    "        classes = list(class_accuracies[\"clean_acc\"].keys())\n",
    "\n",
    "        combined_class_name = f\"{eval_probe_class_id} probe on {eval_data_class_id} data\"\n",
    "\n",
    "        original_acc = class_accuracies[\"clean_acc\"][combined_class_name][\"acc\"]\n",
    "        changed_acc = original_acc\n",
    "\n",
    "        changed_acc = class_accuracies[ablated_probe_class_id][threshold][combined_class_name][acc_key]\n",
    "\n",
    "        results[ae_path][\"average_diff\"] = changed_acc\n",
    "    return results\n",
    "\n",
    "\n",
    "ablated_probe_class_id = \"male / female\"\n",
    "ablated_probe_class_id = \"professor / nurse\"\n",
    "eval_probe_class_id = \"male_professor / female_nurse\"\n",
    "eval_probe_class_id = \"male_professor / female_nurse\"\n",
    "# eval_probe_class_id = \"biased_male / biased_female\"\n",
    "eval_data_class_id = \"professor / nurse\"\n",
    "eval_data_class_id = \"male / female\"\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "spurious_correlation_results = get_spurious_correlation_plotting_dict(\n",
    "    ae_paths,\n",
    "    threshold,\n",
    "    ablated_probe_class_id,\n",
    "    eval_probe_class_id,\n",
    "    eval_data_class_id,\n",
    "    filename_counter,\n",
    "    \"acc\",\n",
    ")\n",
    "\n",
    "\n",
    "l0_threshold = None\n",
    "# l0_threshold = 500\n",
    "\n",
    "custom_metric1 = \"average_diff\"\n",
    "\n",
    "title = f\"\"\"Ablating Top {threshold} gender features.\"\"\"\n",
    "\n",
    "spurious_correlation_results = filter_by_l0_threshold(spurious_correlation_results, l0_threshold)\n",
    "\n",
    "plot_3var_graph(spurious_correlation_results, title, custom_metric1, colorbar_label=\"Probe Accuracy\")\n",
    "plot_interactive_3var_graph(spurious_correlation_results, custom_metric1)\n",
    "# plot_3var_graph(results_acc0, title, custom_metric1)\n",
    "# plot_3var_graph(results, title, custom_metric3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
