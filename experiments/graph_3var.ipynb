{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from typing import Optional\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import experiments.utils as utils\n",
    "\n",
    "\n",
    "DICTIONARIES_PATH = \"../dictionary_learning/dictionaries\"\n",
    "# DICTIONARIES_PATH = \"../dictionary_learning/dictionaries/gemma-2-2b-saved-data\"\n",
    "# DICTIONARIES_PATH = \"../dictionary_learning/dictionaries/pythia70m-autointerp-results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a potential issue as we currently assume that all SAEs have the same classes.\n",
    "\n",
    "\n",
    "def get_classes(first_path: str) -> list[int]:\n",
    "    class_accuracies_file = f\"{first_path}/class_accuracies.pkl\"\n",
    "    with open(class_accuracies_file, \"rb\") as f:\n",
    "        class_accuracies = pickle.load(f)\n",
    "    return list(class_accuracies[\"clean_acc\"].keys())\n",
    "\n",
    "\n",
    "def get_sparsity_penalty(config: dict, trainer_class: str) -> float:\n",
    "    if trainer_class == \"TrainerTopK\":\n",
    "        return config[\"trainer\"][\"k\"]\n",
    "    elif trainer_class == \"PAnnealTrainer\":\n",
    "        return config[\"trainer\"][\"sparsity_penalty\"]\n",
    "    else:\n",
    "        return config[\"trainer\"][\"l1_penalty\"]\n",
    "\n",
    "\n",
    "def get_l0_frac_recovered(ae_paths: list[str]) -> dict[str, dict[str, float]]:\n",
    "    results = {}\n",
    "    for ae_path in ae_paths:\n",
    "        eval_results_file = f\"{ae_path}/eval_results.json\"\n",
    "        if not os.path.exists(eval_results_file):\n",
    "            print(f\"Warning: {eval_results_file} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        with open(eval_results_file, \"r\") as f:\n",
    "            eval_results = json.load(f)\n",
    "\n",
    "        l0 = eval_results[\"l0\"]\n",
    "        frac_recovered = eval_results[\"frac_recovered\"]\n",
    "\n",
    "        results[ae_path] = {\n",
    "            \"l0\": l0,\n",
    "            \"frac_recovered\": frac_recovered,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_ae_config_results(\n",
    "    ae_paths: list[str], results: dict[str, dict[str, float]]\n",
    ") -> dict[str, dict[str, float]]:\n",
    "    for ae_path in ae_paths:\n",
    "        config_file = f\"{ae_path}/config.json\"\n",
    "\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        trainer_class = config[\"trainer\"][\"trainer_class\"]\n",
    "        results[ae_path][\"trainer_class\"] = trainer_class\n",
    "        results[ae_path][\"l1_penalty\"] = get_sparsity_penalty(config, trainer_class)\n",
    "\n",
    "        results[ae_path][\"lr\"] = config[\"trainer\"][\"lr\"]\n",
    "        results[ae_path][\"dict_size\"] = config[\"trainer\"][\"dict_size\"]\n",
    "        if \"steps\" in config[\"trainer\"]:\n",
    "            results[ae_path][\"steps\"] = config[\"trainer\"][\"steps\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_ablation_diff_plotting_dict(\n",
    "    ae_paths: list[str],\n",
    "    results: dict[str, dict[str, float]],\n",
    "    threshold: float,\n",
    "    intended_filter_class_ids: list[int],\n",
    "    unintended_filter_class_ids: list[int],\n",
    "    filename_counter: str,\n",
    "    acc_key: str = \"acc\",\n",
    ") -> dict:\n",
    "    for ae_path in ae_paths:\n",
    "        intended_diffs = []\n",
    "        unintended_diffs = []\n",
    "\n",
    "        class_accuracies_file = f\"{ae_path}/class_accuracies{filename_counter}.pkl\"\n",
    "\n",
    "        if not os.path.exists(class_accuracies_file):\n",
    "            print(\n",
    "                f\"Warning: {class_accuracies_file} does not exist. Removing this path from results.\"\n",
    "            )\n",
    "            del results[ae_path]\n",
    "            continue\n",
    "\n",
    "        with open(class_accuracies_file, \"rb\") as f:\n",
    "            class_accuracies = pickle.load(f)\n",
    "\n",
    "        classes = list(class_accuracies[\"clean_acc\"].keys())\n",
    "\n",
    "        # print(class_accuracies)\n",
    "        # for class_id in classes:\n",
    "        #     print(class_accuracies[\"clean_acc\"][class_id][\"acc\"])\n",
    "\n",
    "        for class_id in classes:\n",
    "            if isinstance(class_id, str) and \" probe on \" in class_id:\n",
    "                continue\n",
    "\n",
    "            if intended_filter_class_ids and class_id not in intended_filter_class_ids:\n",
    "                continue\n",
    "\n",
    "            clean = class_accuracies[\"clean_acc\"][class_id][\"acc\"]\n",
    "            # print(ae_path)\n",
    "            # print(class_accuracies[class_id])\n",
    "            patched = class_accuracies[class_id][threshold][class_id][acc_key]\n",
    "\n",
    "            diff = clean - patched\n",
    "            intended_diffs.append(diff)\n",
    "\n",
    "        for intended_class_id in classes:\n",
    "            if isinstance(intended_class_id, str) and \" probe on \" in intended_class_id:\n",
    "                continue\n",
    "\n",
    "            if intended_filter_class_ids and intended_class_id not in intended_filter_class_ids:\n",
    "                continue\n",
    "\n",
    "            for unintended_class_id in classes:\n",
    "                if intended_class_id == unintended_class_id:\n",
    "                    continue\n",
    "\n",
    "                if (\n",
    "                    unintended_filter_class_ids\n",
    "                    and unintended_class_id not in unintended_filter_class_ids\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                if isinstance(unintended_class_id, str) and \" probe on \" in unintended_class_id:\n",
    "                    continue\n",
    "\n",
    "                clean = class_accuracies[\"clean_acc\"][unintended_class_id][\"acc\"]\n",
    "                patched = class_accuracies[intended_class_id][threshold][unintended_class_id][\n",
    "                    acc_key\n",
    "                ]\n",
    "                diff = clean - patched\n",
    "                unintended_diffs.append(diff)\n",
    "\n",
    "        average_intended_diff = sum(intended_diffs) / len(intended_diffs)\n",
    "        average_unintended_diff = sum(unintended_diffs) / len(unintended_diffs)\n",
    "        average_diff = average_intended_diff - average_unintended_diff\n",
    "\n",
    "        results[ae_path][\"average_diff\"] = average_diff\n",
    "        results[ae_path][\"average_intended_diff\"] = average_intended_diff\n",
    "        results[ae_path][\"average_unintended_diff\"] = average_unintended_diff\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_l0_threshold(results: dict, l0_threshold: Optional[int]) -> dict:\n",
    "    if l0_threshold is not None:\n",
    "        filtered_results = {\n",
    "            path: data for path, data in results.items() if data[\"l0\"] <= l0_threshold\n",
    "        }\n",
    "\n",
    "        # Optional: Print how many results were filtered out\n",
    "        filtered_count = len(results) - len(filtered_results)\n",
    "        print(f\"Filtered out {filtered_count} results with L0 > {l0_threshold}\")\n",
    "\n",
    "        # Replace the original results with the filtered results\n",
    "        results = filtered_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Gated SAE”, “Gated SAE w/ p-annealing”, “Standard”, “Standard w/ p-annealing”\n",
    "label_lookup = {\n",
    "    \"StandardTrainer\": \"Standard\",\n",
    "    # \"PAnnealTrainer\": \"Standard w/ p-annealing\",\n",
    "    # \"GatedSAETrainer\": \"Gated SAE\",\n",
    "    \"TrainerJumpRelu\": \"JumpReLU\",\n",
    "    # \"GatedAnnealTrainer\": \"Gated SAE w/ p-annealing\",\n",
    "    \"TrainerTopK\": \"Top K\",\n",
    "    # \"Identity\": \"Identity\",\n",
    "}\n",
    "\n",
    "unique_trainers = list(label_lookup.keys())\n",
    "\n",
    "# create a dictionary mapping trainer types to marker shapes\n",
    "\n",
    "trainer_markers = {\n",
    "    \"StandardTrainer\": \"o\",\n",
    "    \"TrainerJumpRelu\": \"X\",\n",
    "    \"TrainerTopK\": \"^\",\n",
    "    \"GatedSAETrainer\": \"d\",\n",
    "}\n",
    "\n",
    "\n",
    "# default text size\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "\n",
    "def plot_3var_graph(\n",
    "    results: dict,\n",
    "    title: str,\n",
    "    custom_metric: str,\n",
    "    xlims: Optional[tuple[float, float]] = None,\n",
    "    ylims: Optional[tuple[float, float]] = None,\n",
    "    colorbar_label: str = \"Average Diff\",\n",
    "    output_filename: Optional[str] = None,\n",
    "    legend_location: str = \"lower right\",\n",
    "):\n",
    "    # Extract data from results\n",
    "    l0_values = [data[\"l0\"] for data in results.values()]\n",
    "    frac_recovered_values = [data[\"frac_recovered\"] for data in results.values()]\n",
    "    average_diff_values = [data[custom_metric] for data in results.values()]\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Create a normalize object for color scaling\n",
    "    norm = Normalize(vmin=min(average_diff_values), vmax=max(average_diff_values))\n",
    "\n",
    "    handles, labels = [], []\n",
    "\n",
    "    for trainer, marker in trainer_markers.items():\n",
    "        # Filter data for this trainer\n",
    "        trainer_data = {k: v for k, v in results.items() if v[\"trainer_class\"] == trainer}\n",
    "\n",
    "        if not trainer_data:\n",
    "            continue  # Skip this trainer if no data points\n",
    "\n",
    "        l0_values = [data[\"l0\"] for data in trainer_data.values()]\n",
    "        frac_recovered_values = [data[\"frac_recovered\"] for data in trainer_data.values()]\n",
    "        average_diff_values = [data[custom_metric] for data in trainer_data.values()]\n",
    "\n",
    "        # Plot data points\n",
    "        scatter = ax.scatter(\n",
    "            l0_values,\n",
    "            frac_recovered_values,\n",
    "            c=average_diff_values,\n",
    "            cmap=\"viridis\",\n",
    "            marker=marker,\n",
    "            s=100,\n",
    "            label=label_lookup[trainer],\n",
    "            norm=norm,\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "\n",
    "        # custom legend stuff\n",
    "        _handle, _ = scatter.legend_elements(prop=\"sizes\")\n",
    "        _handle[0].set_markeredgecolor(\"black\")\n",
    "        _handle[0].set_markerfacecolor(\"white\")\n",
    "        _handle[0].set_markersize(10)\n",
    "        if marker == \"d\":\n",
    "            _handle[0].set_markersize(13)\n",
    "        handles += _handle\n",
    "        labels.append(label_lookup[trainer])\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(scatter, ax=ax, label=colorbar_label)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(\"L0\")\n",
    "    ax.set_ylabel(\"Fraction Recovered\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.legend(handles, labels, loc=legend_location)\n",
    "\n",
    "    # Set axis limits\n",
    "    if xlims:\n",
    "        ax.set_xlim(*xlims)\n",
    "    if ylims:\n",
    "        ax.set_ylim(*ylims)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    if output_filename:\n",
    "        plt.savefig(output_filename, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# print(results)\n",
    "# if include_diff:\n",
    "# plot_3var_graph(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "\n",
    "def plot_interactive_3var_graph(\n",
    "    results: Dict[str, Dict[str, float]],\n",
    "    custom_color_metric: str,\n",
    "    xlims: Optional[tuple[float, float]] = None,\n",
    "    y_lims: Optional[tuple[float, float]] = None,\n",
    "    output_filename: Optional[str] = None,\n",
    "):\n",
    "    # Extract data from results\n",
    "    ae_paths = list(results.keys())\n",
    "    l0_values = [data[\"l0\"] for data in results.values()]\n",
    "    frac_recovered_values = [data[\"frac_recovered\"] for data in results.values()]\n",
    "\n",
    "    custom_metric_value = [data[custom_color_metric] for data in results.values()]\n",
    "\n",
    "    dict_size = [data[\"dict_size\"] for data in results.values()]\n",
    "    lr = [data[\"lr\"] for data in results.values()]\n",
    "    l1_penalty = [data[\"l1_penalty\"] for data in results.values()]\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=l0_values,\n",
    "            y=frac_recovered_values,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=custom_metric_value,  # Color points based on frac_recovered\n",
    "                colorscale=\"Viridis\",  # You can change this colorscale\n",
    "                showscale=True,\n",
    "            ),\n",
    "            text=[\n",
    "                f\"AE Path: {ae}<br>L0: {l0:.4f}<br>Frac Recovered: {fr:.4f}<br>Custom Metric: {ad:.4f}<br>Dict Size: {d:.4f}<br>LR: {l:.4f}<br>L1 Penalty: {l1:.4f}\"\n",
    "                for ae, l0, fr, ad, d, l, l1 in zip(\n",
    "                    ae_paths,\n",
    "                    l0_values,\n",
    "                    frac_recovered_values,\n",
    "                    custom_metric_value,\n",
    "                    dict_size,\n",
    "                    lr,\n",
    "                    l1_penalty,\n",
    "                )\n",
    "            ],\n",
    "            hoverinfo=\"text\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"L0 vs Fraction Recovered\",\n",
    "        xaxis_title=\"L0\",\n",
    "        yaxis_title=\"Fraction Recovered\",\n",
    "        hovermode=\"closest\",\n",
    "    )\n",
    "\n",
    "    # Set axis limits\n",
    "    if xlims:\n",
    "        fig.update_xaxes(range=xlims)\n",
    "    if y_lims:\n",
    "        fig.update_yaxes(range=y_lims)\n",
    "\n",
    "    # Save and show the plot\n",
    "    if output_filename:\n",
    "        fig.write_html(output_filename)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# plot_interactive_3var_graph(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2var_graph(\n",
    "    results: dict,\n",
    "    xlims: Optional[tuple[float, float]] = None,\n",
    "    y_lims: Optional[tuple[float, float]] = None,\n",
    "    output_filename: Optional[str] = None,\n",
    "):\n",
    "    # Extract data from results\n",
    "    l0_values = [data[\"l0\"] for data in results.values()]\n",
    "    frac_recovered_values = [data[\"frac_recovered\"] for data in results.values()]\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot data points\n",
    "    ax.scatter(\n",
    "        l0_values,\n",
    "        frac_recovered_values,\n",
    "        s=100,\n",
    "        edgecolor=\"black\",\n",
    "        c=\"blue\",  # You can change this color as needed\n",
    "    )\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(\"L0\")\n",
    "    ax.set_ylabel(\"Fraction Recovered\")\n",
    "    ax.set_title(\"L0 vs Fraction Recovered\")\n",
    "\n",
    "    # Set axis limits\n",
    "    if xlims:\n",
    "        ax.set_xlim(*xlims)\n",
    "    if y_lims:\n",
    "        ax.set_ylim(*y_lims)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    if output_filename:\n",
    "        plt.savefig(output_filename, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# plot_2var_graph(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to generate graphs, where you manually populate sweep_name and submodule_trainers\n",
    "sweep_name = \"pythia70m_test_sae\"\n",
    "submodule_trainers = {\"resid_post_layer_3\": {\"trainer_ids\": [0]}}\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_standard_ctx128_0712\": {\"resid_post_layer_3\": {\"trainer_ids\": [1, 7, 11, 18]}}\n",
    "}\n",
    "\n",
    "# trainer_ids = [2, 6, 10, 14, 18]\n",
    "trainer_ids = None\n",
    "\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_standard_ctx128_0712\": {\n",
    "        # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "        \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "    },\n",
    "    \"pythia70m_sweep_topk_ctx128_0730\": {\n",
    "        # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_3\": {\"trainer_ids\": None},\n",
    "        # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "        \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "    # \"pythia70m_sweep_gated_ctx128_0730\": {\n",
    "    #     # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "    #     # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "    #     # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "    #     # \"resid_post_layer_3\": {\"trainer_ids\": None},\n",
    "    #     # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "    #     \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "    # },\n",
    "}\n",
    "\n",
    "# ae_sweep_paths = {\n",
    "#     \"pythia70m_sweep_topk_ctx128_0730\": {\n",
    "#         # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "#         # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "#         # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "#         \"resid_post_layer_3\": {\"trainer_ids\": None},\n",
    "#         # \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "#     }\n",
    "# }\n",
    "\n",
    "trainer_ids = None\n",
    "# trainer_ids = [1]\n",
    "\n",
    "ae_sweep_paths = {\n",
    "    \"gemma-2-2b_sweep_standard_ctx128_ef8_0824\": {\n",
    "        # \"resid_post_layer_12\": {\"trainer_ids\": trainer_ids},\n",
    "        \"resid_post_layer_15\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_19\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_20\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824\": {\n",
    "        # \"resid_post_layer_12\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "        \"resid_post_layer_15\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_19\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_20\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "    \"gemma-2-2b_sweep_jumprelu_0902\": {\n",
    "        \"resid_post_layer_15\": {\"trainer_ids\": trainer_ids},\n",
    "        # \"resid_post_layer_19\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "}\n",
    "\n",
    "# trainer_ids = None\n",
    "# ae_sweep_paths = {\n",
    "#     \"gemma-2-2b_sweep_jumprelu_0902_probe_layer24_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "#     \"gemma-2-2b_sweep_standard_ctx128_ef8_0824_probe_layer24_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "#     \"gemma-2-2b_sweep_topk_ctx128_ef8_0824_probe_layer24_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "#     \"gemma-2-2b_sweep_standard_ctx128_ef2_0824_probe_layer_24_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "#     \"gemma-2-2b_sweep_topk_ctx128_ef2_0824_probe_layer_24_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# ae_sweep_paths = {\n",
    "#     \"gemma-2-2b_sweep_standard_ctx128_ef8_0824_probe_layer20_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "#     \"gemma-2-2b_sweep_topk_ctx128_ef8_0824_probe_layer20_results\": {\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "# }\n",
    "\n",
    "ae_sweep_paths = {\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824\": {\n",
    "        # \"resid_post_layer_11_checkpoints\": {\"trainer_ids\": trainer_ids},\n",
    "        \"resid_post_layer_15_checkpoints\": {\"trainer_ids\": trainer_ids},\n",
    "        \"resid_post_layer_19_checkpoints\": {\"trainer_ids\": trainer_ids},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "submodule_trainers = ae_sweep_paths[sweep_name]\n",
    "\n",
    "\n",
    "ae_paths = []\n",
    "\n",
    "for sweep_name, submodule_trainers in ae_sweep_paths.items():\n",
    "    ae_group_paths = utils.get_ae_group_paths(DICTIONARIES_PATH, sweep_name, submodule_trainers)\n",
    "    ae_paths.extend(utils.get_ae_paths(ae_group_paths))\n",
    "\n",
    "l0_loss_recovered_results = get_l0_frac_recovered(ae_paths)\n",
    "plotting_results = add_ae_config_results(ae_paths, l0_loss_recovered_results)\n",
    "\n",
    "filename_filter = \"\"\n",
    "\n",
    "l0_threshold = 500\n",
    "l0_threshold = None\n",
    "\n",
    "plotting_results = filter_by_l0_threshold(plotting_results, l0_threshold)\n",
    "\n",
    "title = \"L0 vs Fraction Recovered vs Sparsity Penalty\"\n",
    "\n",
    "custom_metric = \"l1_penalty\"\n",
    "\n",
    "plot_3var_graph(plotting_results, title, custom_metric)\n",
    "plot_interactive_3var_graph(plotting_results, custom_metric)\n",
    "\n",
    "# At this point, if there's any additional .json files located alongside the ae.pt and eval_results.json\n",
    "# You can easily adapt them to be included in the plotting_results dictionary by using something similar to add_ae_config_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ae_paths)\n",
    "\n",
    "# If not empty, this will filter to only include the specified class ids\n",
    "intended_filter_class_ids = [\"male / female\", \"professor / nurse\"]\n",
    "unintended_filter_class_ids = [\"male / female\", \"professor / nurse\"]\n",
    "# intended_filter_class_ids = [0, 1, 2, 6]\n",
    "# unintended_filter_class_ids = [0, 1, 2, 6]\n",
    "# intended_filter_class_ids = [\"male / female\"]\n",
    "# unintended_filter_class_ids = [1]\n",
    "# unintended_filter_class_ids = [-4]\n",
    "\n",
    "threshold = 0.1\n",
    "threshold = 20\n",
    "\n",
    "filename_filter = \"_attrib\"\n",
    "filename_filter = \"_auto_interp\"\n",
    "\n",
    "try:\n",
    "    results_acc = add_ablation_diff_plotting_dict(\n",
    "        ae_paths,\n",
    "        plotting_results,\n",
    "        threshold,\n",
    "        intended_filter_class_ids,\n",
    "        unintended_filter_class_ids,\n",
    "        filename_filter,\n",
    "        \"acc\",\n",
    "    )\n",
    "    # results_acc0 = add_ablation_diff_plotting_dict(\n",
    "    #     ae_paths,\n",
    "    #     plotting_results,\n",
    "    #     threshold,\n",
    "    #     intended_filter_class_ids,\n",
    "    #     unintended_filter_class_ids,\n",
    "    #     filename_counter,\n",
    "    #     \"loss\"\n",
    "    # )\n",
    "\n",
    "    # l0_threshold = None\n",
    "    # l0_threshold = 500\n",
    "\n",
    "    custom_metric1 = \"average_diff\"\n",
    "    custom_metric2 = \"average_intended_diff\"\n",
    "    custom_metric3 = \"average_unintended_diff\"\n",
    "\n",
    "    auto_interp_title = \"\"\n",
    "\n",
    "    if \"auto_interp\" in filename_filter:\n",
    "        auto_interp_title = \"\\n(Filtering features with auto-interp)\"\n",
    "\n",
    "    title = f\"\"\"Ablating Top {threshold} features from attribution patching.\n",
    "                    Color is (intended class difference - unintended class difference).{auto_interp_title}\"\"\"\n",
    "\n",
    "    # results_acc = filter_by_l0_threshold(results_acc, l0_threshold)\n",
    "    # results_acc0 = filter_by_l0_threshold(results_acc0, l0_threshold)\n",
    "\n",
    "    plot_3var_graph(results_acc, title, custom_metric1)\n",
    "    plot_interactive_3var_graph(results_acc, custom_metric1)\n",
    "    # plot_3var_graph(results_acc0, title, custom_metric1)\n",
    "    # plot_3var_graph(results, title, custom_metric3)\n",
    "except Exception as e:\n",
    "    print(\"Error plotting, possibly due to missing class accuracies file.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spurious_correlation_plotting_dict(\n",
    "    ae_paths: list[str],\n",
    "    threshold: float,\n",
    "    ablated_probe_class_id: str,\n",
    "    eval_probe_class_id: str,\n",
    "    eval_data_class_id: str,\n",
    "    filename_counter: str,\n",
    "    acc_key: str = \"acc\",\n",
    ") -> tuple[dict[str, dict[str, float]], float]:\n",
    "    results = {}\n",
    "    orig_acc = None\n",
    "\n",
    "    for ae_path in ae_paths:\n",
    "        eval_results_file = f\"{ae_path}/eval_results.json\"\n",
    "\n",
    "        if not os.path.exists(eval_results_file):\n",
    "            print(f\"Warning: {eval_results_file} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        with open(eval_results_file, \"r\") as f:\n",
    "            eval_results = json.load(f)\n",
    "\n",
    "        l0 = eval_results[\"l0\"]\n",
    "        frac_recovered = eval_results[\"frac_recovered\"]\n",
    "\n",
    "        results[ae_path] = {\n",
    "            \"l0\": l0,\n",
    "            \"frac_recovered\": frac_recovered,\n",
    "        }\n",
    "\n",
    "        config_file = f\"{ae_path}/config.json\"\n",
    "\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        trainer_class = config[\"trainer\"][\"trainer_class\"]\n",
    "        results[ae_path][\"trainer_class\"] = trainer_class\n",
    "        results[ae_path][\"l1_penalty\"] = get_sparsity_penalty(config, trainer_class)\n",
    "\n",
    "        results[ae_path][\"lr\"] = config[\"trainer\"][\"lr\"]\n",
    "        results[ae_path][\"dict_size\"] = config[\"trainer\"][\"dict_size\"]\n",
    "        if \"steps\" in config[\"trainer\"]:\n",
    "            results[ae_path][\"steps\"] = config[\"trainer\"][\"steps\"]\n",
    "\n",
    "        class_accuracies_file = f\"{ae_path}/class_accuracies{filename_counter}.pkl\"\n",
    "\n",
    "        if not os.path.exists(class_accuracies_file):\n",
    "            print(\n",
    "                f\"Warning: {class_accuracies_file} does not exist. Removing this path from results.\"\n",
    "            )\n",
    "            del results[ae_path]\n",
    "            continue\n",
    "\n",
    "        with open(class_accuracies_file, \"rb\") as f:\n",
    "            class_accuracies = pickle.load(f)\n",
    "\n",
    "        # for class_id in class_accuracies['clean_acc']:\n",
    "        #     print(class_id, class_accuracies['clean_acc'][class_id])\n",
    "\n",
    "        combined_class_name = f\"{eval_probe_class_id} probe on {eval_data_class_id} data\"\n",
    "\n",
    "        original_acc = class_accuracies[\"clean_acc\"][combined_class_name][\"acc\"]\n",
    "        if orig_acc is None:\n",
    "            orig_acc = original_acc\n",
    "        print(f\"Original acc: {original_acc}\")\n",
    "\n",
    "        changed_acc = class_accuracies[ablated_probe_class_id][threshold][combined_class_name][\n",
    "            acc_key\n",
    "        ]\n",
    "\n",
    "        results[ae_path][\"average_diff\"] = changed_acc\n",
    "    return results, orig_acc\n",
    "\n",
    "\n",
    "ablated_probe_class_id = \"male / female\"\n",
    "# ablated_probe_class_id = \"professor / nurse\"\n",
    "# ablated_probe_class_id = \"male_professor / female_nurse\"\n",
    "eval_probe_class_id = \"male_professor / female_nurse\"\n",
    "eval_probe_class_id = \"male_professor / female_nurse\"\n",
    "eval_probe_class_id = \"biased_male / biased_female\"\n",
    "# ablated_probe_class_id = eval_probe_class_id\n",
    "eval_data_class_id = \"professor / nurse\"\n",
    "eval_data_class_id = \"male / female\"\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "filename_filter = \"_attrib\"\n",
    "# filename_filter = \"_auto_interp\"\n",
    "# filename_filter = \"_bias_shift_dir2\"\n",
    "\n",
    "attrib_dir = 2\n",
    "\n",
    "if  \"_bias_shift\" in filename_filter:\n",
    "    ablated_probe_class_id = eval_probe_class_id\n",
    "\n",
    "    if filename_filter == \"_bias_shift_dir1\":\n",
    "        title = f\"\"\"Ablating Top {threshold} gender features to increase profession accuracy.\"\"\"\n",
    "        eval_data_class_id = \"professor / nurse\"\n",
    "    elif filename_filter == \"_bias_shift_dir2\":\n",
    "        title = f\"\"\"Ablating Top {threshold} profession features to increase gender accuracy.\"\"\"\n",
    "        eval_data_class_id = \"male / female\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filename filter.\")\n",
    "    title += \"\\nFiltering features with auto-interp.\"\n",
    "else:\n",
    "    if attrib_dir == 1:\n",
    "        ablated_probe_class_id = \"male / female\"\n",
    "        eval_data_class_id = \"professor / nurse\"\n",
    "        title = f\"\"\"Ablating Top {threshold} gender features to increase profession accuracy.\"\"\"\n",
    "    elif attrib_dir == 2:\n",
    "        ablated_probe_class_id = \"professor / nurse\"\n",
    "        eval_data_class_id = \"male / female\"\n",
    "        title = f\"\"\"Ablating Top {threshold} profession features to increase gender accuracy.\"\"\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid attrib_dir.\")\n",
    "\n",
    "\n",
    "\n",
    "spurious_correlation_results, original_acc = get_spurious_correlation_plotting_dict(\n",
    "    ae_paths,\n",
    "    threshold,\n",
    "    ablated_probe_class_id,\n",
    "    eval_probe_class_id,\n",
    "    eval_data_class_id,\n",
    "    filename_filter,\n",
    "    \"acc\",\n",
    ")\n",
    "\n",
    "# title += f\"\\nOriginal Accuracy: {original_acc:.4f}\"\n",
    "\n",
    "l0_threshold = None\n",
    "# l0_threshold = 500\n",
    "\n",
    "custom_metric1 = \"average_diff\"\n",
    "\n",
    "spurious_correlation_results = filter_by_l0_threshold(spurious_correlation_results, l0_threshold)\n",
    "\n",
    "plot_3var_graph(\n",
    "    spurious_correlation_results, title, custom_metric1, colorbar_label=\"Probe Accuracy\"\n",
    ")\n",
    "plot_interactive_3var_graph(spurious_correlation_results, custom_metric1)\n",
    "# plot_3var_graph(results_acc0, title, custom_metric1)\n",
    "# plot_3var_graph(results, title, custom_metric3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_steps_vs_average_diff(\n",
    "    results_dict: dict,\n",
    "    steps_key: str = \"steps\",\n",
    "    avg_diff_key: str = \"average_diff\",\n",
    "    title: Optional[str] = None,\n",
    "    y_label: Optional[str] = None,\n",
    "):\n",
    "    # Initialize a defaultdict to store data for each trainer\n",
    "    trainer_data = defaultdict(lambda: {'steps': [], 'average_diffs': []})\n",
    "\n",
    "    all_steps = set()\n",
    "\n",
    "    # Extract data from the dictionary\n",
    "    for key, value in results_dict.items():\n",
    "        # Extract trainer number from the key\n",
    "        trainer = key.split('/')[-1].split('_')[1]  # Assuming format like \"trainer_1_...\"\n",
    "        layer = key.split('/')[-2].split('_')[-2]\n",
    "        step = int(value[steps_key])\n",
    "        avg_diff = value[avg_diff_key]\n",
    "\n",
    "        trainer_key = f\"Layer {layer} Trainer {trainer}\"\n",
    "\n",
    "        trainer_data[trainer_key]['steps'].append(step)\n",
    "        trainer_data[trainer_key]['average_diffs'].append(avg_diff)\n",
    "        all_steps.add(step)\n",
    "\n",
    "    # Calculate average across all trainers\n",
    "    average_trainer_data = {'steps': [], 'average_diffs': []}\n",
    "    for step in sorted(all_steps):\n",
    "        step_diffs = []\n",
    "        for data in trainer_data.values():\n",
    "            if step in data['steps']:\n",
    "                idx = data['steps'].index(step)\n",
    "                step_diffs.append(data['average_diffs'][idx])\n",
    "        if step_diffs:\n",
    "            average_trainer_data['steps'].append(step)\n",
    "            average_trainer_data['average_diffs'].append(np.mean(step_diffs))\n",
    "\n",
    "    # Add average_trainer_data to trainer_data\n",
    "    trainer_data['Average'] = average_trainer_data\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot data for each trainer\n",
    "    for trainer_key, data in trainer_data.items():\n",
    "        steps = data['steps']\n",
    "        average_diffs = data['average_diffs']\n",
    "\n",
    "        # Sort the data by steps to ensure proper ordering\n",
    "        sorted_data = sorted(zip(steps, average_diffs))\n",
    "        steps, average_diffs = zip(*sorted_data)\n",
    "\n",
    "        # Find the maximum step value for this trainer\n",
    "        max_step = max(steps)\n",
    "\n",
    "        # Convert steps to percentages of max_step\n",
    "        step_percentages = [step / max_step * 100 for step in steps]\n",
    "\n",
    "        # Plot the line for this trainer\n",
    "        if trainer_key == 'Average':\n",
    "            plt.plot(step_percentages, average_diffs, marker=\"o\", label=trainer_key, \n",
    "                     linewidth=3, color='red', zorder=10)  # Emphasized average line\n",
    "        else:\n",
    "            plt.plot(step_percentages, average_diffs, marker=\"o\", label=trainer_key, \n",
    "                     alpha=0.3, linewidth=1)  # More transparent individual lines\n",
    "\n",
    "    if not title:\n",
    "        title = f'{steps_key.capitalize()} vs {avg_diff_key.replace(\"_\", \" \").capitalize()}'\n",
    "\n",
    "    if not y_label:\n",
    "        y_label = avg_diff_key.replace(\"_\", \" \").capitalize()\n",
    "\n",
    "    plt.xlabel(\"Checkpoint at x% of SAE training run\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)  # More transparent grid\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    # Adjust layout to prevent clipping of tick-labels\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# checkpoints_title = \"Training steps vs Decrease in Probe Accuracy\"\n",
    "y_label = \"Probe Accuracy Decrease\"\n",
    "\n",
    "# try:\n",
    "#     plot_steps_vs_average_diff(plotting_results, title=checkpoints_title, y_label=y_label)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error plotting: {e}\")\n",
    "\n",
    "print(f\"Original acc: {original_acc}\")\n",
    "\n",
    "# If your keys are different, you can specify them:\n",
    "plot_steps_vs_average_diff(\n",
    "    spurious_correlation_results,\n",
    "    steps_key=\"steps\",\n",
    "    avg_diff_key=custom_metric1,\n",
    "    title=title,\n",
    "    y_label=y_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tpp_title = f\"Decrease in probe accuracy for Targeted Probe Perturbation\"\n",
    "\n",
    "# plot_steps_vs_average_diff(\n",
    "#     results_acc,\n",
    "#     steps_key=\"steps\",\n",
    "#     avg_diff_key=custom_metric1,\n",
    "#     title=tpp_title,\n",
    "#     y_label=y_label,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_dictionaries_path = DICTIONARIES_PATH\n",
    "DICTIONARIES_PATH = \"../dictionary_learning/dictionaries/spurious_attrib_results\"\n",
    "\n",
    "\n",
    "def average_multiple_runs(\n",
    "    ae_group_path: str,\n",
    "    probe_layer: int,\n",
    "    column1_vals_list: list[tuple[str, str]],\n",
    "    threshold: float | int,\n",
    "    ablated_probe_class_id: str,\n",
    "    eval_probe_class_id: str,\n",
    "    eval_data_class_id: str,\n",
    "    filename_counter: str,\n",
    "    filters: list[str],\n",
    "    acc_key: str = \"acc\",\n",
    "    intervention_type: str = \"spurious\",\n",
    "    dataset: str = \"bias_in_bios\",\n",
    ") -> dict:\n",
    "    ae_base_path = f\"{ae_group_path}_probe_layer_{probe_layer}_{intervention_type}_{dataset}\"\n",
    "    ae_output_path = f\"{ae_group_path}\"\n",
    "\n",
    "    all_results = {}\n",
    "    original_accs = []\n",
    "\n",
    "    for column1_vals in column1_vals_list:\n",
    "        ae_run_path = f\"{ae_base_path}_{column1_vals[0]}_{column1_vals[1]}\"\n",
    "        sweep_name = ae_run_path\n",
    "        submodule_trainers = None\n",
    "        ae_group_paths = utils.get_ae_group_paths(DICTIONARIES_PATH, sweep_name, submodule_trainers)\n",
    "        ae_paths = utils.get_ae_paths(ae_group_paths)\n",
    "\n",
    "        temp_results, orig_acc = get_spurious_correlation_plotting_dict(\n",
    "            ae_paths,\n",
    "            threshold,\n",
    "            ablated_probe_class_id,\n",
    "            eval_probe_class_id,\n",
    "            eval_data_class_id,\n",
    "            filename_counter,\n",
    "            acc_key,\n",
    "        )\n",
    "\n",
    "        all_results.update(temp_results)\n",
    "        original_accs.append(orig_acc)\n",
    "\n",
    "    final_results = {}\n",
    "\n",
    "    average_orig_acc = sum(original_accs) / len(original_accs)\n",
    "\n",
    "    for ae_path in all_results:\n",
    "\n",
    "        skip_path = False\n",
    "        for filter in filters:\n",
    "            if filter in ae_path:\n",
    "                skip_path = True\n",
    "                break\n",
    "\n",
    "        if skip_path:\n",
    "            continue\n",
    "\n",
    "        orig_ae_path = ae_path\n",
    "        name_fixed = False\n",
    "        for column1_vals in column1_vals_list:\n",
    "            ae_run_path = f\"{ae_base_path}_{column1_vals[0]}_{column1_vals[1]}\"\n",
    "            if ae_run_path in ae_path:\n",
    "                ae_path = ae_path.replace(ae_run_path, ae_output_path)\n",
    "                name_fixed = True\n",
    "        assert name_fixed\n",
    "\n",
    "        if ae_path not in final_results:\n",
    "            final_results[ae_path] = all_results[orig_ae_path]\n",
    "        else:\n",
    "            final_results[ae_path][\"average_diff\"] += all_results[orig_ae_path][\"average_diff\"]\n",
    "\n",
    "    for ae_path in final_results:\n",
    "        final_results[ae_path][\"average_diff\"] /= len(column1_vals_list)\n",
    "\n",
    "    return final_results, average_orig_acc\n",
    "\n",
    "\n",
    "ae_group_paths = [\n",
    "    \"gemma-2-2b_sweep_topk_ctx128_ef8_0824\",\n",
    "    \"gemma-2-2b_sweep_standard_ctx128_ef8_0824\",\n",
    "]\n",
    "probe_layers = [15, 19]\n",
    "column1_vals_list = [\n",
    "    (\"professor\", \"nurse\"),\n",
    "    (\"filmmaker\", \"dentist\"),\n",
    "    (\"painter\", \"teacher\"),\n",
    "    (\"photographer\", \"physician\"),\n",
    "]\n",
    "\n",
    "filters = [\"trainer_5\"]\n",
    "# filters = []\n",
    "\n",
    "averaged_results, average_orig_acc = average_multiple_runs(\n",
    "    ae_group_paths[0],\n",
    "    probe_layers[0],\n",
    "    column1_vals_list,\n",
    "    threshold,\n",
    "    ablated_probe_class_id,\n",
    "    eval_probe_class_id,\n",
    "    eval_data_class_id,\n",
    "    filename_filter,\n",
    "    filters,\n",
    ")\n",
    "\n",
    "print(average_orig_acc)\n",
    "\n",
    "DICTIONARIES_PATH = prev_dictionaries_path\n",
    "\n",
    "plot_3var_graph(\n",
    "    averaged_results, title, custom_metric1, colorbar_label=\"Probe Accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_steps_vs_average_diff(\n",
    "    averaged_results,\n",
    "    steps_key=\"steps\",\n",
    "    avg_diff_key=custom_metric1,\n",
    "    title=title,\n",
    "    y_label=y_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
