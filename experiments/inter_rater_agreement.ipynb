{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_manual_labels_json(file_path: str) -> Dict:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = {int(k): v for k, v in data.items()}\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_llm_pkl(file_path: str) -> Dict:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        llm_file = pickle.load(f)\n",
    "\n",
    "    llm_file = {int(k): v for k, v in llm_file.items()}\n",
    "    return llm_file\n",
    "\n",
    "\n",
    "file1 = \"llm_autointerp/manual_labels_can_final.json\"\n",
    "file2 = \"llm_autointerp/llm_results.pkl\"\n",
    "\n",
    "manual_file = load_manual_labels_json(file1)\n",
    "\n",
    "llm_file = load_llm_pkl(file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = list(llm_file.keys())[1]\n",
    "\n",
    "print(f\"##### Example Prompts\\n {manual_file[sample_idx]['example_prompts'][0]}\\n\\n\")\n",
    "print(f\"##### Manual chain of thought\\n{manual_file[sample_idx]['chain_of_thought']}\\n\\n\")\n",
    "print(f\"##### LLM chain of thought\\n{llm_file[sample_idx][0]}\\n\\n\")\n",
    "print(f\"manual labels {manual_file[sample_idx]['per_class_scores']}\")\n",
    "print(f\"LLM labels    {llm_file[sample_idx][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scores_manual(data: Dict, is_valid: List[bool]) -> Dict[str, List[int]]:\n",
    "    manual_labels = {}\n",
    "    for idx in sorted(data.keys()):\n",
    "        idx = int(idx)\n",
    "        item = data[idx]\n",
    "        if idx >= len(is_valid):\n",
    "            continue\n",
    "        if is_valid[idx]:\n",
    "            for category, score in item[\"per_class_scores\"].items():\n",
    "                if category not in manual_labels:\n",
    "                    manual_labels[category] = []\n",
    "                manual_labels[category].append(score)\n",
    "    return manual_labels\n",
    "\n",
    "\n",
    "def extract_scores_llm(data: List[Tuple[str, Dict[str, int], bool, str]]) -> Dict[str, List[int]]:\n",
    "    is_valid = []\n",
    "    result = {}\n",
    "    for idx in sorted(data.keys()):\n",
    "        idx_results = data[idx]\n",
    "        scores = idx_results[1]  # The scores dictionary is the second element of each tuple\n",
    "        if scores is None:\n",
    "            is_valid.append(False)\n",
    "        else:\n",
    "            is_valid.append(True)\n",
    "            for category, score in scores.items():\n",
    "                if category not in result:\n",
    "                    result[category] = []\n",
    "                result[category].append(score)\n",
    "    return result, is_valid\n",
    "\n",
    "\n",
    "def extract_paired_llm_manual_scores(\n",
    "    llm_data: dict[int, tuple[str, dict[str, int], bool, str]],\n",
    "    manual_data: dict[int, dict],\n",
    ") -> dict[str, list[int]]:\n",
    "    is_valid = []\n",
    "    llm_results_per_class = {}\n",
    "    manual_results_per_class = {}\n",
    "\n",
    "    for idx in sorted(llm_data.keys()):\n",
    "        llm_results = llm_data[idx]\n",
    "        manual_labels = manual_data[idx]\n",
    "\n",
    "        llm_scores = llm_results[1]  # The scores dictionary is the second element of each tuple\n",
    "        manual_scores = manual_labels[\"per_class_scores\"]\n",
    "\n",
    "        if llm_scores is None:\n",
    "            is_valid.append(False)\n",
    "        else:\n",
    "            is_valid.append(True)\n",
    "            for category in llm_scores.keys():\n",
    "                if category not in llm_results_per_class:\n",
    "                    llm_results_per_class[category] = []\n",
    "                    manual_results_per_class[category] = []\n",
    "                llm_results_per_class[category].append(llm_scores[category])\n",
    "                manual_results_per_class[category].append(manual_scores[category])\n",
    "    return llm_results_per_class, manual_results_per_class, is_valid\n",
    "\n",
    "\n",
    "# llm_labels, is_valid = extract_scores_llm(llm_file)\n",
    "# manual_labels = extract_scores_manual(manual_file, is_valid)\n",
    "\n",
    "llm_labels, manual_labels, is_valid = extract_paired_llm_manual_scores(llm_file, manual_file)\n",
    "\n",
    "test_key = \"dentist\"\n",
    "\n",
    "print(llm_labels[test_key][:])\n",
    "print(manual_labels[test_key][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_kappa(scores1: Dict[str, List[int]], scores2: Dict[str, List[int]]) -> Dict[str, float]:\n",
    "    def kappa(a: np.ndarray, b: np.ndarray) -> float:\n",
    "        n = len(a)\n",
    "        categories = np.unique(np.concatenate([a, b]))\n",
    "        n_categories = len(categories)\n",
    "\n",
    "        # Observed agreement\n",
    "        observed = np.sum(a == b) / n\n",
    "\n",
    "        # Expected agreement\n",
    "        expected = sum((np.sum(a == i) / n) * (np.sum(b == i) / n) for i in categories)\n",
    "\n",
    "        # Compute kappa\n",
    "        kappa = (observed - expected) / (1 - expected + EPS)\n",
    "        return kappa\n",
    "\n",
    "    results = {}\n",
    "    for category in scores1.keys():\n",
    "        a = np.array(scores1[category])\n",
    "        b = np.array(scores2[category])\n",
    "        results[category] = kappa(a, b)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def compute_kappa_for_files(file1: str, file2: str) -> Dict[str, float]:\n",
    "    manual_labels = load_manual_labels_json(file1)\n",
    "    llm_labels = load_llm_pkl(file2)\n",
    "\n",
    "    print(f\"Length of manual labels: {len(manual_labels)}\")\n",
    "    print(f\"Length of LLM labels: {len(llm_labels)}\")\n",
    "\n",
    "    # Find overlapping keys\n",
    "    # overlap = set(data1.keys()) & set(data2.keys())\n",
    "    # print(f'Number of shared keys: {len(overlap)}')\n",
    "    # data1_overlap, data2_overlap = {}, {}\n",
    "    # for key in overlap:\n",
    "    #     data1_overlap[key] = data1[key]\n",
    "    #     data2_overlap[key] = data2[key]\n",
    "\n",
    "    llm_labels, manual_labels, is_valid_llm_output = extract_paired_llm_manual_scores(llm_file, manual_file)\n",
    "\n",
    "    print(f\"Number of invalid valid scores: {len(is_valid_llm_output) - sum(is_valid_llm_output)}\")\n",
    "\n",
    "    return cohens_kappa(llm_labels, manual_labels)\n",
    "\n",
    "\n",
    "scores = cohens_kappa(llm_labels, manual_labels)\n",
    "for class_name in scores:\n",
    "    print(f\"{class_name}: {scores[class_name]:.4f}\")\n",
    "# kappa_scores = compute_kappa_for_files(file1, file2)\n",
    "\n",
    "# print(\"Cohen's Kappa scores for each category:\")\n",
    "# for category, score in kappa_scores.items():\n",
    "#     print(f\"{category}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzeros = {\"llm\": {}, \"manual\": {}}\n",
    "\n",
    "for category in llm_labels.keys():\n",
    "    nonzero_llm = 0\n",
    "    nonzero_manual = 0\n",
    "\n",
    "    for llm_score, manual_score in zip(llm_labels[category], manual_labels[category]):\n",
    "        if llm_score > 0:\n",
    "            nonzero_llm += 1\n",
    "        if manual_score > 0:\n",
    "            nonzero_manual += 1\n",
    "    print(category, nonzero_llm, nonzero_manual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
