{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_manual_labels_json(file_path: str) -> Dict:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    data = {int(k): v for k, v in data.items()}\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_llm_pkl(file_path: str) -> Dict:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        llm_file = pickle.load(f)\n",
    "\n",
    "    llm_dict = {}\n",
    "\n",
    "    for _, value in enumerate(llm_file):\n",
    "        sample_idx = int(value[0])\n",
    "        results = value[1:]\n",
    "        llm_dict[sample_idx] = results\n",
    "\n",
    "    return llm_dict\n",
    "\n",
    "\n",
    "file1 = \"llm_autointerp/manual_labels_can_final.json\"\n",
    "file2 = \"llm_autointerp/llm_results.pkl\"\n",
    "\n",
    "manual_file = load_manual_labels_json(file1)\n",
    "\n",
    "llm_file = load_llm_pkl(file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([63, 13, 9, 4, 17, 2, 65, 53, 1, 15, 27, 67, 69, 59, 87, 47, 85, 81, 71, 31, 21, 45, 83, 37, 33, 57, 35, 51, 11, 55, 3, 75, 49, 19, 73, 77, 0, 79, 39, 41, 89, 7, 6, 29, 8, 23, 61, 25, 43, 5])\n"
     ]
    }
   ],
   "source": [
    "print(llm_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Example Prompts\n",
      " \n",
      "\n",
      "\n",
      "Example 1: a variance to permit construction of the << dental>>(4) << office>>(1) by the Marion County Board of Zoning Appeals.\n",
      "Subsequently on September 11, 1959, the Director of the Metropolitan Planning Department filed an affidavit to appeal said decision to the Metropolitan Board of Zoning Appeals, as authorized by statute.\n",
      "\"53-969. Petitions for variance. Â— The city and county board of zoning appeals and the metropolitan board of zoning appeals are hereby authorized to grant height, bulk, area and use variances in the manner hereinafter set forth. Both city or county board of zoning appeals and the metropolitan board of zoning appeals may grant petitions for variance in their entirety or in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 2: eliminate << dental>>(4), << vision>>(1) and << pharmacy>>(0) benefits for low-income adults.\n",
      "\n",
      "The Trump administration had argued Obama's Medicaid expansion essentially created a new program under Medicaid. Allowing states to cover low-income adults with no children living at home changed the nature of the program, the administration asserted, and opened the way for provisions such as work requirements.\n",
      "\n",
      "The national implications of Friday's ruling could take a while to sort out. Officials in Arkansas have already implemented similar work requirement rules there.\n",
      "\n",
      "The drive to expand Medicaid in GOP-led states had gotten a boost from the prospect of work requirements, which appeal to conservatives\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 3: a picture of the patient\\'s facial profiles onto the soft tissue on the 3D-CT images. The asymmetry was improved in the front and lower areas, including the facial profile, following the surgery simulation.\n",
      "\n",
      "The reduction of the << mandibular>>(2) width was measured, upon confirming the precise occlusal relationship after osteotomy, by optical scanning of the << dental>>(4) cast to link the data to the 3D-CT images.\n",
      "\n",
      "Cant correction and yaw correction were implemented in the maxilla with a LeFort I osteotomy, and the right << molar>>(2) << tooth>>(4) was << impacted>>(0) in the upper area, resulting in complete down fracture, while Piezo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 4: An in vitro microleakage study of three restorative techniques for Class II restorations in posterior << teeth>>(4).\n",
      "Microleakage associated with a silver reinforced restorative glass ionomer cement used alone and also as a laminate restoration with a composite resin and << dent>>(2)ine adhesive in extracted premolar and << molar>>(2) << teeth>>(4) was evaluated. The influence of artificial saliva, thermal and load cycling was also determined. The composite and dentine adhesive alone were used for comparative purposes. The results showed that the composite resin/ <<dent>>(2)ine adhesive restorations showed substantial microleakage at both the cervical and occlusal margins of the Class II\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 5: that the, \"Self-induced vomiting seen in both anorexia nervosa and bulimia nervosa can lead to swelling of << salivary>>(2) glands, electrolyte and mineral disturbances, and << dental>>(4) << enamel>>(3) erosion.\" In addition, \"rarer complications\" include \"tearing [of] the esophagus, rupturing of the stomach, and life-threatening irregularities of the heart rhythm.\"\n",
      "\n",
      "Possible causes\n",
      "According to Cassell and Gleaves, \"biological, psychological, [and] social factors\" all play a role in the development of an eating << disorder>>(0). In their Introduction, they note that, \"In addition to core eating\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 6: MCRCF was among the best prisons he had seen, but he expressed a concern that if as many as 800 men came to be housed there, \"it will become one of the more dangerous places to work and live in.\" Nevertheless, as previously noted, MCRCF, as well as BCRCF and LCRCF have thus far been among the least violent of TDOC's adult institutions.\n",
      "\n",
      "5. MCRCF Health Care\n",
      "MCRCF, a facility which opened in 1980, contains a small clinic with a two-table examination room, a << dental>>(4) room, a room with a bed for short-term use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 7: Punisher had become such an incredibly popular character, the Code had already become << tooth>>(4)less in many ways. The Punisher was one of the most violent comics on the stands, and the very basic premise of the character as anything other than - repeat after me - a villain (which is essentially what the character had been, a few gritty appearances in Marvel's short-lived black & white magazines notwithstanding), sort of went against the grain of the entire Marvel Universe. Or at least the conception of Marvel as a publishing company whose entire mainline was theoretically fit for kids aged 8 to 80.\n",
      "\n",
      "So despite the character's unquest\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 8: a first aperture spaced from a second aperture by a first distance; a second link member connected to the first link member and having a first toe spaced from a second toe by a second distance, the toes being adapted for engagement with << tooth>>(3) spaces associated with a sprocket, the << tooth>>(3) spaces being spaced apart by a third distance; and the second distance being substantially equal to the third distance, and the second distance being about one half of the first distance.\n",
      "In accordance with yet another aspect of the present invention, a chain system is disclosed. The chain system includes a first sprocket having a first plurality of << tooth>>(3) spaces spaced apart by a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 9: or incentives, were among the most approximately planted next survivors in both europe and north america. Enhanced stature and election, with local non-criminal crisis and significant harmful policy.\n",
      "\n",
      "The mid-nineteenth difficulties are exposed for 48 songs under likely balloons with five works of the public records official county of san diego deh. In film to the scheme of preferential how to start a background check company on someone without them knowing, significantly administered camera << teeth>>(3) are well used when examining the culture. One public records database bexar county district clerk criminal claimed that he and his goods had back been informed of large built-in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 10: 40 F.3d 698, 712-13 (5th Cir.1994). The Court must consider all evidence in the light most favorable to the nonmoving party. See Id. at 713.\n",
      "Facts\n",
      "On October 4, 2002, Olivas, while housed at the Mineral Wells unit, damaged two << teeth>>(3) when a locker lid fell, striking him in the << mouth>>(1). Olivas testified that he reported this to an officer, who told him to fill out a sick-call request, which Olivas completed the next day and submitted on October 6th. Olivas also maintains he told another officer, Chris Little,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##### Manual chain of thought\n",
      "The top promoted logits are related to tooth care.\n",
      "The activating inputs are coherently related to dentists.\n",
      "I will rate the dentist class as a 4.\n",
      "\n",
      "\n",
      "##### LLM chain of thought\n",
      "Step 1. The neuron appears to activate strongly on words related to dentistry, particularly \"dental\" and \"teeth\".\n",
      "\n",
      "Step 2. Scoring the neuron's behavior for each concept:\n",
      "\n",
      "Gender: The neuron does not show any clear relation to gender. Score: 0\n",
      "\n",
      "Professor: There is no evidence of the neuron relating to professors. Score: 0\n",
      "\n",
      "Nurse: While healthcare-related, the neuron doesn't specifically relate to nurses. Score: 0\n",
      "\n",
      "Accountant: No relation to accountants is evident. Score: 0\n",
      "\n",
      "Architect: There's no connection to architects or architecture. Score: 0\n",
      "\n",
      "Attorney: One example mentions a zoning appeal, but this seems incidental. Score: 0\n",
      "\n",
      "Dentist: The neuron strongly activates on words directly related to dentistry, such as \"dental\", \"teeth\", \"enamel\", and \"molar\". This is the clearest and most consistent pattern. Score: 4\n",
      "\n",
      "Filmmaker: No relation to filmmaking is apparent. Score: 0\n",
      "\n",
      "```json\n",
      "{\"gender\": 0, \"professor\": 0, \"nurse\": 0, \"accountant\": 0, \"architect\": 0, \"attorney\": 0, \"dentist\": 4, \"filmmaker\": 0}\n",
      "```\n",
      "\n",
      "\n",
      "manual labels {'gender': 0, 'professor': 0, 'nurse': 0, 'accountant': 0, 'architect': 0, 'attorney': 0, 'dentist': 4, 'filmmaker': 0}\n",
      "LLM labels    {'gender': 0, 'professor': 0, 'nurse': 0, 'accountant': 0, 'architect': 0, 'attorney': 0, 'dentist': 4, 'filmmaker': 0}\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 1\n",
    "\n",
    "print(f\"##### Example Prompts\\n {manual_file[sample_idx]['example_prompts'][0]}\\n\\n\")\n",
    "print(f\"##### Manual chain of thought\\n{manual_file[sample_idx]['chain_of_thought']}\\n\\n\")\n",
    "print(f\"##### LLM chain of thought\\n{llm_file[sample_idx][0]}\\n\\n\")\n",
    "print(f\"manual labels {manual_file[sample_idx]['per_class_scores']}\")\n",
    "print(f\"LLM labels    {llm_file[sample_idx][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def extract_scores_manual(data: Dict, is_valid: List[bool]) -> Dict[str, List[int]]:\n",
    "    manual_labels = {}\n",
    "    for idx in sorted(data.keys()):\n",
    "        idx = int(idx)\n",
    "        item = data[idx]\n",
    "        if idx >= len(is_valid):\n",
    "            continue\n",
    "        if is_valid[idx]:\n",
    "            for category, score in item[\"per_class_scores\"].items():\n",
    "                if category not in manual_labels:\n",
    "                    manual_labels[category] = []\n",
    "                manual_labels[category].append(score)\n",
    "    return manual_labels\n",
    "\n",
    "\n",
    "def extract_scores_llm(data: List[Tuple[str, Dict[str, int], bool, str]]) -> Dict[str, List[int]]:\n",
    "    is_valid = []\n",
    "    result = {}\n",
    "    for idx in sorted(data.keys()):\n",
    "        idx_results = data[idx]\n",
    "        scores = idx_results[1]  # The scores dictionary is the second element of each tuple\n",
    "        if scores is None:\n",
    "            is_valid.append(False)\n",
    "        else:\n",
    "            is_valid.append(True)\n",
    "            for category, score in scores.items():\n",
    "                if category not in result:\n",
    "                    result[category] = []\n",
    "                result[category].append(score)\n",
    "    return result, is_valid\n",
    "\n",
    "\n",
    "def extract_paired_llm_manual_scores(\n",
    "    llm_data: dict[int, tuple[str, dict[str, int], bool, str]],\n",
    "    manual_data: dict[int, dict],\n",
    ") -> dict[str, list[int]]:\n",
    "    is_valid = []\n",
    "    llm_results_per_class = {}\n",
    "    manual_results_per_class = {}\n",
    "\n",
    "    for idx in sorted(llm_data.keys()):\n",
    "        llm_results = llm_data[idx]\n",
    "        manual_labels = manual_data[idx]\n",
    "\n",
    "        llm_scores = llm_results[1]  # The scores dictionary is the second element of each tuple\n",
    "        manual_scores = manual_labels[\"per_class_scores\"]\n",
    "\n",
    "        if llm_scores is None:\n",
    "            is_valid.append(False)\n",
    "        else:\n",
    "            is_valid.append(True)\n",
    "            for category in llm_scores.keys():\n",
    "                if category not in llm_results_per_class:\n",
    "                    llm_results_per_class[category] = []\n",
    "                    manual_results_per_class[category] = []\n",
    "                llm_results_per_class[category].append(llm_scores[category])\n",
    "                manual_results_per_class[category].append(manual_scores[category])\n",
    "    return llm_results_per_class, manual_results_per_class, is_valid\n",
    "\n",
    "\n",
    "# llm_labels, is_valid = extract_scores_llm(llm_file)\n",
    "# manual_labels = extract_scores_manual(manual_file, is_valid)\n",
    "\n",
    "llm_labels, manual_labels, is_valid = extract_paired_llm_manual_scores(llm_file, manual_file)\n",
    "\n",
    "test_key = \"dentist\"\n",
    "\n",
    "print(llm_labels[test_key][:])\n",
    "print(manual_labels[test_key][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: 0.5452\n",
      "professor: 0.6449\n",
      "nurse: -0.0208\n",
      "accountant: 0.1929\n",
      "architect: 0.0000\n",
      "attorney: 0.6390\n",
      "dentist: 1.0000\n",
      "filmmaker: 0.3758\n"
     ]
    }
   ],
   "source": [
    "def cohens_kappa(scores1: Dict[str, List[int]], scores2: Dict[str, List[int]]) -> Dict[str, float]:\n",
    "    def kappa(a: np.ndarray, b: np.ndarray) -> float:\n",
    "        n = len(a)\n",
    "        categories = np.unique(np.concatenate([a, b]))\n",
    "        n_categories = len(categories)\n",
    "\n",
    "        # Observed agreement\n",
    "        observed = np.sum(a == b) / n\n",
    "\n",
    "        # Expected agreement\n",
    "        expected = sum((np.sum(a == i) / n) * (np.sum(b == i) / n) for i in categories)\n",
    "\n",
    "        # Compute kappa\n",
    "        kappa = (observed - expected) / (1 - expected + EPS)\n",
    "        return kappa\n",
    "\n",
    "    results = {}\n",
    "    for category in scores1.keys():\n",
    "        a = np.array(scores1[category])\n",
    "        b = np.array(scores2[category])\n",
    "        results[category] = kappa(a, b)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def compute_kappa_for_files(file1: str, file2: str) -> Dict[str, float]:\n",
    "    manual_labels = load_manual_labels_json(file1)\n",
    "    llm_labels = load_llm_pkl(file2)\n",
    "\n",
    "    print(f\"Length of manual labels: {len(manual_labels)}\")\n",
    "    print(f\"Length of LLM labels: {len(llm_labels)}\")\n",
    "\n",
    "    # Find overlapping keys\n",
    "    # overlap = set(data1.keys()) & set(data2.keys())\n",
    "    # print(f'Number of shared keys: {len(overlap)}')\n",
    "    # data1_overlap, data2_overlap = {}, {}\n",
    "    # for key in overlap:\n",
    "    #     data1_overlap[key] = data1[key]\n",
    "    #     data2_overlap[key] = data2[key]\n",
    "\n",
    "    llm_labels, manual_labels, is_valid_llm_output = extract_paired_llm_manual_scores(llm_file, manual_file)\n",
    "\n",
    "    print(f\"Number of invalid valid scores: {len(is_valid_llm_output) - sum(is_valid_llm_output)}\")\n",
    "\n",
    "    return cohens_kappa(llm_labels, manual_labels)\n",
    "\n",
    "\n",
    "scores = cohens_kappa(llm_labels, manual_labels)\n",
    "for class_name in scores:\n",
    "    print(f\"{class_name}: {scores[class_name]:.4f}\")\n",
    "# kappa_scores = compute_kappa_for_files(file1, file2)\n",
    "\n",
    "# print(\"Cohen's Kappa scores for each category:\")\n",
    "# for category, score in kappa_scores.items():\n",
    "#     print(f\"{category}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender 9 11\n",
      "professor 4 5\n",
      "nurse 2 2\n",
      "accountant 2 7\n",
      "architect 2 0\n",
      "attorney 7 5\n",
      "dentist 2 2\n",
      "filmmaker 7 7\n"
     ]
    }
   ],
   "source": [
    "nonzeros = {\"llm\": {}, \"manual\": {}}\n",
    "\n",
    "for category in llm_labels.keys():\n",
    "    nonzero_llm = 0\n",
    "    nonzero_manual = 0\n",
    "\n",
    "    for llm_score, manual_score in zip(llm_labels[category], manual_labels[category]):\n",
    "        if llm_score > 0:\n",
    "            nonzero_llm += 1\n",
    "        if manual_score > 0:\n",
    "            nonzero_manual += 1\n",
    "    print(category, nonzero_llm, nonzero_manual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
