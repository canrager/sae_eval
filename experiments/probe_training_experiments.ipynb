{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import einops\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "import experiments.utils as utils\n",
    "from experiments.probe_training import *\n",
    "from experiments.pipeline_config import PipelineConfig\n",
    "\n",
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "\n",
    "# Configuration\n",
    "DEBUGGING = False\n",
    "SEED = 42\n",
    "\n",
    "# Set up paths and model\n",
    "parent_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "tracer_kwargs = dict(scan=DEBUGGING, validate=DEBUGGING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_activations(\n",
    "    text_inputs: list[str], model: LanguageModel, batch_size: int, submodule: utils.submodule_alias\n",
    ") -> torch.Tensor:\n",
    "    # TODO: Rename text_inputs\n",
    "    text_batches = utils.batch_inputs(text_inputs, batch_size)\n",
    "\n",
    "    all_acts_list_BD = []\n",
    "    for text_batch_BL in text_batches:\n",
    "        with model.trace(\n",
    "            text_batch_BL,\n",
    "            **tracer_kwargs,\n",
    "        ):\n",
    "            attn_mask = model.input[1][\"attention_mask\"]\n",
    "            acts_BLD = submodule.output[0]\n",
    "            acts_BLD = acts_BLD * attn_mask[:, :, None]\n",
    "            acts_BD = acts_BLD.sum(1) / attn_mask.sum(1)[:, None]\n",
    "            acts_BD = acts_BD.save()\n",
    "        all_acts_list_BD.append(acts_BD.value)\n",
    "\n",
    "    all_acts_bD = torch.cat(all_acts_list_BD, dim=0)\n",
    "    return all_acts_bD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = \"google/gemma-2-2b\"\n",
    "device = \"cuda\"\n",
    "train_set_size = 4000\n",
    "test_set_size = 1000\n",
    "context_length = 128\n",
    "include_gender = True\n",
    "model_dtype = torch.bfloat16\n",
    "\n",
    "probe_batch_size = 500\n",
    "llm_batch_size = 32\n",
    "\n",
    "# TODO: I think there may be a scoping issue with model and get_acts(), but we currently aren't using get_acts()\n",
    "model = LanguageModel(\n",
    "    llm_model_name,\n",
    "    device_map=device,\n",
    "    dispatch=True,\n",
    "    torch_dtype=model_dtype,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "probe_dir = \"trained_bib_probes\"\n",
    "only_model_name = llm_model_name.split(\"/\")[-1]\n",
    "\n",
    "model_eval_config = utils.ModelEvalConfig.from_full_model_name(llm_model_name)\n",
    "probe_layer = model_eval_config.probe_layer\n",
    "\n",
    "probe_output_filename = (\n",
    "    f\"{probe_dir}/{only_model_name}/probes_ctx_len_{context_length}_layer_{probe_layer}.pkl\"\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "save_results = True\n",
    "seed = SEED\n",
    "include_gender = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Because we save the probes, we always train them on all classes to avoid potential issues with missing classes. It's only a one-time cost.\"\"\"\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "model_eval_config = utils.ModelEvalConfig.from_full_model_name(llm_model_name)\n",
    "d_model = model_eval_config.activation_dim\n",
    "probe_layer = model_eval_config.probe_layer\n",
    "probe_act_submodule = utils.get_submodule(model, \"resid_post\", probe_layer)\n",
    "\n",
    "dataset_name = \"bias_in_bios\"\n",
    "\n",
    "column1_vals = (\"professor\", \"nurse\")\n",
    "column2_vals = (\"male\", \"female\")\n",
    "\n",
    "train_df, test_df = load_and_prepare_dataset(dataset_name)\n",
    "\n",
    "train_bios, test_bios = get_train_test_data(\n",
    "    train_df, test_df, dataset_name, True, train_set_size, test_set_size, 42, column1_vals, column2_vals\n",
    ")\n",
    "\n",
    "train_bios = utils.tokenize_data(train_bios, model.tokenizer, context_length, device)\n",
    "test_bios = utils.tokenize_data(test_bios, model.tokenizer, context_length, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_ids = [2]\n",
    "\n",
    "# ae_sweep_paths = {\n",
    "#     # \"pythia70m_sweep_standard_ctx128_0712\": {\n",
    "#     #     #     # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "#     #     #     # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "#     #     #     # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "#     #     \"resid_post_layer_3\": {\"trainer_ids\": [6]},\n",
    "#     #     #     \"resid_post_layer_4\": {\"trainer_ids\": None},\n",
    "#     # },\n",
    "#     # \"pythia70m_sweep_topk_ctx128_0730\": {\n",
    "#     #     # \"resid_post_layer_0\": {\"trainer_ids\": None},\n",
    "#     #     # \"resid_post_layer_1\": {\"trainer_ids\": None},\n",
    "#     #     # \"resid_post_layer_2\": {\"trainer_ids\": None},\n",
    "#     #     \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "#     #     # \"resid_post_layer_4\": {\"trainer_ids\": trainer_ids},\n",
    "#     # },\n",
    "#     \"gemma-2-2b_sweep_topk_ctx128_ef2_0824\": {\n",
    "#         # \"resid_post_layer_3\": {\"trainer_ids\": trainer_ids},\n",
    "#         # \"resid_post_layer_7\": {\"trainer_ids\": trainer_ids},\n",
    "#         \"resid_post_layer_11\": {\"trainer_ids\": trainer_ids},\n",
    "#         # \"resid_post_layer_15\": {\"trainer_ids\": trainer_ids},\n",
    "#         # \"resid_post_layer_19\": {\"trainer_ids\": trainer_ids},\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# p_config = PipelineConfig()\n",
    "\n",
    "# sweep_name, submodule_trainers = list(ae_sweep_paths.items())[0]\n",
    "\n",
    "# ae_group_paths = utils.get_ae_group_paths(\n",
    "#     p_config.dictionaries_path, sweep_name, submodule_trainers\n",
    "# )\n",
    "# ae_paths = utils.get_ae_paths(ae_group_paths)\n",
    "# print(ae_paths)\n",
    "\n",
    "# ae_path = ae_paths[0]\n",
    "\n",
    "# submodule, dictionary, sae_config = utils.load_dictionary(model, ae_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_all_sae_activations(\n",
    "    text_inputs: list[str],\n",
    "    model: LanguageModel,\n",
    "    dictionary: AutoEncoder,\n",
    "    batch_size: int,\n",
    "    submodule: utils.submodule_alias,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    # TODO: Rename text_inputs\n",
    "    text_batches = utils.batch_inputs(text_inputs, batch_size)\n",
    "\n",
    "    with torch.no_grad(), model.trace(\"_\"):\n",
    "        is_tuple = type(submodule.outputorch.shape) == tuple\n",
    "\n",
    "    model_dtype = model.dtype\n",
    "\n",
    "    all_acts_list_BD = []\n",
    "    all_sae_acts_list_BF = []\n",
    "    for text_batch_BL in text_batches:\n",
    "        with model.trace(\n",
    "            text_batch_BL,\n",
    "            **tracer_kwargs,\n",
    "        ):\n",
    "            attn_mask = model.input[1][\"attention_mask\"]\n",
    "            acts_BLD = submodule.output\n",
    "\n",
    "            if is_tuple:\n",
    "                acts_BLD = acts_BLD[0]\n",
    "\n",
    "            acts_BLF = dictionary.encode(acts_BLD)\n",
    "            acts_BLF = acts_BLF * attn_mask[:, :, None]\n",
    "            acts_BF = acts_BLF.sum(1) / attn_mask.sum(1)[:, None]\n",
    "            acts_BF = acts_BF.save()\n",
    "\n",
    "            acts_BLD = acts_BLD * attn_mask[:, :, None]\n",
    "            acts_BD = acts_BLD.sum(1) / attn_mask.sum(1)[:, None]\n",
    "            acts_BD = acts_BD.save()\n",
    "        all_acts_list_BD.append(acts_BD.value)\n",
    "        all_sae_acts_list_BF.append(acts_BF.value.to(dtype=model_dtype))\n",
    "\n",
    "    all_acts_bD = torch.cat(all_acts_list_BD, dim=0)\n",
    "    all_sae_acts_bF = torch.cat(all_sae_acts_list_BF, dim=0)\n",
    "\n",
    "    return all_acts_bD, all_sae_acts_bF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_bios.keys())\n",
    "print(test_bios.keys())\n",
    "\n",
    "new_train_bios = {}\n",
    "new_test_bios = {}\n",
    "\n",
    "for key in train_bios:\n",
    "    if isinstance(key, int):\n",
    "        continue\n",
    "\n",
    "    new_train_bios[key] = train_bios[key]\n",
    "    new_test_bios[key] = test_bios[key]\n",
    "\n",
    "train_bios = new_train_bios\n",
    "test_bios = new_test_bios\n",
    "\n",
    "print(train_bios.keys())\n",
    "print(test_bios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_acts = {}\n",
    "all_test_acts = {}\n",
    "\n",
    "\n",
    "llm_batch_size = 32\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, profession in enumerate(train_bios.keys()):\n",
    "        # if isinstance(profession, int):\n",
    "        #     continue\n",
    "\n",
    "        print(f\"Collecting activations for profession: {profession}\")\n",
    "\n",
    "        all_train_acts[profession] = get_all_activations(\n",
    "            train_bios[profession], model, llm_batch_size, probe_act_submodule\n",
    "        )\n",
    "        all_test_acts[profession] = get_all_activations(\n",
    "            test_bios[profession], model, llm_batch_size, probe_act_submodule\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_tensor_memory_usage(tensor: torch.Tensor):\n",
    "#     if not isinstance(tensor, torch.Tensor):\n",
    "#         print(\"Input is not a tensor. Cannot calculate memory usage.\")\n",
    "#         return\n",
    "    \n",
    "#     memory = tensor.element_size() * tensor.nelement()\n",
    "#     print(f\"Tensor Shape: {tensor.shape}\")\n",
    "#     print(f\"Tensor Type: {tensor.dtype}\")\n",
    "#     print(f\"Memory usage: {memory / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model_acts = all_train_acts[0]\n",
    "# print_tensor_memory_usage(model_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_probe_data(\n",
    "    all_activations: dict[int | str, torch.Tensor],\n",
    "    class_idx: int | str,\n",
    "    batch_size: int,\n",
    "    select_top_k: Optional[int] = None,\n",
    ") -> tuple[list[torch.Tensor], list[torch.Tensor]]:\n",
    "    \"\"\"If class_idx is a string, there is a paired class idx in utils.py.\"\"\"\n",
    "    positive_acts_BD = all_activations[class_idx]\n",
    "    device = positive_acts_BD.device\n",
    "\n",
    "    num_positive = len(positive_acts_BD)\n",
    "\n",
    "    if isinstance(class_idx, int):\n",
    "        # Collect all negative class activations and labels\n",
    "        negative_acts = []\n",
    "        for idx, acts in all_activations.items():\n",
    "            if idx != class_idx and isinstance(idx, int):\n",
    "                negative_acts.append(acts)\n",
    "\n",
    "        negative_acts = torch.cat(negative_acts)\n",
    "    # elif class_idx == \"biased_male / biased_female\":\n",
    "    #     male_professors = all_activations[\"male_professor / female_nurse\"]\n",
    "    #     female_nurses = all_activations[\"female_nurse_data_only\"]\n",
    "    #     males = all_activations[\"male / female\"]\n",
    "    #     females = all_activations[\"female_data_only\"]\n",
    "    #     professors = all_activations[\"professor / nurse\"]\n",
    "    #     nurses = all_activations[\"nurse_data_only\"]\n",
    "\n",
    "    #     mixed_data = [males, females, professors, nurses]\n",
    "    #     mixed_data = torch.cat(mixed_data)\n",
    "    #     shuffle_indices = torch.randperm(len(mixed_data))\n",
    "    #     mixed_data = mixed_data[shuffle_indices]\n",
    "\n",
    "    #     random_pos = torch.randperm(int(num_positive * 0.1))\n",
    "    #     random_neg = torch.randperm(int(num_positive * 0.1))\n",
    "\n",
    "    #     random_pos_data = mixed_data[random_pos]\n",
    "    #     random_neg_data = mixed_data[random_neg]\n",
    "\n",
    "    #     positive_acts_BD = torch.cat([male_professors, random_pos_data])\n",
    "    #     negative_acts = torch.cat([female_nurses, random_neg_data])\n",
    "    else:\n",
    "        if class_idx not in utils.PAIRED_CLASS_KEYS:\n",
    "            raise ValueError(f\"Class index {class_idx} is not a valid class index.\")\n",
    "\n",
    "        negative_acts = all_activations[utils.PAIRED_CLASS_KEYS[class_idx]]\n",
    "\n",
    "    # Randomly select num_positive samples from negative class\n",
    "    indices = torch.randperm(len(negative_acts))[:len(positive_acts_BD)]\n",
    "    selected_negative_acts_BD = negative_acts[indices]\n",
    "\n",
    "    assert selected_negative_acts_BD.shape == positive_acts_BD.shape\n",
    "\n",
    "    if select_top_k is not None:\n",
    "        positive_distribution_D = positive_acts_BD.mean(dim=(0))\n",
    "        negative_distribution_D = negative_acts.mean(dim=(0))\n",
    "        distribution_diff_D = (positive_distribution_D - negative_distribution_D).abs()\n",
    "        top_k_indices_D = torch.argsort(distribution_diff_D, descending=True)[:select_top_k]\n",
    "\n",
    "        mask_D = torch.ones(distribution_diff_D.shape[0], dtype=torch.bool, device=positive_acts_BD.device)\n",
    "        mask_D[top_k_indices_D] = False\n",
    "\n",
    "        masked_positive_acts_BD = positive_acts_BD.clone()\n",
    "        masked_negative_acts_BD = selected_negative_acts_BD.clone()\n",
    "\n",
    "        masked_positive_acts_BD[:, mask_D] = 0.0\n",
    "        masked_negative_acts_BD[:, mask_D] = 0.0\n",
    "    else:\n",
    "        masked_positive_acts_BD = positive_acts_BD\n",
    "        masked_negative_acts_BD = selected_negative_acts_BD\n",
    "\n",
    "    # Combine positive and negative samples\n",
    "    combined_acts = torch.cat([masked_positive_acts_BD, masked_negative_acts_BD])\n",
    "\n",
    "    combined_labels = torch.empty(len(combined_acts), dtype=torch.int, device=device)\n",
    "    combined_labels[:num_positive] = utils.POSITIVE_CLASS_LABEL\n",
    "    combined_labels[num_positive:] = utils.NEGATIVE_CLASS_LABEL\n",
    "\n",
    "    # Shuffle the combined data\n",
    "    shuffle_indices = torch.randperm(len(combined_acts))\n",
    "    shuffled_acts = combined_acts[shuffle_indices]\n",
    "    shuffled_labels = combined_labels[shuffle_indices]\n",
    "\n",
    "    # Reshape into lists of tensors with specified batch_size\n",
    "    num_samples = len(shuffled_acts)\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    batched_acts = [\n",
    "        shuffled_acts[i * batch_size : (i + 1) * batch_size] for i in range(num_batches)\n",
    "    ]\n",
    "    batched_labels = [\n",
    "        shuffled_labels[i * batch_size : (i + 1) * batch_size] for i in range(num_batches)\n",
    "    ]\n",
    "\n",
    "    return batched_acts, batched_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe model and training\n",
    "class Probe(nn.Module):\n",
    "    def __init__(self, activation_dim: int, dtype: torch.dtype):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(activation_dim, 1, bias=True, dtype=dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "def train_probe(\n",
    "    train_input_batches: list,\n",
    "    train_label_batches: list[torch.Tensor],\n",
    "    test_input_batches: list,\n",
    "    test_label_batches: list[torch.Tensor],\n",
    "    get_acts: Callable,\n",
    "    precomputed_acts: bool,\n",
    "    dim: int,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "    model_dtype: torch.dtype,\n",
    "    lr: float = 1e-2,\n",
    "    seed: int = SEED,\n",
    "    verbose: bool = False,\n",
    ") -> tuple[Probe, float]:\n",
    "    \"\"\"input_batches can be a list of tensors or strings. If strings, get_acts must be provided.\"\"\"\n",
    "\n",
    "    if type(train_input_batches[0]) == str or type(test_input_batches[0]) == str:\n",
    "        assert precomputed_acts == False\n",
    "    elif type(train_input_batches[0]) == torch.Tensor or type(test_input_batches[0]) == torch.Tensor:\n",
    "        assert precomputed_acts == True\n",
    "\n",
    "    probe = Probe(dim, model_dtype).to(device)\n",
    "    optimizer = torch.optim.AdamW(probe.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_idx = 0\n",
    "        for inputs, labels in zip(train_input_batches, train_label_batches):\n",
    "            if precomputed_acts:\n",
    "                acts_BD = inputs\n",
    "            else:\n",
    "                acts_BD = get_acts(inputs)\n",
    "            logits_B = probe(acts_BD)\n",
    "            loss = criterion(logits_B, labels.clone().detach().to(device=device, dtype=model_dtype))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_idx += 1\n",
    "\n",
    "        \n",
    "\n",
    "        train_accuracy = test_probe(\n",
    "            train_input_batches[:30], train_label_batches[:30], probe, get_acts, precomputed_acts\n",
    "        )\n",
    "\n",
    "\n",
    "        test_accuracy = test_probe(\n",
    "            test_input_batches, test_label_batches, probe, get_acts, precomputed_acts\n",
    "        )\n",
    "\n",
    "        if epoch == epochs - 1 and verbose:\n",
    "            print(f\"\\nEpoch {epoch + 1}/{epochs} Loss: {loss.item()}, train accuracy: {train_accuracy}, test accuracy: {test_accuracy}\\n\")\n",
    "    \n",
    "    return probe, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.probe_training import prepare_probe_data\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def train_probe_on_activations(\n",
    "    train_activations: dict[str | int : torch.Tensor],\n",
    "    test_activations: dict[str | int : torch.Tensor],\n",
    "    select_top_k: Optional[int] = None,\n",
    ") -> tuple[dict[str | int : Probe], dict[str | int : float]]:\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    probes, test_accuracies = {}, {}\n",
    "\n",
    "    for profession in train_activations.keys():\n",
    "        if profession in utils.PAIRED_CLASS_KEYS.values():\n",
    "            continue\n",
    "\n",
    "        train_acts, train_labels = prepare_probe_data(train_activations, profession, True, probe_batch_size, select_top_k)\n",
    "\n",
    "        test_acts, test_labels = prepare_probe_data(test_activations, profession, True, probe_batch_size, select_top_k)\n",
    "\n",
    "        if profession == \"biased_male / biased_female\" or profession == \"male / female\":\n",
    "            probe_epochs = epochs\n",
    "        else:\n",
    "            probe_epochs = epochs\n",
    "\n",
    "        activation_dim = train_acts[0].shape[1]\n",
    "\n",
    "        probe, test_accuracy = train_probe(\n",
    "            train_acts,\n",
    "            train_labels,\n",
    "            test_acts,\n",
    "            test_labels,\n",
    "            get_acts,\n",
    "            precomputed_acts=True,\n",
    "            epochs=probe_epochs,\n",
    "            dim=activation_dim,\n",
    "            device=device,\n",
    "            model_dtype=model_dtype,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        probes[profession] = probe\n",
    "        test_accuracies[profession] = test_accuracy\n",
    "\n",
    "    return probes, test_accuracies\n",
    "\n",
    "    # if save_results:\n",
    "    #     only_model_name = llm_model_name.split(\"/\")[-1]\n",
    "    #     os.makedirs(f\"{probe_dir}\", exist_ok=True)\n",
    "    #     os.makedirs(f\"{probe_dir}/{only_model_name}\", exist_ok=True)\n",
    "\n",
    "    #     with open(probe_output_filename, \"wb\") as f:\n",
    "    #         pickle.dump(probes, f)\n",
    "\n",
    "\n",
    "probes, test_accuracies = train_probe_on_activations(all_train_acts, all_test_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_accs.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(all_train_acts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diffs = []\n",
    "int_diffs = []\n",
    "str_diffs = []\n",
    "\n",
    "for class_name in test_accuracies.keys():\n",
    "    model_acc = test_accuracies[class_name][0]\n",
    "\n",
    "    print(f\"Class: {class_name}, Accuracy: {model_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_class_indices = [\"male / female\", \"professor / nurse\", \"male_professor / female_nurse\", \"biased_male / biased_female\"]\n",
    "\n",
    "test_accuracies = get_probe_test_accuracy(\n",
    "    probes, chosen_class_indices, all_test_acts, p_config.probe_batch_size\n",
    ")\n",
    "\n",
    "for class_name in test_accuracies.keys():\n",
    "    model_acc = test_accuracies[class_name]['acc']\n",
    "\n",
    "    print(f\"Class: {class_name}, Accuracy: {model_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
