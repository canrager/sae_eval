{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature labelling and prompt building\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "import datasets\n",
    "import anthropic\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import experiments.utils as utils\n",
    "from experiments.autointerp import (\n",
    "    get_max_activating_prompts, \n",
    "    highlight_top_activations,\n",
    "    compute_dla, \n",
    "    format_examples,\n",
    "    evaluate_binary_llm_output,\n",
    "    get_autointerp_inputs_for_all_saes,\n",
    ")\n",
    "from experiments.explainers.simple.prompt_builder import build_prompt\n",
    "from experiments.explainers.simple.prompts import build_system_prompt\n",
    "\n",
    "DEBUGGING = True\n",
    "\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = dict(scan=True, validate=True)\n",
    "else:\n",
    "    tracer_kwargs = dict(scan=False, validate=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict = {\n",
    "    \"accountant\": 0, \"architect\": 1, \"attorney\": 2, \"chiropractor\": 3,\n",
    "    \"comedian\": 4, \"composer\": 5, \"dentist\": 6, \"dietitian\": 7,\n",
    "    \"dj\": 8, \"filmmaker\": 9, \"interior_designer\": 10, \"journalist\": 11,\n",
    "    \"model\": 12, \"nurse\": 13, \"painter\": 14, \"paralegal\": 15,\n",
    "    \"pastor\": 16, \"personal_trainer\": 17, \"photographer\": 18, \"physician\": 19,\n",
    "    \"poet\": 20, \"professor\": 21, \"psychologist\": 22, \"rapper\": 23,\n",
    "    \"software_engineer\": 24, \"surgeon\": 25, \"teacher\": 26, \"yoga_teacher\": 27,\n",
    "    \"male / female\": \"male / female\", \"professor / nurse\": \"professor / nurse\",\n",
    "    \"male_professor / female_nurse\": \"male_professor / female_nurse\",\n",
    "    \"biased_male / biased_female\": \"biased_male / biased_female\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "\n",
    "dictionaries_path = \"../dictionary_learning/dictionaries/autointerp_test_data\"\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_topk_ctx128_0730\": {\"resid_post_layer_3\": {\"trainer_ids\": [2, 6, 10, 18]}},\n",
    "    \"gemma-2-2b_test_sae\": {\"resid_post_layer_12\": {\"trainer_ids\": [2]}}, \n",
    "}\n",
    "pythia_sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "pythia_submodule_trainers = ae_sweep_paths[pythia_sweep_name]\n",
    "\n",
    "pythia_group_paths = utils.get_ae_group_paths(dictionaries_path, pythia_sweep_name, pythia_submodule_trainers)\n",
    "pythia_ae_paths = utils.get_ae_paths(pythia_group_paths)\n",
    "\n",
    "gemma_sweep_name = list(ae_sweep_paths.keys())[1]\n",
    "gemma_submodule_trainers = ae_sweep_paths[gemma_sweep_name]\n",
    "\n",
    "gemma_group_paths = utils.get_ae_group_paths(dictionaries_path, gemma_sweep_name, gemma_submodule_trainers)\n",
    "gemma_ae_paths = utils.get_ae_paths(gemma_group_paths)\n",
    "\n",
    "chosen_class_indices = [\n",
    "        \"male / female\",\n",
    "        \"professor / nurse\",\n",
    "        \"male_professor / female_nurse\",\n",
    "        \"biased_male / biased_female\",\n",
    "        \"accountant\",\n",
    "        \"architect\",\n",
    "        \"attorney\",\n",
    "        \"dentist\",\n",
    "        \"filmmaker\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 96 combinations to evaluate.\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = [0, 10, 100, 1000]\n",
    "class_indices_1 = [\"male / female\", \"professor / nurse\", \"accountant\", \"architect\"]\n",
    "class_indices_2 = [\"male_professor / female_nurse\", \"attorney\", \"dentist\", \"filmmaker\"]\n",
    "class_indices_3 = class_indices_1 + class_indices_2\n",
    "\n",
    "combinations = [\n",
    "    {\"sae\": pythia_ae_paths[0], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[1], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": pythia_ae_paths[2], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[3], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": gemma_ae_paths[0], \"class_indices\": class_indices_3},\n",
    "]\n",
    "\n",
    "def generate_combinations(sampled_indices, combinations):\n",
    "    result = []\n",
    "    for combo in combinations:\n",
    "        sae = combo[\"sae\"]\n",
    "        class_indices = combo[\"class_indices\"]\n",
    "        for class_index in class_indices:\n",
    "            for sampled_index in sampled_indices:\n",
    "                result.append({\n",
    "                    \"sae\": sae,\n",
    "                    \"class_index\": class_index,\n",
    "                    \"sampled_index\": sampled_index\n",
    "                })\n",
    "    return result\n",
    "\n",
    "combinations_list = generate_combinations(sampled_indices, combinations)\n",
    "print(f\"There are {len(combinations_list)} combinations to evaluate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia_model_eval_config = utils.ModelEvalConfig.from_sweep_name(pythia_sweep_name)\n",
    "pythia_model_name = pythia_model_eval_config.full_model_name\n",
    "pythia_tokenizer = AutoTokenizer.from_pretrained(pythia_model_name)\n",
    "\n",
    "gemma_model_eval_config = utils.ModelEvalConfig.from_sweep_name(gemma_sweep_name)\n",
    "gemma_model_name = gemma_model_eval_config.full_model_name\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamkarvonen/sae_eval/venv/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "# Run max activating examples once from all SAEs\n",
    "\n",
    "k_inputs_per_feature = 10\n",
    "example_ae_path = pythia_ae_paths[0]\n",
    "\n",
    "with open(os.path.join(example_ae_path, \"max_activating_inputs.pkl\"), \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "tensor([1.5156, 0.2812, 0.1514], dtype=torch.bfloat16)\n",
      "tensor([15482, 11871,  2419])\n"
     ]
    }
   ],
   "source": [
    "### Find features relevant to a profession from the class_probe node_effects.pkl\n",
    "\n",
    "class_name = \"male / female\"\n",
    "k_features_per_concept = 3 \n",
    "\n",
    "filename_counter = \"\"\n",
    "class_id = profession_dict[class_name]\n",
    "node_effects_filename = f\"{example_ae_path}/node_effects{filename_counter}.pkl\"\n",
    "\n",
    "with open(node_effects_filename, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "print(effects.shape)\n",
    "\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, k_features_per_concept)\n",
    "t.set_printoptions(sci_mode=False)\n",
    "print(top_k_values)\n",
    "print(top_k_indices)\n",
    "\n",
    "selected_token_idxs_FKL = max_token_idxs_FKL[top_k_indices]\n",
    "selected_activations_FKL = max_activations_FKL[top_k_indices]\n",
    "top_dla_token_idxs_FK = top_dla_token_idxs_FK[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10])\n",
      " her, herself, she, hers, She,She,she, Her, pregnancy, woman\n"
     ]
    }
   ],
   "source": [
    "# Format max_activating_inputs by << emphasizing>> max act examples\n",
    "\n",
    "num_top_emphasized_tokens = 5\n",
    "\n",
    "print(top_dla_token_idxs_FK.shape)\n",
    "\n",
    "example_prompts = format_examples(pythia_tokenizer, selected_token_idxs_FKL, selected_activations_FKL, num_top_emphasized_tokens)\n",
    "\n",
    "top_dla_tokens_list = []\n",
    "\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_FK, pythia_tokenizer)\n",
    "tokens = tokens_list[0]\n",
    "\n",
    "print(\",\".join(tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANUAL LABELING BEGINS HERE\n",
    "\n",
    "Run manual inputs creation to view DLA and top 4 example prompts.\n",
    "\n",
    "Add scores / chain of thought to Label adding per example.\n",
    "\n",
    "Save as json once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_idx = 0\n",
    "\n",
    "displayed_prompts = 4\n",
    "num_top_emphasized_tokens = 5\n",
    "t.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current idx: 0\n",
      "SAE path: ../dictionary_learning/dictionaries/autointerp_test_data/pythia70m_sweep_topk_ctx128_0730/resid_post_layer_3/trainer_2\n",
      "class index: male / female\n",
      "sampled index: 0\n",
      " her, herself, she, hers, She,She,she, Her, pregnancy, woman\n",
      "\n",
      "\n",
      "\n",
      "Example 1: the broker and said yes.\n",
      "\n",
      "She << told>> her younger sister she was going to America for work, << but>> << to>> << keep>> it a secret from her parents, who would never grant her permission to work abroad. You Mi told her parents she was going to Seoul to be a golf caddy -- one of the few legal women's jobs that bring hefty tips from rich men.\n",
      "\n",
      "She planned to << tell>> them the truth after she paid off her debts.\n",
      "\n",
      "You Mi was instructed to take passport photos and give them to a man named Kevin in Seoul. The broker drove her to the city, and two days later, You Mi had\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 2: (everyone was wearing hop-bought clothes. What is the world coming to?). I thought she'd << lost>> << when>> an even littler girl appeared dressed as a bumble bee - but she hung << onto>> mummy the whole time, and wouldn't talk or look at the audience, << whereas>> LMD went up on her own, yelled her age down the microphone, and roundly << told>> off anyone who tried to steal her moment of fame:-) LMB also got to win one of the paltry prizes of \"a foil mask\" by winning hide and seek on the last day. Admittedly I found the hiding place -\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 3: she wanted to show it off to everybody – ‘I’m the captain’ – and she’d be dragging children, parents on [to it] and that was just the way she was << about>> her job, how passionate she was << about>> it. She << wanted>> everybody to know about it, she was so proud << of>> her team and her helicopter and she << wanted>> everybody to know about it,” he said.\n",
      "\n",
      "Capt Fitzpatrick worked for CHC, a private company providing helicopter search and rescue capability to the Irish Coast Guard. On Monday night, her Sikorsky helicopter, Rescue 116, was deployed from Dublin to give “top cover\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example 4: adopted from Korea when she was 7½ months old, grew up in Milwaukee, Wis., and now lives in Queens. April 2017.Credit: Mengwen Cao\n",
      "\n",
      "Emily Roe, now 26, in her apartment in Brooklyn. She was adopted << from>> China << when>> she was 4 months old, grew up in Connecticut and moved to New York to study fashion and textile design at Pratt Institute <<.>> April 2017.\n",
      "\n",
      "Credit: Mengwen Cao\n",
      "\n",
      "Emily Roe, now 26, in her apartment in Brooklyn <<.>> She was adopted from China << when>> she was 4 months old, grew up in Connecticut\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamkarvonen/sae_eval/venv/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "# Manual inputs creation\n",
    "\n",
    "current_combination = combinations_list[current_idx]\n",
    "ae_path = current_combination[\"sae\"]\n",
    "class_index = current_combination[\"class_index\"]\n",
    "sampled_index = current_combination[\"sampled_index\"]\n",
    "\n",
    "class_id = profession_dict[class_index]\n",
    "\n",
    "if \"pythia\" in ae_path:\n",
    "    tokenizer = pythia_tokenizer\n",
    "else:\n",
    "    tokenizer = gemma_tokenizer\n",
    "\n",
    "print(f\"current idx: {current_idx}\")\n",
    "print(f\"SAE path: {ae_path}\")\n",
    "print(f\"class index: {class_index}\")\n",
    "print(f\"sampled index: {sampled_index}\")\n",
    "\n",
    "inputs_path = os.path.join(ae_path, \"max_activating_inputs.pkl\")\n",
    "node_effects_path = os.path.join(ae_path, \"node_effects.pkl\")\n",
    "\n",
    "with open(inputs_path, \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "with open(node_effects_path, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]\n",
    "\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, 2000)\n",
    "\n",
    "sae_feat_index = top_k_indices[sampled_index]\n",
    "\n",
    "selected_token_idxs_1KL = max_token_idxs_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "selected_activations_1KL = max_activations_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "top_dla_token_idxs_K = top_dla_token_idxs_FK[sae_feat_index]\n",
    "\n",
    "example_prompts = format_examples(tokenizer, selected_token_idxs_1KL, selected_activations_1KL, num_top_emphasized_tokens)\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_K, tokenizer)\n",
    "tokens_string = \",\".join(tokens_list)\n",
    "\n",
    "print(tokens_string)\n",
    "print(example_prompts[0])\n",
    "\n",
    "previous_idx = current_idx\n",
    "current_idx += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add the following idx to manual_labels: 0\n"
     ]
    }
   ],
   "source": [
    "# Label adding\n",
    "\n",
    "per_class_scores = {\n",
    "    \"male / female\": 4,\n",
    "    \"professor / nurse\": 0,\n",
    "    \"male_professor / female_nurse\": 0,\n",
    "    \"biased_male / biased_female\": 0,\n",
    "    \"accountant\": 1,\n",
    "    \"architect\": 0,\n",
    "    \"attorney\": 0,\n",
    "    \"dentist\": 0,\n",
    "    \"filmmaker\": 0,\n",
    "}\n",
    "\n",
    "chain_of_thought = \"\"\"The top promoted logits are female pronouns and female pronouns are in every sentence, thus this is a 4 for male / female.\n",
    "Two sentences mention companies and brokers, so this is a 1 for accountant. No other classes appear to be relevant.\"\"\"\n",
    "\n",
    "new_label = {\n",
    "    \"sae\": ae_path,\n",
    "    \"class_index\": class_index,\n",
    "    \"sampled_index\": sampled_index,\n",
    "    \"sae_feat_index\": sae_feat_index.item(),\n",
    "    \"example_prompts\": example_prompts,\n",
    "    \"tokens_string\": tokens_string,\n",
    "    \"per_class_scores\": per_class_scores,\n",
    "    \"chain_of_thought\": chain_of_thought,\n",
    "}\n",
    "\n",
    "manual_labels[current_idx] = new_label\n",
    "\n",
    "print(f\"Add the following idx to manual_labels: {previous_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"manual_labels.json\", \"w\") as f:\n",
    "    json.dump(manual_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = build_system_prompt(\n",
    "#     cot=False,\n",
    "#     concepts=list(profession_dict.keys()),\n",
    "#     logits=True\n",
    "# )\n",
    "\n",
    "# prompts = []\n",
    "# for example_prompt, top_dla_tokens_K in zip(example_prompts, top_dla_tokens_FK):\n",
    "#     message = build_prompt(\n",
    "#         examples=example_prompt,\n",
    "#         cot=False,\n",
    "#         top_logits=top_dla_tokens_K,\n",
    "#     )\n",
    "#     prompts.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to a concept for each concept in (accountant, architect, attorney, chiropractor, comedian, composer, dentist, dietitian, dj, filmmaker, interior_designer, journalist, model, nurse, painter, paralegal, pastor, personal_trainer, photographer, physician, poet, professor, psychologist, rapper, software_engineer, surgeon, teacher, yoga_teacher, male / female, professor / nurse, male_professor / female_nurse, biased_male / biased_female).\n",
      "\n",
      "(Part 2) Tokens that the neuron boosts in the next token prediction\n",
      "\n",
      "You will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\n",
      "\n",
      "Pay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\n",
      "yes_or_no_decisions = {\"accountant\": \"your_decision\", \"architect\": \"your_decision\", \"attorney\": \"your_decision\", \"chiropractor\": \"your_decision\", \"comedian\": \"your_decision\", \"composer\": \"your_decision\", \"dentist\": \"your_decision\", \"dietitian\": \"your_decision\", \"dj\": \"your_decision\", \"filmmaker\": \"your_decision\", \"interior_designer\": \"your_decision\", \"journalist\": \"your_decision\", \"model\": \"your_decision\", \"nurse\": \"your_decision\", \"painter\": \"your_decision\", \"paralegal\": \"your_decision\", \"pastor\": \"your_decision\", \"personal_trainer\": \"your_decision\", \"photographer\": \"your_decision\", \"physician\": \"your_decision\", \"poet\": \"your_decision\", \"professor\": \"your_decision\", \"psychologist\": \"your_decision\", \"rapper\": \"your_decision\", \"software_engineer\": \"your_decision\", \"surgeon\": \"your_decision\", \"teacher\": \"your_decision\", \"yoga_teacher\": \"your_decision\", \"male / female\": \"your_decision\", \"professor / nurse\": \"your_decision\", \"male_professor / female_nurse\": \"your_decision\", \"biased_male / biased_female\": \"your_decision\"}\n",
      "Guidelines:\n",
      "\n",
      "You will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\n",
      "\n",
      "- For each concept in (accountant, architect, attorney, chiropractor, comedian, composer, dentist, dietitian, dj, filmmaker, interior_designer, journalist, model, nurse, painter, paralegal, pastor, personal_trainer, photographer, physician, poet, professor, psychologist, rapper, software_engineer, surgeon, teacher, yoga_teacher, male / female, professor / nurse, male_professor / female_nurse, biased_male / biased_female), try to judge whether the neurons behavior is related to the concept. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\n",
      "- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\n",
      "- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to any concept.\n",
      "- The last line of your response must be your binary decisions, yes or no in the following format: yes_or_no_decisions = {\"accountant\": \"your_decision\", \"architect\": \"your_decision\", \"attorney\": \"your_decision\", \"chiropractor\": \"your_decision\", \"comedian\": \"your_decision\", \"composer\": \"your_decision\", \"dentist\": \"your_decision\", \"dietitian\": \"your_decision\", \"dj\": \"your_decision\", \"filmmaker\": \"your_decision\", \"interior_designer\": \"your_decision\", \"journalist\": \"your_decision\", \"model\": \"your_decision\", \"nurse\": \"your_decision\", \"painter\": \"your_decision\", \"paralegal\": \"your_decision\", \"pastor\": \"your_decision\", \"personal_trainer\": \"your_decision\", \"photographer\": \"your_decision\", \"physician\": \"your_decision\", \"poet\": \"your_decision\", \"professor\": \"your_decision\", \"psychologist\": \"your_decision\", \"rapper\": \"your_decision\", \"software_engineer\": \"your_decision\", \"surgeon\": \"your_decision\", \"teacher\": \"your_decision\", \"yoga_teacher\": \"your_decision\", \"male / female\": \"your_decision\", \"professor / nurse\": \"your_decision\", \"male_professor / female_nurse\": \"your_decision\", \"biased_male / biased_female\": \"your_decision\"}\n"
     ]
    }
   ],
   "source": [
    "# print(system_prompt[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Max act examples for Feature 15482:\n",
      "Example 1: the broker and said yes.\n",
      "\n",
      "She << told>> her younger sister she was going to America for work, << but>> << to>> << keep>> it a secret from her parents, who would never grant her permission to work abroad. You Mi told her parents she was going to Seoul to be a golf caddy -- one of the few legal women's jobs that bring hefty tips from rich men.\n",
      "\n",
      "She planned to << tell>> them the truth after she paid off her debts.\n",
      "\n",
      "You Mi was instructed to take passport photos and give them to a man named Kevin in Seoul. The broker drove her to the city, and two days later, You Mi had\n",
      "\n",
      "Example 2: (everyone was wearing hop-bought clothes. What is the world coming to?). I thought she'd << lost>> << when>> an even littler girl appeared dressed as a bumble bee - but she hung << onto>> mummy the whole time, and wouldn't talk or look at the audience, << whereas>> LMD went up on her own, yelled her age down the microphone, and roundly << told>> off anyone who tried to steal her moment of fame:-) LMB also got to win one of the paltry prizes of \"a foil mask\" by winning hide and seek on the last day. Admittedly I found the hiding place -\n",
      "\n",
      "Example 3: she wanted to show it off to everybody – ‘I’m the captain’ – and she’d be dragging children, parents on [to it] and that was just the way she was << about>> her job, how passionate she was << about>> it. She << wanted>> everybody to know about it, she was so proud << of>> her team and her helicopter and she << wanted>> everybody to know about it,” he said.\n",
      "\n",
      "Capt Fitzpatrick worked for CHC, a private company providing helicopter search and rescue capability to the Irish Coast Guard. On Monday night, her Sikorsky helicopter, Rescue 116, was deployed from Dublin to give “top cover\n",
      "\n",
      "Example 4: adopted from Korea when she was 7½ months old, grew up in Milwaukee, Wis., and now lives in Queens. April 2017.Credit: Mengwen Cao\n",
      "\n",
      "Emily Roe, now 26, in her apartment in Brooklyn. She was adopted << from>> China << when>> she was 4 months old, grew up in Connecticut and moved to New York to study fashion and textile design at Pratt Institute <<.>> April 2017.\n",
      "\n",
      "Credit: Mengwen Cao\n",
      "\n",
      "Emily Roe, now 26, in her apartment in Brooklyn <<.>> She was adopted from China << when>> she was 4 months old, grew up in Connecticut\n",
      "\n",
      "Example 5: On to part 2 of theReal Housewives of New York City. The drama raged on for the housewives as we get a continuation of the ladies rehashing what went down this season.\n",
      "\n",
      "We start of with Jill, who stormed off the set in Part 1, returning and apologizing. The verbal smackdown on Jill continues, and Alex states the obvious that she believes the sole reason Jill wanted to make up with Bethenny is because of the public backlash. Jill makes a point, an excellent one at that, when she says she << wanted>> to << make>> << up>> << with>> Bethenny << while>> the show was still filming\n",
      "\n",
      "Example 6: While << her>> boyfriend is sleeping, Codi << decides>> that she is very horny and needs him << inside>> her! So she w <<akes>> him up with a two fisted handjob and his cock gets so hard from her stroking. She even l <<icks>> his big dick for some wet friction and then when he's ready to cum, Codi milks him of his jizz and gets her mouth fulled up with cum!Most accomplished black skiers\n",
      "\n",
      "Share via e-mail\n",
      "\n",
      "Ralph Green of the United States competed in the Mens Slalom Standing during day 13 of the Winter Games NZ in New Zeland.\n",
      "\n",
      "\n",
      "\n",
      "Example 7: story online. Though she considered herself very conservative with money (“All of my retirement accounts are in index funds”), she << was>> inexplicably drawn << to>> PredictIt. She << liked>> deb <<ating>> in the comments section, where the anonymity << allowed>> her to come out of her shell and blow off steam. “I could call people stupid, which I would never do in real life.”\n",
      "\n",
      "She also loved that she could blend science and current events to make money. She was drawn to the polling markets, where traders tried to predict what polls would say before they were released. The markets were very mathematical, which appealed to Kay. She realized that understanding the\n",
      "\n",
      "Example 8: great! There's nothing wrong with a happy ending. Please don't leave yet…\" Yang almost whispered the last part. She didn't know why she was << asking>> Blake to stay, she had only just met the girl two hours ago after all. Maybe it was because Yang had been enjoying Blake's company. Maybe it was because she knew that after this she would never see Blake again <<,>> and she didn't << want>> that. Whatever it was, all Yang knew was that she didn't << want>> Blake to << leave>> yet.\n",
      "\n",
      "Besides, it's still raining! Surely cats hate the…. wait, Blake's not a cat. Or at\n",
      "\n",
      "Example 9: that her marital experiences prevented her from being part << of>> a congregation or a religion. She did not << wish>> to have any specific faith imposed << upon>> her. God was very important for Helen in spite of this. Her relationship << with>> God, which she had not tried to manage without, had given her an inner strength. Her feedback on meeting << with>> the family therapist was that therapy had strengthened her faith in God. She felt that the therapist really met her.\n",
      "\n",
      "Helen, who had many different experiences of therapists, loved the fact that the therapist could understand her spiritual path. Previously, when she had not felt the spirituality of the therapist, Helen had\n",
      "\n",
      "Example 10: and friendly. She <<'s>> << got>> a brief respite << from>> back-to-back shoots — Vishal Bhardwaj's Haider starring Shahid Kapoor, The Villain with Sidharth Malhotra and a roster full of endorsements.\n",
      "\n",
      "Fidgeting with her thick-rimmed glasses (\"I'm a basic beauty girl: Cetaphil, Neutrogena and M.A.C,\" she << tells>> me), she << lets>> us in on what goes on in the life of an effervescent 26-year-old Juhu girl who now happens to be a bonafide movie star.\n",
      "\n",
      "\n",
      "############### Top dla tokens for Feature 15482:\n",
      " her herself she hers SheSheshe Her pregnancy woman\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############### Max act examples for Feature 11871:\n",
      "Example 1: of anybody I have ever coached.\n",
      "\n",
      "Whatever he << did>>, he << wanted>> << to>> << do>> better << than>> anybody else\"\n",
      "With Brown's talent and leadership, Manhasset High became a powerhouse in football, baseball, and lacrosse The students at the school were so impressed with their star athlete that they elected him chief justice of the high school court Even so, Brown admits that he did indulge in a bit of minor gang activity as a teenager-- chiefly breaking in on rival parties and fighting occasionally This mischief, however, did not impinge on his athletic career or his academic potential During most of his high school years he was a member of\n",
      "\n",
      "Example 2: had good stuff through three innings.\n",
      "\n",
      "\"He was executing pitches, and the next thing you know -- I don't know what he << grabbed>> -- but I << knew>> it was his arm. It's never a good sign, never a good feeling, to be out there and see a pitcher walk off the mound like that,\" Gattis said. \"On the last pitch, he just << threw>> a yanked changeup -- I've never seen that -- and immediately there was a problem.... He was << throwing>> good pitches, << and>> then it was just an out-of-the-blue kind of thing.\"\n",
      "\n",
      "STARTING TIME\n",
      "\n",
      "\n",
      "Example 3: glad to see Parnell go after some hitters.\n",
      "\n",
      "\"To see him out there for the first time and really << see>> him << let>> loose -- he's been a little tentative << in>> the 'pen and I understand it,\" Collins said. \"He << threw>> the ball great. The last five or six he << let>> the ball go good.\"\n",
      "\n",
      "LOOKING AHEAD\n",
      "\n",
      "The Mets will host the Marlins on Monday, but they won't face NL Rookie of the Year Jose Fernandez, who pitched against New York in Port St. Lucie last Wednesday. Miami manager Mike Redmond has opted to go with le\n",
      "\n",
      "Example 4: to fetch his sleeping bag but that he would << meet>> her at 5am that morning to walk her back to Euston station, from where she could get on the first train. She said she did not believe he would << return>>.\n",
      "\n",
      "But shortly after 5am, Mark came running to the cafe, having taken a bus to make sure he would be there to accompany her to the station.\n",
      "\n",
      "Nicole Sedgebeer was rescued by a homeless man at Euston Station after she missed her last train home (Getty Images)\n",
      "\n",
      "Nicole wrote: \"When I asked him << why>> he << did>> it he << said>> 'He\n",
      "\n",
      "Example 5: sensitive issues and to select which portions of their narratives are appropriate for their children to hear. Sometimes more than one session is required to model and practice the requisite skills.\n",
      "\n",
      "The *first family session* is devoted to sharing family narratives and addressing differences in experiences and interpretations across the family. This session usually has the children sharing their timelines or timemaps with the parents invited to share their experiences or clarify misunderstandings or misattributions. In the current example, the father was relieved and actually touched to hear that his son avoided him when he said goodbye << because>> he was so upset and << afraid>> << that>> he would << disappoint>> his dad << if>> he\n",
      "\n",
      "Example 6: Roland Emmerich, but Christopher Nolan! The guy who made Memento and Following!\n",
      "\n",
      "Nolan's next movie isn't even announced yet and I'm already excited about it, because I can look at his IMDb credits and << see>> << that>> he hasn't << made>> a bad film. The last non-Batman film he << made>> was about dreams, and the creative process, and spinning tops, I think, and it was one of the most exciting action movies of the last 20 years. He's << in>> a position where literally every studio will open up their wallets to fund any idea he has, and every single A\n",
      "\n",
      "Example 7: at lunchtime. The Furry Boy will be joining you tomorrow and he << tells>> me that he << has>> a goodie give-away.....did he << ask>> permission to delve << into>> my crafty stash again....not on your nelly but according to him he's << in>> charge of the cubbyhole at the moment so I have no say in the matter....cheeky blighter.\n",
      "\n",
      "Friday, October 29, 2010\n",
      "\n",
      "Morning folks.....that's Day 1 under my belt....all set for another fun filled Fiskars Day and another Simply Create DT project to share with you......a card to match yesterday's Mem\n",
      "\n",
      "Example 8: the next weekend when the Packers came to town. He was a healthy scratch.\n",
      "\n",
      "That decision was a big one for Agholor, but also for Pederson.\n",
      "\n",
      "\"I think it was definitely big on both our parts because it was the first time I've really had to sort of bench a player for the performance or whatever or just the sort of the slump that he was << in>>,\" Pederson said. \"I really think that it was a great - it was a wakeup call I think for him, but he << embraced>> it the right way. Part << of>> the conversation that he << and>> I had leading up << to>> me\n",
      "\n",
      "Example 9: we visit this superb venue John always << makes>> sure all the chairs are out and no request is too small for him << to>> << help>> << us>> << with>>.\n",
      "\n",
      "One of the most incredible occurrences that happened at The Old Nick was when a group of ghost hunters were calling in a circle around a table out in the theatre, when all of a sudden in the corner of the room a really loud noise was heard, immediately Simply Ghost Nights experienced paranormal investigator Mark shone his torch in the area of the noise and to his and Rosey's, Martin, Hannah, Sue's and Mandy's astonishment they all clearly saw a chair moving as if it\n",
      "\n",
      "Example 10: by, some noticing him and others either ignoring him intentionally or unaware that he was there or not caring whatsoever. A sense of bewilderment came over him. He had << expected>> too much << of>> the people of Teirlin’pur. He << expected>> savages as evil and maniacal as Luthien, << yet>> here he could clearly << see>> that the people of Teirlin’pur were actually not unlike the people of ArlinCity, despite the difference in races. People here seemed so alike to the people of ArlinCity in how they moved and acted. They walked and talked amongst themselves as if no war had ever been started,\n",
      "\n",
      "\n",
      "############### Top dla tokens for Feature 11871:\n",
      " his himself hehimself His himHishis He\\]\\].\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############### Max act examples for Feature 2419:\n",
      "Example 1: noise.@  << She>> indicated that << she>> thought the victim was\n",
      "gagging on her own blood.\n",
      "Anthony Lopez, who was living with Flores=s\n",
      "mother at the time, testified that the victim was in and out of their house all\n",
      "the time.  He stated that he spent all of\n",
      "Super Bowl Sunday drinking, a super bowl tradition.  He said he went to bed about 9:30 p.m.  He indicated he was subsequently awakened by\n",
      "his daughter banging on his bedroom door. \n",
      "He said Flores came to his bedroom\n",
      "carrying a shotgun and saying\n",
      "\n",
      "Example 2: this victory.\n",
      "\n",
      "Also saluting the late leaders of the Resistance, << She>>ikh Ragheb Harb, Sayyed Abbas Moussawi, Haj Imad Moghnieh, and absented Imam Moussa Sadr, Sayyed Nasrallah assured that if it were not for these leaders who established the Resistance movement, all the victories would not have been achieved.\n",
      "\n",
      "July War Aim: Eliminating the Resistance\n",
      "The Resistance leader pointed out that the July war was a main part of a bigger plot to give birth to a \"New Middle East\".\n",
      "\n",
      "\"A lot has been\n",
      "\n",
      "Example 3: be there.\" He left when Young told him to. When Young came out a few minutes later, he said \" <<She>> liked it.\" They called a cab. Young had nothing in his hands. Boston also stated that Young put nothing over the woman's head, just his hand over her mouth and told her to keep quiet. Young was still holding the woman when Boston left. Young's version was that when the woman woke up << she>> recognized him and smiled. << She>> put her arms around his neck and made no outcry. He did not explain the scratches.\n",
      "We find little in the statements of Bowler and Boston to contradict his own\n",
      "\n",
      "Example 4:                                           3\n",
      "\fjust did not get back up[.]\" At that point (about 4:30 a.m.), Victim \"was able to get out of\n",
      "\n",
      "the room and call the police.\"\n",
      "\n",
      "        Springfield Police Officer Brandon Bowling was dispatched to Victim's address at\n",
      "\n",
      "around 4:40 a.m., where he found Victim standing on the front porch. \" <<She>> seemed shaken,\n",
      "\n",
      "[and << she>>] appeared as if << she>>'d been crying.\" Officer Bowling found Defendant lying asleep\n",
      "\n",
      "on Victim's bedroom floor. The officer awakened Defendant and placed him under arrest.\n",
      "\n",
      "\n",
      "Example 5: pray for peace and communal amity in the country. << She>> said thousands of people come to Delhi every year to go for the Haj pilgrimage. But all of them were not given permission, as there was limited seats for Delhi.\n",
      "\n",
      "New Delhi, November 22\n",
      "The MCD Standing Committee, at its meeting today, resolved to carry out a survey to identify 1,000 additional roads to notify them for commercial or mixed land use. The survey would be completed within ten days.\n",
      "\n",
      "The decision was taken after a resolution was tabled before the committee by the Leader of the House, Mr Jitender Kochar.\n",
      "\n",
      "Example 6: cities (Manchester, Belfast, Glasgow and Edinburgh). << She>> met council officials and media outlets, and set up meetings with Eric Pickles, secretary of state for communities and local government, under secretary Don Foster and other officials, all, << she>> says, listed in her report.\n",
      "\n",
      "The trouble started when Rolnik observed that the bedroom tax (where people must pay for \"spare\" rooms through a deduction in their housing benefit) is causing great hardship and distress to the most vulnerable. Some people << she>> spoke to were in tears; some said they even contemplated suicide, because they had nowhere to downsize to – owing to a\n",
      "\n",
      "Example 7: a call from an unknown number, a really worried voice from a lady I didn’t know,” he says. “ <<She>> said, ‘My fiance Jamal Khashoggi went into the Saudi consulate and didn’t co me out.'”\n",
      "\n",
      "Dr Yasin Aklay Dr Yasin Aklay\n",
      "\n",
      "Yasin swiftly called the head of Turkish intelligence and alerted the office of President Tayyip Erdogan.\n",
      "\n",
      "By 18:30, the members of the hit squad were on a private jet to Ryiadh, less than 24 hours after they had arrived.\n",
      "\n",
      "The next day,\n",
      "\n",
      "Example 8: and injuries to protestors. No official death total has been released, but the latest reports today have two women being killed when hit in the head by tear gas and another died in Tahir Square. That would bring an unofficial death toll over the past four days to over 10. In one instance, Amnesty has learned that 22-year-old Ahmed Atef was killed yesterday in North Sinai when security forces in the town of << She>>ikh Zuweid opened fire on a crowd of more than 1000 demonstrators.\n",
      "\n",
      "2. Independent legal observers count the number of detained as of Thursday at around 1,200 people.\n",
      "\n",
      "Example 9: to form leaders capable of “responding to the demands of living in the American cultural context as a people of faith,” and helping others do the same.\n",
      "\n",
      " <<She>> is one of two MAFC students to join 298 undergraduates and 739 graduates at the University’s 64th Commencement Ceremony at Reliant Arena on May 17.\n",
      "\n",
      "Before graduating, MFAC candidates must complete a practicum that incorporates all they have studied into a community-oriented, service-learning project, one that illustrates the integration of faith development and civic responsibility.\n",
      "\n",
      "For her practicum, Egea chose to work for two\n",
      "\n",
      "Example 10: again by their families or contacts.\n",
      "\n",
      "Purgatory is minimally armed with GARDIAN defenses. Though a cruiser-weight ship, it relies on the Blue Suns' fighters to prevent any attacks bent on a jailbreak or similar events.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mission Edit\n",
      "\n",
      "Upon arrival to the Purgatory, << She>>pard is informed that the \"package\" is being prepared. Warden Kuril indicates that Cerberus paid for Jack's release. << She>>pard is directed to the Outprocessing area of the ship. On the way to outprocessing, << She>>pard has the opportunity to stop the brutal interrogation of a prisoner called B\n",
      "\n",
      "\n",
      "############### Top dla tokens for Feature 2419:\n",
      "pherdpherffieldduleikh herselfathedttypard'll\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, feat_examples in enumerate(example_prompts):\n",
    "    print(f'############### Max act examples for Feature {top_k_indices[i]}:')\n",
    "    print(feat_examples)\n",
    "    print(f'############### Top dla tokens for Feature {top_k_indices[i]}:')\n",
    "    print(top_dla_tokens_FK[i])\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render prompt for human labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 15482:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-70e2b4c0-31ab\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-70e2b4c0-31ab\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"the\", \" broker\", \" and\", \" said\", \" yes\", \".\", \"\\n\", \"\\n\", \"She\", \" told\", \" her\", \" younger\", \" sister\", \" she\", \" was\", \" going\", \" to\", \" America\", \" for\", \" work\", \",\", \" but\", \" to\", \" keep\", \" it\", \" a\", \" secret\", \" from\", \" her\", \" parents\", \",\", \" who\", \" would\", \" never\", \" grant\", \" her\", \" permission\", \" to\", \" work\", \" abroad\", \".\", \" You\", \" Mi\", \" told\", \" her\", \" parents\", \" she\", \" was\", \" going\", \" to\", \" Seoul\", \" to\", \" be\", \" a\", \" golf\", \" c\", \"addy\", \" --\", \" one\", \" of\", \" the\", \" few\", \" legal\", \" women\", \"'s\", \" jobs\", \" that\", \" bring\", \" he\", \"fty\", \" tips\", \" from\", \" rich\", \" men\", \".\", \"\\n\", \"\\n\", \"She\", \" planned\", \" to\", \" tell\", \" them\", \" the\", \" truth\", \" after\", \" she\", \" paid\", \" off\", \" her\", \" debts\", \".\", \"\\n\", \"\\n\", \"You\", \" Mi\", \" was\", \" instructed\", \" to\", \" take\", \" passport\", \" photos\", \" and\", \" give\", \" them\", \" to\", \" a\", \" man\", \" named\", \" Kevin\", \" in\", \" Seoul\", \".\", \" The\", \" broker\", \" drove\", \" her\", \" to\", \" the\", \" city\", \",\", \" and\", \" two\", \" days\", \" later\", \",\", \" You\", \" Mi\", \" had\"], [\"(\", \"every\", \"one\", \" was\", \" wearing\", \" hop\", \"-\", \"b\", \"ought\", \" clothes\", \".\", \" What\", \" is\", \" the\", \" world\", \" coming\", \" to\", \"?).\", \" I\", \" thought\", \" she\", \"'d\", \" lost\", \" when\", \" an\", \" even\", \" l\", \"itt\", \"ler\", \" girl\", \" appeared\", \" dressed\", \" as\", \" a\", \" b\", \"umble\", \" bee\", \" -\", \" but\", \" she\", \" hung\", \" onto\", \" m\", \"ummy\", \" the\", \" whole\", \" time\", \",\", \" and\", \" wouldn\", \"'t\", \" talk\", \" or\", \" look\", \" at\", \" the\", \" audience\", \",\", \" whereas\", \" L\", \"MD\", \" went\", \" up\", \" on\", \" her\", \" own\", \",\", \" yelled\", \" her\", \" age\", \" down\", \" the\", \" microphone\", \",\", \" and\", \" round\", \"ly\", \" told\", \" off\", \" anyone\", \" who\", \" tried\", \" to\", \" steal\", \" her\", \" moment\", \" of\", \" fame\", \":\", \"-)\", \" L\", \"MB\", \" also\", \" got\", \" to\", \" win\", \" one\", \" of\", \" the\", \" p\", \"alt\", \"ry\", \" prizes\", \" of\", \" \\\"\", \"a\", \" foil\", \" mask\", \"\\\"\", \" by\", \" winning\", \" hide\", \" and\", \" seek\", \" on\", \" the\", \" last\", \" day\", \".\", \" Ad\", \"mitted\", \"ly\", \" I\", \" found\", \" the\", \" hiding\", \" place\", \" -\"], [\"she\", \" wanted\", \" to\", \" show\", \" it\", \" off\", \" to\", \" everybody\", \" \\u2013\", \" \\u2018\", \"I\", \"\\u2019\", \"m\", \" the\", \" captain\", \"\\u2019\", \" \\u2013\", \" and\", \" she\", \"\\u2019\", \"d\", \" be\", \" dragging\", \" children\", \",\", \" parents\", \" on\", \" [\", \"to\", \" it\", \"]\", \" and\", \" that\", \" was\", \" just\", \" the\", \" way\", \" she\", \" was\", \" about\", \" her\", \" job\", \",\", \" how\", \" passionate\", \" she\", \" was\", \" about\", \" it\", \".\", \" She\", \" wanted\", \" everybody\", \" to\", \" know\", \" about\", \" it\", \",\", \" she\", \" was\", \" so\", \" proud\", \" of\", \" her\", \" team\", \" and\", \" her\", \" helicopter\", \" and\", \" she\", \" wanted\", \" everybody\", \" to\", \" know\", \" about\", \" it\", \",\\u201d\", \" he\", \" said\", \".\", \"\\n\", \"\\n\", \"Capt\", \" Fitz\", \"patrick\", \" worked\", \" for\", \" CH\", \"C\", \",\", \" a\", \" private\", \" company\", \" providing\", \" helicopter\", \" search\", \" and\", \" rescue\", \" capability\", \" to\", \" the\", \" Irish\", \" Coast\", \" Guard\", \".\", \" On\", \" Monday\", \" night\", \",\", \" her\", \" S\", \"ik\", \"ors\", \"ky\", \" helicopter\", \",\", \" Rescue\", \" 116\", \",\", \" was\", \" deployed\", \" from\", \" Dublin\", \" to\", \" give\", \" \\u201c\", \"top\", \" cover\"], [\"ad\", \"opt\", \"ed\", \" from\", \" Korea\", \" when\", \" she\", \" was\", \" 7\", \"\\u00bd\", \" months\", \" old\", \",\", \" grew\", \" up\", \" in\", \" Milwaukee\", \",\", \" Wis\", \".,\", \" and\", \" now\", \" lives\", \" in\", \" Queens\", \".\", \" April\", \" 2017\", \".\", \"Credit\", \":\", \" M\", \"eng\", \"wen\", \" Ca\", \"o\", \"\\n\", \"\\n\", \"Em\", \"ily\", \" R\", \"oe\", \",\", \" now\", \" 26\", \",\", \" in\", \" her\", \" apartment\", \" in\", \" Brooklyn\", \".\", \" She\", \" was\", \" adopted\", \" from\", \" China\", \" when\", \" she\", \" was\", \" 4\", \" months\", \" old\", \",\", \" grew\", \" up\", \" in\", \" Connecticut\", \" and\", \" moved\", \" to\", \" New\", \" York\", \" to\", \" study\", \" fashion\", \" and\", \" textile\", \" design\", \" at\", \" Pr\", \"att\", \" Institute\", \".\", \" April\", \" 2017\", \".\", \"\\n\", \"\\n\", \"Credit\", \":\", \" M\", \"eng\", \"wen\", \" Ca\", \"o\", \"\\n\", \"\\n\", \"Em\", \"ily\", \" R\", \"oe\", \",\", \" now\", \" 26\", \",\", \" in\", \" her\", \" apartment\", \" in\", \" Brooklyn\", \".\", \" She\", \" was\", \" adopted\", \" from\", \" China\", \" when\", \" she\", \" was\", \" 4\", \" months\", \" old\", \",\", \" grew\", \" up\", \" in\", \" Connecticut\"], [\"On\", \" to\", \" part\", \" 2\", \" of\", \" the\", \"Real\", \" House\", \"wives\", \" of\", \" New\", \" York\", \" City\", \".\", \" The\", \" drama\", \" r\", \"aged\", \" on\", \" for\", \" the\", \" house\", \"wives\", \" as\", \" we\", \" get\", \" a\", \" continuation\", \" of\", \" the\", \" ladies\", \" re\", \"h\", \"ashing\", \" what\", \" went\", \" down\", \" this\", \" season\", \".\", \"\\n\", \"\\n\", \"We\", \" start\", \" of\", \" with\", \" Jill\", \",\", \" who\", \" storm\", \"ed\", \" off\", \" the\", \" set\", \" in\", \" Part\", \" 1\", \",\", \" returning\", \" and\", \" apolog\", \"izing\", \".\", \" The\", \" verbal\", \" sm\", \"ack\", \"down\", \" on\", \" Jill\", \" continues\", \",\", \" and\", \" Alex\", \" states\", \" the\", \" obvious\", \" that\", \" she\", \" believes\", \" the\", \" sole\", \" reason\", \" Jill\", \" wanted\", \" to\", \" make\", \" up\", \" with\", \" Bet\", \"hen\", \"ny\", \" is\", \" because\", \" of\", \" the\", \" public\", \" backlash\", \".\", \" Jill\", \" makes\", \" a\", \" point\", \",\", \" an\", \" excellent\", \" one\", \" at\", \" that\", \",\", \" when\", \" she\", \" says\", \" she\", \" wanted\", \" to\", \" make\", \" up\", \" with\", \" Bet\", \"hen\", \"ny\", \" while\", \" the\", \" show\", \" was\", \" still\", \" filming\"], [\"While\", \" her\", \" boyfriend\", \" is\", \" sleeping\", \",\", \" C\", \"odi\", \" decides\", \" that\", \" she\", \" is\", \" very\", \" horn\", \"y\", \" and\", \" needs\", \" him\", \" inside\", \" her\", \"!\", \" So\", \" she\", \" w\", \"akes\", \" him\", \" up\", \" with\", \" a\", \" two\", \" f\", \"isted\", \" hand\", \"job\", \" and\", \" his\", \" cock\", \" gets\", \" so\", \" hard\", \" from\", \" her\", \" stro\", \"king\", \".\", \" She\", \" even\", \" l\", \"icks\", \" his\", \" big\", \" dick\", \" for\", \" some\", \" wet\", \" friction\", \" and\", \" then\", \" when\", \" he\", \"'s\", \" ready\", \" to\", \" cum\", \",\", \" C\", \"odi\", \" mil\", \"ks\", \" him\", \" of\", \" his\", \" j\", \"izz\", \" and\", \" gets\", \" her\", \" mouth\", \" full\", \"ed\", \" up\", \" with\", \" cum\", \"!\", \"Most\", \" accomplished\", \" black\", \" sk\", \"iers\", \"\\n\", \"\\n\", \"Share\", \" via\", \" e\", \"-\", \"mail\", \"\\n\", \"\\n\", \"R\", \"alph\", \" Green\", \" of\", \" the\", \" United\", \" States\", \" competed\", \" in\", \" the\", \" Mens\", \" Sl\", \"al\", \"om\", \" Standing\", \" during\", \" day\", \" 13\", \" of\", \" the\", \" Winter\", \" Games\", \" NZ\", \" in\", \" New\", \" Z\", \"eland\", \".\", \"\\n\", \"\\n\"], [\"story\", \" online\", \".\", \" Though\", \" she\", \" considered\", \" herself\", \" very\", \" conservative\", \" with\", \" money\", \" (\\u201c\", \"All\", \" of\", \" my\", \" retirement\", \" accounts\", \" are\", \" in\", \" index\", \" funds\", \"\\u201d),\", \" she\", \" was\", \" inex\", \"plic\", \"ably\", \" drawn\", \" to\", \" Predict\", \"It\", \".\", \" She\", \" liked\", \" deb\", \"ating\", \" in\", \" the\", \" comments\", \" section\", \",\", \" where\", \" the\", \" anonymity\", \" allowed\", \" her\", \" to\", \" come\", \" out\", \" of\", \" her\", \" shell\", \" and\", \" blow\", \" off\", \" steam\", \".\", \" \\u201c\", \"I\", \" could\", \" call\", \" people\", \" stupid\", \",\", \" which\", \" I\", \" would\", \" never\", \" do\", \" in\", \" real\", \" life\", \".\\u201d\", \"\\n\", \"\\n\", \"She\", \" also\", \" loved\", \" that\", \" she\", \" could\", \" blend\", \" science\", \" and\", \" current\", \" events\", \" to\", \" make\", \" money\", \".\", \" She\", \" was\", \" drawn\", \" to\", \" the\", \" polling\", \" markets\", \",\", \" where\", \" traders\", \" tried\", \" to\", \" predict\", \" what\", \" polls\", \" would\", \" say\", \" before\", \" they\", \" were\", \" released\", \".\", \" The\", \" markets\", \" were\", \" very\", \" mathematical\", \",\", \" which\", \" appealed\", \" to\", \" Kay\", \".\", \" She\", \" realized\", \" that\", \" understanding\", \" the\"], [\"great\", \"!\", \" There\", \"'s\", \" nothing\", \" wrong\", \" with\", \" a\", \" happy\", \" ending\", \".\", \" Please\", \" don\", \"'t\", \" leave\", \" yet\", \"\\u2026\", \"\\\"\", \" Yang\", \" almost\", \" whispered\", \" the\", \" last\", \" part\", \".\", \" She\", \" didn\", \"'t\", \" know\", \" why\", \" she\", \" was\", \" asking\", \" Blake\", \" to\", \" stay\", \",\", \" she\", \" had\", \" only\", \" just\", \" met\", \" the\", \" girl\", \" two\", \" hours\", \" ago\", \" after\", \" all\", \".\", \" Maybe\", \" it\", \" was\", \" because\", \" Yang\", \" had\", \" been\", \" enjoying\", \" Blake\", \"'s\", \" company\", \".\", \" Maybe\", \" it\", \" was\", \" because\", \" she\", \" knew\", \" that\", \" after\", \" this\", \" she\", \" would\", \" never\", \" see\", \" Blake\", \" again\", \",\", \" and\", \" she\", \" didn\", \"'t\", \" want\", \" that\", \".\", \" Whatever\", \" it\", \" was\", \",\", \" all\", \" Yang\", \" knew\", \" was\", \" that\", \" she\", \" didn\", \"'t\", \" want\", \" Blake\", \" to\", \" leave\", \" yet\", \".\", \"\\n\", \"\\n\", \"Besides\", \",\", \" it\", \"'s\", \" still\", \" ra\", \"ining\", \"!\", \" Surely\", \" cats\", \" hate\", \" the\", \"\\u2026.\", \" wait\", \",\", \" Blake\", \"'s\", \" not\", \" a\", \" cat\", \".\", \" Or\", \" at\"], [\"that\", \" her\", \" marital\", \" experiences\", \" prevented\", \" her\", \" from\", \" being\", \" part\", \" of\", \" a\", \" congregation\", \" or\", \" a\", \" religion\", \".\", \" She\", \" did\", \" not\", \" wish\", \" to\", \" have\", \" any\", \" specific\", \" faith\", \" imposed\", \" upon\", \" her\", \".\", \" God\", \" was\", \" very\", \" important\", \" for\", \" Helen\", \" in\", \" spite\", \" of\", \" this\", \".\", \" Her\", \" relationship\", \" with\", \" God\", \",\", \" which\", \" she\", \" had\", \" not\", \" tried\", \" to\", \" manage\", \" without\", \",\", \" had\", \" given\", \" her\", \" an\", \" inner\", \" strength\", \".\", \" Her\", \" feedback\", \" on\", \" meeting\", \" with\", \" the\", \" family\", \" therapist\", \" was\", \" that\", \" therapy\", \" had\", \" strengthened\", \" her\", \" faith\", \" in\", \" God\", \".\", \" She\", \" felt\", \" that\", \" the\", \" therapist\", \" really\", \" met\", \" her\", \".\", \"\\n\", \"\\n\", \"Hel\", \"en\", \",\", \" who\", \" had\", \" many\", \" different\", \" experiences\", \" of\", \" therapists\", \",\", \" loved\", \" the\", \" fact\", \" that\", \" the\", \" therapist\", \" could\", \" understand\", \" her\", \" spiritual\", \" path\", \".\", \" Previously\", \",\", \" when\", \" she\", \" had\", \" not\", \" felt\", \" the\", \" spirituality\", \" of\", \" the\", \" therapist\", \",\", \" Helen\", \" had\"], [\"and\", \" friendly\", \".\", \" She\", \"'s\", \" got\", \" a\", \" brief\", \" resp\", \"ite\", \" from\", \" back\", \"-\", \"to\", \"-\", \"back\", \" shoots\", \" \\u2014\", \" V\", \"ish\", \"al\", \" B\", \"hard\", \"w\", \"aj\", \"'s\", \" Ha\", \"ider\", \" starring\", \" Shah\", \"id\", \" Kap\", \"oor\", \",\", \" The\", \" Vill\", \"ain\", \" with\", \" Sid\", \"h\", \"arth\", \" Mal\", \"hot\", \"ra\", \" and\", \" a\", \" roster\", \" full\", \" of\", \" endorse\", \"ments\", \".\", \"\\n\", \"\\n\", \"F\", \"idget\", \"ing\", \" with\", \" her\", \" thick\", \"-\", \"rim\", \"med\", \" glasses\", \" (\\\"\", \"I\", \"'m\", \" a\", \" basic\", \" beauty\", \" girl\", \":\", \" C\", \"et\", \"aph\", \"il\", \",\", \" Neut\", \"rogen\", \"a\", \" and\", \" M\", \".\", \"A\", \".\", \"C\", \",\\\"\", \" she\", \" tells\", \" me\", \"),\", \" she\", \" lets\", \" us\", \" in\", \" on\", \" what\", \" goes\", \" on\", \" in\", \" the\", \" life\", \" of\", \" an\", \" eff\", \"erves\", \"cent\", \" 26\", \"-\", \"year\", \"-\", \"old\", \" J\", \"uh\", \"u\", \" girl\", \" who\", \" now\", \" happens\", \" to\", \" be\", \" a\", \" bon\", \"af\", \"ide\", \" movie\", \" star\", \".\"]], \"activations\": [[[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.76171875]], [[3.375]], [[1.6328125]], [[1.7578125]], [[1.9921875]], [[2.0]], [[2.5625]], [[2.828125]], [[3.125]], [[2.5]], [[2.921875]], [[2.40625]], [[2.609375]], [[3.84375]], [[3.171875]], [[3.734375]], [[1.8671875]], [[1.78125]], [[2.40625]], [[2.875]], [[1.796875]], [[1.890625]], [[2.53125]], [[2.28125]], [[2.828125]], [[1.7421875]], [[2.734375]], [[1.1875]], [[1.4609375]], [[2.09375]], [[2.375]], [[2.171875]], [[2.984375]], [[1.375]], [[1.15625]], [[3.046875]], [[1.84375]], [[1.640625]], [[1.75]], [[2.265625]], [[2.34375]], [[2.625]], [[1.96875]], [[2.34375]], [[1.984375]], [[2.09375]], [[1.734375]], [[1.0390625]], [[1.5859375]], [[2.09375]], [[1.4140625]], [[2.171875]], [[1.28125]], [[0.99609375]], [[1.1015625]], [[1.1640625]], [[1.5234375]], [[1.1953125]], [[1.53125]], [[1.640625]], [[0.78515625]], [[0.94921875]], [[0.92578125]], [[1.2578125]], [[0.0]], [[0.0]], [[2.5625]], [[1.5078125]], [[2.140625]], [[1.671875]], [[2.828125]], [[2.46875]], [[4.25]], [[1.984375]], [[1.53125]], [[1.7109375]], [[2.609375]], [[1.890625]], [[2.75]], [[2.453125]], [[1.2890625]], [[1.46875]], [[3.046875]], [[1.3515625]], [[2.765625]], [[0.734375]], [[1.5234375]], [[1.703125]], [[1.7734375]], [[1.3671875]], [[1.34375]], [[0.0]], [[1.359375]], [[1.1953125]], [[1.7421875]], [[1.2109375]], [[1.390625]], [[0.9453125]], [[0.828125]], [[0.0]], [[0.0]], [[0.84375]], [[1.171875]], [[1.203125]], [[0.0]], [[0.0]], [[0.87890625]], [[0.73828125]], [[1.578125]], [[1.21875]], [[0.82421875]], [[0.83203125]], [[1.546875]], [[0.875]], [[0.0]], [[1.375]], [[1.046875]], [[0.0]], [[0.0]], [[1.15625]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1328125]], [[2.546875]], [[3.203125]], [[4.15625]], [[1.546875]], [[1.1171875]], [[0.6640625]], [[0.59765625]], [[1.15625]], [[1.84375]], [[2.390625]], [[2.0625]], [[2.203125]], [[1.765625]], [[1.09375]], [[0.0]], [[1.1171875]], [[2.0625]], [[2.4375]], [[2.046875]], [[2.390625]], [[3.265625]], [[0.7421875]], [[0.9453125]], [[1.1328125]], [[1.4453125]], [[1.9296875]], [[1.703125]], [[2.140625]], [[1.3515625]], [[2.234375]], [[2.0625]], [[1.28125]], [[1.8046875]], [[2.515625]], [[1.515625]], [[1.1328125]], [[1.75]], [[2.625]], [[1.046875]], [[1.2109375]], [[1.2109375]], [[1.0234375]], [[1.4296875]], [[0.7890625]], [[1.0703125]], [[1.484375]], [[1.453125]], [[0.796875]], [[1.3515625]], [[1.046875]], [[0.91015625]], [[1.2109375]], [[1.296875]], [[1.828125]], [[1.6640625]], [[0.9453125]], [[2.640625]], [[1.65625]], [[0.79296875]], [[1.0625]], [[1.0234375]], [[1.1953125]], [[1.1796875]], [[0.7734375]], [[1.2890625]], [[1.3671875]], [[1.53125]], [[1.3828125]], [[0.94921875]], [[0.71875]], [[0.0]], [[1.375]], [[1.34375]], [[1.203125]], [[1.1640625]], [[0.7109375]], [[1.609375]], [[0.7890625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.375]], [[0.5703125]], [[0.0]], [[0.0]], [[0.0]], [[0.671875]], [[0.6171875]], [[0.765625]], [[0.0]], [[0.0]], [[0.0]], [[1.015625]], [[0.0]], [[0.0]], [[0.0]], [[1.234375]], [[0.0]], [[1.4375]], [[0.94921875]], [[1.2265625]], [[1.296875]], [[0.8515625]], [[0.0]], [[0.0]], [[0.6796875]]], [[[1.5703125]], [[1.90625]], [[1.890625]], [[2.0625]], [[1.484375]], [[1.6484375]], [[1.40625]], [[1.25]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.79296875]], [[0.0]], [[1.875]], [[1.5]], [[2.1875]], [[1.953125]], [[2.9375]], [[1.1953125]], [[1.96875]], [[0.85546875]], [[1.0625]], [[1.359375]], [[0.0]], [[0.74609375]], [[0.0]], [[0.94921875]], [[1.6484375]], [[1.3671875]], [[1.6953125]], [[0.95703125]], [[2.203125]], [[2.171875]], [[2.703125]], [[3.375]], [[1.703125]], [[2.25]], [[2.4375]], [[2.921875]], [[2.890625]], [[2.453125]], [[3.234375]], [[3.6875]], [[2.28125]], [[0.7421875]], [[1.984375]], [[4.125]], [[2.140625]], [[1.90625]], [[2.859375]], [[2.640625]], [[1.3359375]], [[2.328125]], [[1.25]], [[2.359375]], [[2.53125]], [[2.71875]], [[3.78125]], [[1.765625]], [[1.953125]], [[2.96875]], [[1.6015625]], [[1.4921875]], [[2.5625]], [[1.90625]], [[3.5]], [[1.9453125]], [[2.046875]], [[2.5]], [[2.234375]], [[1.359375]], [[1.5703125]], [[1.0546875]], [[1.4140625]], [[1.4765625]], [[1.359375]], [[1.3359375]], [[0.7421875]], [[0.0]], [[1.15625]], [[1.25]], [[1.2265625]], [[0.91015625]], [[0.0]], [[0.0]], [[0.7890625]], [[0.71875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.8359375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7734375]], [[0.91015625]], [[0.83203125]], [[0.0]], [[0.0]], [[0.0]], [[0.8671875]], [[0.0]], [[0.83984375]], [[0.0]], [[0.0]], [[0.79296875]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1171875]], [[1.6796875]], [[1.5859375]], [[0.0]], [[1.7265625]], [[1.9453125]], [[1.3359375]], [[1.6171875]], [[1.2421875]], [[1.1640625]], [[0.90625]], [[0.7734375]], [[0.0]], [[0.0]], [[1.2421875]], [[1.4609375]], [[1.3046875]], [[1.1328125]], [[0.69140625]], [[0.337890625]], [[0.486328125]], [[0.6640625]], [[0.59375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.65234375]], [[0.0]], [[1.0390625]], [[1.65625]], [[1.4921875]], [[1.796875]], [[2.15625]], [[2.296875]], [[1.5703125]], [[1.90625]], [[1.546875]], [[2.234375]], [[2.109375]], [[1.75]], [[2.765625]], [[2.140625]], [[2.765625]], [[3.03125]], [[3.125]], [[2.53125]], [[4.09375]], [[2.421875]], [[2.75]], [[2.484375]], [[2.140625]], [[2.640625]], [[2.828125]], [[2.609375]], [[2.4375]], [[2.15625]], [[1.8515625]], [[2.84375]], [[2.921875]], [[2.40625]], [[1.3125]], [[1.5703125]], [[2.109375]], [[2.53125]], [[2.0]], [[1.8984375]], [[1.5234375]], [[1.8515625]], [[1.90625]], [[0.8203125]], [[0.0]], [[0.859375]], [[3.28125]], [[1.9140625]], [[1.6953125]], [[2.203125]], [[2.015625]], [[2.03125]], [[1.1015625]], [[1.0234375]], [[1.328125]], [[1.21875]], [[0.98046875]], [[0.96484375]], [[0.9765625]], [[1.375]], [[2.21875]], [[1.875]], [[1.7109375]], [[1.8125]], [[2.171875]], [[2.421875]], [[2.0625]], [[2.453125]], [[1.7890625]], [[2.953125]], [[1.8359375]], [[1.9375]], [[2.203125]], [[1.875]], [[3.609375]], [[2.265625]], [[2.484375]], [[2.71875]], [[2.6875]], [[2.578125]], [[4.125]], [[2.0]], [[2.1875]], [[2.421875]], [[2.125]], [[2.40625]], [[2.265625]], [[2.515625]], [[2.40625]], [[2.03125]], [[1.8515625]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1484375]], [[0.96484375]], [[0.0]], [[0.52734375]], [[0.0]], [[0.58984375]], [[0.0]], [[0.0]], [[0.0]], [[0.78515625]], [[0.6171875]], [[0.859375]], [[0.0]], [[0.71484375]], [[1.09375]], [[0.0]], [[0.0]], [[0.91015625]], [[0.0]], [[0.5859375]], [[0.734375]], [[0.0]], [[0.8359375]], [[0.0]], [[0.796875]], [[0.69921875]], [[0.0]], [[0.0]], [[0.6171875]], [[0.765625]], [[0.53515625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.859375]], [[1.765625]], [[1.7890625]], [[2.171875]], [[2.09375]], [[1.2890625]], [[1.15625]], [[1.5390625]], [[0.734375]], [[0.90234375]], [[1.09375]], [[1.375]], [[1.21875]], [[0.0]], [[1.28125]], [[1.4609375]], [[0.921875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.703125]], [[0.0]], [[0.61328125]], [[0.828125]], [[1.0546875]], [[0.0]], [[1.125]], [[0.81640625]], [[0.0]], [[0.953125]], [[1.421875]], [[2.734375]], [[1.421875]], [[1.40625]], [[1.46875]], [[1.3984375]], [[3.0625]], [[2.578125]], [[3.0625]], [[2.546875]], [[3.03125]], [[0.99609375]], [[0.8515625]], [[0.9375]], [[1.96875]], [[2.90625]], [[2.328125]], [[1.53125]], [[1.0390625]], [[1.2109375]], [[1.8515625]], [[1.3046875]], [[2.765625]], [[1.8125]], [[1.46875]], [[1.546875]], [[1.671875]], [[1.359375]], [[1.234375]], [[1.5625]], [[1.4453125]], [[1.6953125]], [[2.171875]], [[1.890625]], [[3.171875]], [[2.265625]], [[3.8125]], [[3.015625]], [[3.484375]], [[3.46875]], [[3.921875]], [[1.984375]], [[2.078125]], [[2.578125]], [[4.09375]], [[2.390625]], [[2.15625]], [[2.15625]], [[1.84375]], [[2.640625]]], [[[0.0]], [[3.484375]], [[2.53125]], [[2.15625]], [[1.5625]], [[2.640625]], [[0.6171875]], [[1.1484375]], [[3.28125]], [[2.59375]], [[1.8515625]], [[2.296875]], [[1.8671875]], [[2.015625]], [[1.6953125]], [[2.578125]], [[2.90625]], [[1.9921875]], [[3.0625]], [[1.5390625]], [[2.953125]], [[2.46875]], [[1.859375]], [[1.5234375]], [[4.0]], [[1.8828125]], [[1.5625]], [[2.359375]], [[1.609375]], [[1.4453125]], [[0.77734375]], [[1.0859375]], [[1.578125]], [[2.0625]], [[2.140625]], [[1.6015625]], [[1.046875]], [[1.796875]], [[1.5625]], [[1.90625]], [[2.09375]], [[1.3203125]], [[1.515625]], [[2.421875]], [[0.875]], [[1.640625]], [[2.703125]], [[0.95703125]], [[3.40625]], [[1.6171875]], [[1.1171875]], [[1.9765625]], [[2.234375]], [[1.6953125]], [[1.2109375]], [[1.8125]], [[2.265625]], [[2.609375]], [[2.703125]], [[1.5859375]], [[1.8125]], [[2.0]], [[1.4296875]], [[1.5625]], [[2.46875]], [[1.1640625]], [[1.390625]], [[1.1796875]], [[1.609375]], [[1.3515625]], [[1.6015625]], [[0.0]], [[0.0]], [[1.4140625]], [[1.6484375]], [[1.8359375]], [[1.203125]], [[0.0]], [[1.03125]], [[1.59375]], [[1.4375]], [[1.8125]], [[1.0234375]], [[2.6875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7421875]], [[0.546875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.0078125]], [[2.65625]], [[1.4765625]], [[1.4375]], [[1.7421875]], [[2.296875]], [[1.8359375]], [[0.80859375]], [[0.91796875]], [[0.91015625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.359375]], [[2.5625]], [[3.703125]], [[1.890625]], [[1.7578125]], [[1.9765625]], [[2.328125]], [[3.984375]], [[1.953125]], [[1.640625]], [[2.75]], [[2.46875]], [[3.453125]], [[1.4765625]], [[3.453125]], [[3.1875]], [[1.5]], [[2.40625]], [[1.578125]], [[2.1875]], [[3.109375]], [[1.0390625]], [[1.40625]], [[3.265625]], [[1.265625]], [[2.140625]], [[1.9375]], [[2.078125]], [[2.515625]], [[0.765625]], [[1.3203125]], [[2.3125]], [[2.3125]], [[1.859375]], [[1.5546875]], [[3.046875]], [[1.3125]], [[0.7265625]], [[0.92578125]], [[1.2734375]], [[0.76171875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.203125]], [[0.80859375]], [[2.15625]], [[1.828125]], [[2.234375]], [[3.234375]], [[2.234375]], [[2.0]], [[2.28125]], [[2.03125]], [[1.5703125]], [[1.4921875]], [[1.8125]], [[1.7890625]], [[2.453125]], [[2.375]], [[2.046875]], [[3.109375]], [[2.15625]], [[2.8125]], [[1.8828125]], [[3.03125]], [[1.484375]], [[1.4453125]], [[1.71875]], [[2.234375]], [[2.25]], [[0.73046875]], [[0.0]], [[0.9453125]], [[0.88671875]], [[1.140625]], [[1.015625]], [[1.046875]], [[0.0]], [[1.3359375]], [[0.71484375]], [[0.9375]], [[1.4296875]], [[3.0625]], [[1.109375]], [[0.91796875]], [[1.3203125]], [[0.0]], [[0.0]], [[0.0]], [[2.25]], [[1.3671875]], [[2.703125]], [[0.0]], [[2.1875]], [[1.734375]], [[2.765625]], [[3.140625]], [[1.78125]], [[0.94921875]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.9375]], [[0.76171875]], [[0.0]], [[0.0]], [[0.62109375]], [[0.890625]], [[0.0]], [[1.828125]], [[2.0625]], [[2.625]], [[1.78125]], [[2.328125]], [[3.984375]], [[0.0]], [[1.4609375]], [[2.34375]], [[2.015625]], [[1.40625]], [[1.7890625]], [[1.671875]], [[1.328125]], [[2.25]], [[1.2421875]], [[1.4453125]], [[1.375]], [[1.3984375]], [[1.9453125]], [[2.3125]], [[2.03125]], [[2.015625]], [[2.140625]], [[1.3515625]], [[1.4375]], [[2.28125]], [[1.375]], [[1.515625]], [[1.8359375]], [[2.125]], [[1.1640625]], [[1.3046875]], [[1.109375]], [[1.8125]], [[1.6171875]], [[0.92578125]], [[0.9609375]], [[1.84375]], [[1.015625]], [[2.5625]], [[2.0625]], [[2.078125]], [[1.0234375]], [[1.6484375]], [[2.265625]], [[2.3125]], [[2.703125]], [[1.390625]], [[2.421875]], [[2.96875]], [[2.71875]], [[1.5859375]], [[0.984375]], [[2.21875]], [[3.1875]], [[2.046875]], [[2.109375]], [[1.859375]], [[1.2109375]], [[1.09375]], [[2.109375]], [[1.640625]], [[1.234375]], [[1.6015625]], [[1.5703125]], [[1.8984375]], [[1.53125]], [[1.21875]], [[2.03125]], [[3.078125]], [[1.3515625]], [[2.21875]], [[2.78125]], [[2.203125]], [[2.21875]], [[1.1953125]], [[1.3984375]], [[1.7890625]], [[1.6875]], [[1.125]], [[0.91015625]], [[0.91796875]], [[0.0]], [[0.0]], [[1.1640625]], [[1.328125]], [[0.0]], [[0.9375]], [[0.97265625]], [[1.1015625]], [[0.0]], [[0.0]], [[0.0]], [[0.796875]], [[0.921875]], [[0.796875]], [[0.0]], [[0.90625]], [[1.3203125]], [[1.375]]], [[[0.0]], [[1.9140625]], [[1.6171875]], [[2.421875]], [[1.9375]], [[1.5859375]], [[1.96875]], [[2.515625]], [[2.40625]], [[3.71875]], [[2.28125]], [[1.6953125]], [[1.9921875]], [[1.9453125]], [[1.1640625]], [[0.0]], [[1.75]], [[1.984375]], [[2.15625]], [[3.9375]], [[2.546875]], [[2.6875]], [[1.8984375]], [[1.8984375]], [[1.5234375]], [[2.125]], [[3.953125]], [[1.2578125]], [[2.359375]], [[1.1640625]], [[1.3046875]], [[0.7578125]], [[1.1796875]], [[2.21875]], [[1.1875]], [[2.859375]], [[2.03125]], [[2.75]], [[1.8203125]], [[2.21875]], [[1.8984375]], [[2.15625]], [[3.140625]], [[1.5859375]], [[2.3125]], [[2.234375]], [[1.6328125]], [[2.09375]], [[1.890625]], [[2.46875]], [[2.15625]], [[2.484375]], [[2.3125]], [[1.703125]], [[2.1875]], [[2.703125]], [[1.5]], [[1.625]], [[1.2578125]], [[1.21875]], [[2.765625]], [[2.046875]], [[2.21875]], [[2.9375]], [[2.703125]], [[3.0]], [[1.8203125]], [[1.4921875]], [[2.234375]], [[1.953125]], [[2.609375]], [[1.7578125]], [[1.71875]], [[1.859375]], [[1.296875]], [[1.5]], [[2.59375]], [[1.3828125]], [[2.625]], [[1.7109375]], [[2.890625]], [[2.875]], [[1.4375]], [[2.015625]], [[2.046875]], [[2.421875]], [[1.5625]], [[2.515625]], [[1.359375]], [[1.578125]], [[1.0390625]], [[1.609375]], [[2.59375]], [[2.625]], [[2.578125]], [[2.265625]], [[1.6640625]], [[1.75]], [[2.28125]], [[1.625]], [[1.8203125]], [[2.4375]], [[1.6171875]], [[1.9375]], [[2.328125]], [[1.125]], [[1.75]], [[1.9453125]], [[1.9765625]], [[1.5078125]], [[1.296875]], [[2.03125]], [[2.40625]], [[2.15625]], [[1.9375]], [[2.15625]], [[1.875]], [[2.484375]], [[2.3125]], [[2.65625]], [[1.6171875]], [[1.765625]], [[2.71875]], [[1.4765625]], [[1.8046875]], [[2.5]], [[2.015625]], [[2.5625]]], [[[0.0]], [[0.0]], [[0.0]], [[1.4296875]], [[3.0]], [[2.90625]], [[2.453125]], [[1.8125]], [[0.9765625]], [[2.15625]], [[2.984375]], [[2.015625]], [[1.0078125]], [[0.76953125]], [[0.0]], [[1.703125]], [[2.328125]], [[2.171875]], [[0.68359375]], [[0.0]], [[0.0]], [[0.7265625]], [[0.7421875]], [[0.0]], [[0.53125]], [[1.3515625]], [[0.494140625]], [[0.8984375]], [[1.515625]], [[0.0]], [[0.0]], [[0.0]], [[0.9921875]], [[1.5859375]], [[0.96875]], [[0.0]], [[0.0]], [[1.4296875]], [[0.0]], [[0.0]], [[0.70703125]], [[0.0]], [[0.78125]], [[1.234375]], [[1.75]], [[1.296875]], [[0.0]], [[0.0]], [[1.203125]], [[0.0]], [[1.109375]], [[2.015625]], [[1.2421875]], [[1.75]], [[1.234375]], [[1.09375]], [[1.25]], [[1.3046875]], [[1.1484375]], [[1.1015625]], [[0.6328125]], [[0.94140625]], [[1.203125]], [[1.734375]], [[0.90234375]], [[0.6796875]], [[0.6953125]], [[0.6328125]], [[0.734375]], [[1.1484375]], [[1.3828125]], [[1.4609375]], [[1.09375]], [[0.65625]], [[0.7265625]], [[0.0]], [[0.98046875]], [[1.3046875]], [[0.99609375]], [[0.0]], [[1.2578125]], [[1.125]], [[0.71875]], [[0.9375]], [[0.671875]], [[0.73828125]], [[0.7265625]], [[1.28125]], [[3.15625]], [[1.5703125]], [[2.078125]], [[1.6953125]], [[3.890625]], [[1.8515625]], [[1.59375]], [[1.640625]], [[1.5703125]], [[1.078125]], [[1.546875]], [[1.6171875]], [[1.1875]], [[1.15625]], [[1.828125]], [[1.046875]], [[1.1171875]], [[1.4375]], [[1.3671875]], [[1.359375]], [[0.8359375]], [[0.98828125]], [[0.71484375]], [[1.65625]], [[0.98046875]], [[0.0]], [[0.0]], [[1.4765625]], [[2.234375]], [[2.859375]], [[2.609375]], [[2.78125]], [[2.21875]], [[2.15625]], [[0.80859375]], [[0.0]], [[1.421875]], [[1.7578125]], [[1.890625]], [[2.421875]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x32b531650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 11871:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b3e90d0b-b027\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b3e90d0b-b027\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"of\", \" anybody\", \" I\", \" have\", \" ever\", \" coached\", \".\", \"\\n\", \"\\n\", \"Whatever\", \" he\", \" did\", \",\", \" he\", \" wanted\", \" to\", \" do\", \" better\", \" than\", \" anybody\", \" else\", \"\\\"\", \"\\n\", \"With\", \" Brown\", \"'s\", \" talent\", \" and\", \" leadership\", \",\", \" Man\", \"h\", \"asset\", \" High\", \" became\", \" a\", \" power\", \"house\", \" in\", \" football\", \",\", \" baseball\", \",\", \" and\", \" lac\", \"rosse\", \" The\", \" students\", \" at\", \" the\", \" school\", \" were\", \" so\", \" impressed\", \" with\", \" their\", \" star\", \" athlete\", \" that\", \" they\", \" elected\", \" him\", \" chief\", \" justice\", \" of\", \" the\", \" high\", \" school\", \" court\", \" Even\", \" so\", \",\", \" Brown\", \" admits\", \" that\", \" he\", \" did\", \" indulge\", \" in\", \" a\", \" bit\", \" of\", \" minor\", \" gang\", \" activity\", \" as\", \" a\", \" teenager\", \"--\", \" chiefly\", \" breaking\", \" in\", \" on\", \" rival\", \" parties\", \" and\", \" fighting\", \" occasionally\", \" This\", \" mis\", \"chief\", \",\", \" however\", \",\", \" did\", \" not\", \" imp\", \"inge\", \" on\", \" his\", \" athletic\", \" career\", \" or\", \" his\", \" academic\", \" potential\", \" During\", \" most\", \" of\", \" his\", \" high\", \" school\", \" years\", \" he\", \" was\", \" a\", \" member\", \" of\"], [\"had\", \" good\", \" stuff\", \" through\", \" three\", \" innings\", \".\", \"\\n\", \"\\n\", \"\\\"\", \"He\", \" was\", \" executing\", \" pitches\", \",\", \" and\", \" the\", \" next\", \" thing\", \" you\", \" know\", \" --\", \" I\", \" don\", \"'t\", \" know\", \" what\", \" he\", \" grabbed\", \" --\", \" but\", \" I\", \" knew\", \" it\", \" was\", \" his\", \" arm\", \".\", \" It\", \"'s\", \" never\", \" a\", \" good\", \" sign\", \",\", \" never\", \" a\", \" good\", \" feeling\", \",\", \" to\", \" be\", \" out\", \" there\", \" and\", \" see\", \" a\", \" pitcher\", \" walk\", \" off\", \" the\", \" mound\", \" like\", \" that\", \",\\\"\", \" G\", \"att\", \"is\", \" said\", \".\", \" \\\"\", \"On\", \" the\", \" last\", \" pitch\", \",\", \" he\", \" just\", \" threw\", \" a\", \" y\", \"anked\", \" change\", \"up\", \" --\", \" I\", \"'ve\", \" never\", \" seen\", \" that\", \" --\", \" and\", \" immediately\", \" there\", \" was\", \" a\", \" problem\", \".\", \"...\", \" He\", \" was\", \" throwing\", \" good\", \" pitches\", \",\", \" and\", \" then\", \" it\", \" was\", \" just\", \" an\", \" out\", \"-\", \"of\", \"-\", \"the\", \"-\", \"blue\", \" kind\", \" of\", \" thing\", \".\\\"\", \"\\n\", \"\\n\", \"START\", \"ING\", \" TIME\", \"\\n\"], [\"gl\", \"ad\", \" to\", \" see\", \" P\", \"arn\", \"ell\", \" go\", \" after\", \" some\", \" hit\", \"ters\", \".\", \"\\n\", \"\\n\", \"\\\"\", \"To\", \" see\", \" him\", \" out\", \" there\", \" for\", \" the\", \" first\", \" time\", \" and\", \" really\", \" see\", \" him\", \" let\", \" loose\", \" --\", \" he\", \"'s\", \" been\", \" a\", \" little\", \" tentative\", \" in\", \" the\", \" '\", \"pen\", \" and\", \" I\", \" understand\", \" it\", \",\\\"\", \" Collins\", \" said\", \".\", \" \\\"\", \"He\", \" threw\", \" the\", \" ball\", \" great\", \".\", \" The\", \" last\", \" five\", \" or\", \" six\", \" he\", \" let\", \" the\", \" ball\", \" go\", \" good\", \".\\\"\", \"\\n\", \"\\n\", \"L\", \"OOK\", \"ING\", \" A\", \"HEAD\", \"\\n\", \"\\n\", \"The\", \" Mets\", \" will\", \" host\", \" the\", \" Marl\", \"ins\", \" on\", \" Monday\", \",\", \" but\", \" they\", \" won\", \"'t\", \" face\", \" NL\", \" R\", \"ookie\", \" of\", \" the\", \" Year\", \" Jose\", \" Fern\", \"andez\", \",\", \" who\", \" pitched\", \" against\", \" New\", \" York\", \" in\", \" Port\", \" St\", \".\", \" Luc\", \"ie\", \" last\", \" Wednesday\", \".\", \" Miami\", \" manager\", \" Mike\", \" Red\", \"mond\", \" has\", \" opted\", \" to\", \" go\", \" with\", \" le\"], [\"to\", \" fetch\", \" his\", \" sleeping\", \" bag\", \" but\", \" that\", \" he\", \" would\", \" meet\", \" her\", \" at\", \" 5\", \"am\", \" that\", \" morning\", \" to\", \" walk\", \" her\", \" back\", \" to\", \" E\", \"ust\", \"on\", \" station\", \",\", \" from\", \" where\", \" she\", \" could\", \" get\", \" on\", \" the\", \" first\", \" train\", \".\", \" She\", \" said\", \" she\", \" did\", \" not\", \" believe\", \" he\", \" would\", \" return\", \".\", \"\\n\", \"\\n\", \"But\", \" shortly\", \" after\", \" 5\", \"am\", \",\", \" Mark\", \" came\", \" running\", \" to\", \" the\", \" cafe\", \",\", \" having\", \" taken\", \" a\", \" bus\", \" to\", \" make\", \" sure\", \" he\", \" would\", \" be\", \" there\", \" to\", \" accompany\", \" her\", \" to\", \" the\", \" station\", \".\", \"\\n\", \"\\n\", \"Nic\", \"ole\", \" S\", \"edge\", \"be\", \"er\", \" was\", \" rescued\", \" by\", \" a\", \" homeless\", \" man\", \" at\", \" E\", \"ust\", \"on\", \" Station\", \" after\", \" she\", \" missed\", \" her\", \" last\", \" train\", \" home\", \" (\", \"Getty\", \" Images\", \")\", \"\\n\", \"\\n\", \"Nic\", \"ole\", \" wrote\", \":\", \" \\\"\", \"When\", \" I\", \" asked\", \" him\", \" why\", \" he\", \" did\", \" it\", \" he\", \" said\", \" '\", \"He\"], [\"sensitive\", \" issues\", \" and\", \" to\", \" select\", \" which\", \" portions\", \" of\", \" their\", \" narratives\", \" are\", \" appropriate\", \" for\", \" their\", \" children\", \" to\", \" hear\", \".\", \" Sometimes\", \" more\", \" than\", \" one\", \" session\", \" is\", \" required\", \" to\", \" model\", \" and\", \" practice\", \" the\", \" requisite\", \" skills\", \".\", \"\\n\", \"\\n\", \"The\", \" *\", \"first\", \" family\", \" session\", \"*\", \" is\", \" devoted\", \" to\", \" sharing\", \" family\", \" narratives\", \" and\", \" addressing\", \" differences\", \" in\", \" experiences\", \" and\", \" interpretations\", \" across\", \" the\", \" family\", \".\", \" This\", \" session\", \" usually\", \" has\", \" the\", \" children\", \" sharing\", \" their\", \" tim\", \"elines\", \" or\", \" tim\", \"em\", \"aps\", \" with\", \" the\", \" parents\", \" invited\", \" to\", \" share\", \" their\", \" experiences\", \" or\", \" clarify\", \" misunder\", \"stand\", \"ings\", \" or\", \" mis\", \"att\", \"ributions\", \".\", \" In\", \" the\", \" current\", \" example\", \",\", \" the\", \" father\", \" was\", \" relieved\", \" and\", \" actually\", \" touched\", \" to\", \" hear\", \" that\", \" his\", \" son\", \" avoided\", \" him\", \" when\", \" he\", \" said\", \" goodbye\", \" because\", \" he\", \" was\", \" so\", \" upset\", \" and\", \" afraid\", \" that\", \" he\", \" would\", \" disappoint\", \" his\", \" dad\", \" if\", \" he\"], [\"Rol\", \"and\", \" Em\", \"mer\", \"ich\", \",\", \" but\", \" Christopher\", \" Nolan\", \"!\", \" The\", \" guy\", \" who\", \" made\", \" M\", \"ement\", \"o\", \" and\", \" Following\", \"!\", \"\\n\", \"\\n\", \"N\", \"olan\", \"'s\", \" next\", \" movie\", \" isn\", \"'t\", \" even\", \" announced\", \" yet\", \" and\", \" I\", \"'m\", \" already\", \" excited\", \" about\", \" it\", \",\", \" because\", \" I\", \" can\", \" look\", \" at\", \" his\", \" I\", \"MD\", \"b\", \" credits\", \" and\", \" see\", \" that\", \" he\", \" hasn\", \"'t\", \" made\", \" a\", \" bad\", \" film\", \".\", \" The\", \" last\", \" non\", \"-\", \"Bat\", \"man\", \" film\", \" he\", \" made\", \" was\", \" about\", \" dreams\", \",\", \" and\", \" the\", \" creative\", \" process\", \",\", \" and\", \" spinning\", \" tops\", \",\", \" I\", \" think\", \",\", \" and\", \" it\", \" was\", \" one\", \" of\", \" the\", \" most\", \" exciting\", \" action\", \" movies\", \" of\", \" the\", \" last\", \" 20\", \" years\", \".\", \" He\", \"'s\", \" in\", \" a\", \" position\", \" where\", \" literally\", \" every\", \" studio\", \" will\", \" open\", \" up\", \" their\", \" wal\", \"lets\", \" to\", \" fund\", \" any\", \" idea\", \" he\", \" has\", \",\", \" and\", \" every\", \" single\", \" A\"], [\"at\", \" lunch\", \"time\", \".\", \" The\", \" F\", \"urry\", \" Boy\", \" will\", \" be\", \" joining\", \" you\", \" tomorrow\", \" and\", \" he\", \" tells\", \" me\", \" that\", \" he\", \" has\", \" a\", \" good\", \"ie\", \" give\", \"-\", \"away\", \".....\", \"did\", \" he\", \" ask\", \" permission\", \" to\", \" del\", \"ve\", \" into\", \" my\", \" cra\", \"fty\", \" st\", \"ash\", \" again\", \"....\", \"not\", \" on\", \" your\", \" n\", \"elly\", \" but\", \" according\", \" to\", \" him\", \" he\", \"'s\", \" in\", \" charge\", \" of\", \" the\", \" cub\", \"by\", \"hole\", \" at\", \" the\", \" moment\", \" so\", \" I\", \" have\", \" no\", \" say\", \" in\", \" the\", \" matter\", \"....\", \"che\", \"ek\", \"y\", \" bl\", \"ighter\", \".\", \"\\n\", \"\\n\", \"Friday\", \",\", \" October\", \" 29\", \",\", \" 2010\", \"\\n\", \"\\n\", \"Mor\", \"ning\", \" folks\", \".....\", \"that\", \"'s\", \" Day\", \" 1\", \" under\", \" my\", \" belt\", \"....\", \"all\", \" set\", \" for\", \" another\", \" fun\", \" filled\", \" F\", \"isk\", \"ars\", \" Day\", \" and\", \" another\", \" Simply\", \" Create\", \" DT\", \" project\", \" to\", \" share\", \" with\", \" you\", \"......\", \"a\", \" card\", \" to\", \" match\", \" yesterday\", \"'s\", \" Mem\"], [\"the\", \" next\", \" weekend\", \" when\", \" the\", \" Packers\", \" came\", \" to\", \" town\", \".\", \" He\", \" was\", \" a\", \" healthy\", \" scratch\", \".\", \"\\n\", \"\\n\", \"That\", \" decision\", \" was\", \" a\", \" big\", \" one\", \" for\", \" Ag\", \"hol\", \"or\", \",\", \" but\", \" also\", \" for\", \" Ped\", \"erson\", \".\", \"\\n\", \"\\n\", \"\\\"\", \"I\", \" think\", \" it\", \" was\", \" definitely\", \" big\", \" on\", \" both\", \" our\", \" parts\", \" because\", \" it\", \" was\", \" the\", \" first\", \" time\", \" I\", \"'ve\", \" really\", \" had\", \" to\", \" sort\", \" of\", \" bench\", \" a\", \" player\", \" for\", \" the\", \" performance\", \" or\", \" whatever\", \" or\", \" just\", \" the\", \" sort\", \" of\", \" the\", \" sl\", \"ump\", \" that\", \" he\", \" was\", \" in\", \",\\\"\", \" Ped\", \"erson\", \" said\", \".\", \" \\\"\", \"I\", \" really\", \" think\", \" that\", \" it\", \" was\", \" a\", \" great\", \" -\", \" it\", \" was\", \" a\", \" wake\", \"up\", \" call\", \" I\", \" think\", \" for\", \" him\", \",\", \" but\", \" he\", \" embraced\", \" it\", \" the\", \" right\", \" way\", \".\", \" Part\", \" of\", \" the\", \" conversation\", \" that\", \" he\", \" and\", \" I\", \" had\", \" leading\", \" up\", \" to\", \" me\"], [\"we\", \" visit\", \" this\", \" superb\", \" venue\", \" John\", \" always\", \" makes\", \" sure\", \" all\", \" the\", \" chairs\", \" are\", \" out\", \" and\", \" no\", \" request\", \" is\", \" too\", \" small\", \" for\", \" him\", \" to\", \" help\", \" us\", \" with\", \".\", \"\\n\", \"\\n\", \"One\", \" of\", \" the\", \" most\", \" incredible\", \" occurrences\", \" that\", \" happened\", \" at\", \" The\", \" Old\", \" Nick\", \" was\", \" when\", \" a\", \" group\", \" of\", \" ghost\", \" hunters\", \" were\", \" calling\", \" in\", \" a\", \" circle\", \" around\", \" a\", \" table\", \" out\", \" in\", \" the\", \" theatre\", \",\", \" when\", \" all\", \" of\", \" a\", \" sudden\", \" in\", \" the\", \" corner\", \" of\", \" the\", \" room\", \" a\", \" really\", \" loud\", \" noise\", \" was\", \" heard\", \",\", \" immediately\", \" Simply\", \" Ghost\", \" N\", \"ights\", \" experienced\", \" paran\", \"ormal\", \" investigator\", \" Mark\", \" shone\", \" his\", \" torch\", \" in\", \" the\", \" area\", \" of\", \" the\", \" noise\", \" and\", \" to\", \" his\", \" and\", \" Rose\", \"y\", \"'s\", \",\", \" Martin\", \",\", \" Hannah\", \",\", \" Sue\", \"'s\", \" and\", \" M\", \"andy\", \"'s\", \" aston\", \"ishment\", \" they\", \" all\", \" clearly\", \" saw\", \" a\", \" chair\", \" moving\", \" as\", \" if\", \" it\"], [\"by\", \",\", \" some\", \" noticing\", \" him\", \" and\", \" others\", \" either\", \" ignoring\", \" him\", \" intentionally\", \" or\", \" unaware\", \" that\", \" he\", \" was\", \" there\", \" or\", \" not\", \" caring\", \" whatsoever\", \".\", \" A\", \" sense\", \" of\", \" bew\", \"ilder\", \"ment\", \" came\", \" over\", \" him\", \".\", \" He\", \" had\", \" expected\", \" too\", \" much\", \" of\", \" the\", \" people\", \" of\", \" Te\", \"irl\", \"in\", \"\\u2019\", \"pur\", \".\", \" He\", \" expected\", \" sav\", \"ages\", \" as\", \" evil\", \" and\", \" man\", \"iac\", \"al\", \" as\", \" L\", \"uth\", \"ien\", \",\", \" yet\", \" here\", \" he\", \" could\", \" clearly\", \" see\", \" that\", \" the\", \" people\", \" of\", \" Te\", \"irl\", \"in\", \"\\u2019\", \"pur\", \" were\", \" actually\", \" not\", \" unlike\", \" the\", \" people\", \" of\", \" Ar\", \"lin\", \"City\", \",\", \" despite\", \" the\", \" difference\", \" in\", \" races\", \".\", \" People\", \" here\", \" seemed\", \" so\", \" alike\", \" to\", \" the\", \" people\", \" of\", \" Ar\", \"lin\", \"City\", \" in\", \" how\", \" they\", \" moved\", \" and\", \" acted\", \".\", \" They\", \" walked\", \" and\", \" talked\", \" amongst\", \" themselves\", \" as\", \" if\", \" no\", \" war\", \" had\", \" ever\", \" been\", \" started\", \",\"]], \"activations\": [[[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.73828125]], [[2.765625]], [[2.390625]], [[1.7578125]], [[4.09375]], [[2.875]], [[2.890625]], [[2.21875]], [[3.234375]], [[1.75]], [[1.609375]], [[1.2578125]], [[0.478515625]], [[1.28125]], [[0.0]], [[1.3046875]], [[1.5390625]], [[1.75]], [[1.78125]], [[1.4140625]], [[0.515625]], [[0.0]], [[0.98046875]], [[0.0]], [[1.2890625]], [[0.83984375]], [[0.0]], [[0.0]], [[1.03125]], [[0.0]], [[0.71875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.71484375]], [[0.0]], [[0.0]], [[0.0]], [[1.1328125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.60546875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7890625]], [[1.4140625]], [[0.94140625]], [[0.0]], [[2.65625]], [[2.375]], [[1.015625]], [[2.15625]], [[2.75]], [[2.359375]], [[1.8515625]], [[1.90625]], [[1.6640625]], [[0.91015625]], [[1.5625]], [[1.71875]], [[1.859375]], [[1.3125]], [[1.421875]], [[1.6953125]], [[1.25]], [[1.4765625]], [[1.234375]], [[1.609375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.66796875]], [[0.9375]], [[0.984375]], [[1.8046875]], [[1.234375]], [[1.4453125]], [[0.0]], [[1.0625]], [[1.5078125]], [[0.0]], [[1.328125]], [[1.1796875]], [[1.546875]], [[1.1015625]], [[0.96484375]], [[1.65625]], [[2.015625]], [[1.3671875]], [[1.7734375]], [[0.0]], [[0.0]], [[0.0]], [[1.90625]], [[0.5546875]], [[1.625]], [[1.3203125]], [[1.0234375]], [[2.15625]]], [[[0.0]], [[0.84375]], [[0.0]], [[0.73046875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.71875]], [[1.9609375]], [[2.46875]], [[1.421875]], [[1.8671875]], [[2.09375]], [[1.0234375]], [[1.359375]], [[1.1484375]], [[0.0]], [[1.3828125]], [[1.234375]], [[0.69921875]], [[0.61328125]], [[0.578125]], [[1.171875]], [[0.99609375]], [[1.359375]], [[4.0625]], [[1.6640625]], [[1.9140625]], [[1.5]], [[2.921875]], [[1.6953125]], [[1.9609375]], [[1.234375]], [[1.9375]], [[1.9375]], [[1.7265625]], [[1.6015625]], [[1.796875]], [[1.21875]], [[0.9921875]], [[1.5546875]], [[1.5390625]], [[1.984375]], [[1.65625]], [[1.09375]], [[1.8828125]], [[1.6875]], [[1.8125]], [[1.859375]], [[1.7421875]], [[1.2421875]], [[2.109375]], [[2.390625]], [[1.2578125]], [[1.25]], [[1.3984375]], [[1.6328125]], [[0.0]], [[1.3046875]], [[2.171875]], [[1.4765625]], [[1.0078125]], [[0.0]], [[0.0]], [[0.0]], [[1.3125]], [[0.98828125]], [[1.5546875]], [[1.421875]], [[0.7265625]], [[1.5546875]], [[1.0703125]], [[1.3828125]], [[1.0390625]], [[2.234375]], [[3.171875]], [[2.40625]], [[0.99609375]], [[2.015625]], [[1.828125]], [[1.7109375]], [[1.6484375]], [[1.0234375]], [[0.9765625]], [[0.88671875]], [[1.7890625]], [[1.8046875]], [[1.765625]], [[1.90625]], [[1.4453125]], [[1.578125]], [[1.75]], [[1.2734375]], [[1.5859375]], [[1.6015625]], [[1.7890625]], [[1.3203125]], [[2.734375]], [[3.5]], [[1.9453125]], [[1.9140625]], [[2.375]], [[3.0625]], [[2.59375]], [[1.1015625]], [[1.9609375]], [[1.859375]], [[1.2890625]], [[0.90625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.265625]], [[1.4921875]], [[1.3671875]], [[1.1015625]], [[1.0078125]], [[0.71875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1015625]], [[1.75]], [[0.75]], [[0.76953125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.4453125]], [[2.203125]], [[1.6640625]], [[2.734375]], [[1.3359375]], [[1.34375]], [[1.59375]], [[2.109375]], [[1.6015625]], [[4.03125]], [[1.9296875]], [[3.578125]], [[2.53125]], [[1.5]], [[1.25]], [[2.359375]], [[2.359375]], [[2.265625]], [[2.046875]], [[2.421875]], [[2.9375]], [[2.078125]], [[1.5390625]], [[0.0]], [[1.5546875]], [[1.03125]], [[2.125]], [[0.0]], [[1.0546875]], [[0.0]], [[1.5078125]], [[1.0625]], [[1.9140625]], [[1.4453125]], [[3.140625]], [[1.7421875]], [[1.390625]], [[1.6640625]], [[1.8046875]], [[1.640625]], [[1.953125]], [[1.171875]], [[0.0]], [[0.828125]], [[0.83984375]], [[3.25]], [[1.2734375]], [[1.6953125]], [[1.6171875]], [[1.484375]], [[0.9765625]], [[0.5]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.73828125]], [[1.2734375]], [[1.5078125]], [[0.984375]], [[0.0]], [[0.0]], [[0.71875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7265625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.3515625]], [[0.76953125]], [[1.1484375]], [[1.359375]], [[1.546875]], [[0.59375]]], [[[0.0]], [[0.0]], [[0.0]], [[0.65625]], [[0.0]], [[0.70703125]], [[1.09375]], [[0.87109375]], [[1.671875]], [[2.546875]], [[0.96484375]], [[1.7265625]], [[0.97265625]], [[0.0]], [[1.4609375]], [[1.4921875]], [[1.2421875]], [[1.5625]], [[0.0]], [[0.0]], [[1.21875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.90625]], [[1.03125]], [[1.3828125]], [[0.0]], [[0.99609375]], [[1.234375]], [[1.2734375]], [[0.0]], [[0.73046875]], [[0.0]], [[0.0]], [[0.0]], [[0.84765625]], [[0.0]], [[0.0]], [[0.0]], [[1.328125]], [[0.0]], [[1.546875]], [[2.078125]], [[1.125]], [[0.0]], [[0.48046875]], [[0.98046875]], [[0.0]], [[1.1484375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1796875]], [[1.4375]], [[1.5]], [[0.0]], [[0.0]], [[0.765625]], [[1.3984375]], [[1.265625]], [[0.92578125]], [[0.0]], [[0.0]], [[0.0]], [[1.125]], [[0.0]], [[1.21875]], [[1.1015625]], [[1.2578125]], [[1.0625]], [[1.2109375]], [[0.0]], [[0.92578125]], [[0.0]], [[0.0]], [[0.86328125]], [[0.6796875]], [[0.56640625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7421875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.421875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.03125]], [[1.234375]], [[2.046875]], [[1.4921875]], [[1.109375]], [[2.265625]], [[1.109375]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.0390625]], [[1.4921875]], [[1.0]], [[1.7265625]], [[1.9765625]], [[2.078125]], [[1.734375]], [[1.53125]], [[0.0]], [[1.1953125]], [[2.5625]], [[0.90234375]], [[3.21875]], [[1.0234375]], [[1.9921875]], [[1.8515625]], [[3.390625]], [[1.3203125]], [[2.1875]], [[2.09375]], [[2.703125]], [[2.484375]], [[3.46875]], [[3.96875]], [[1.71875]], [[2.765625]], [[3.765625]], [[0.0]], [[1.640625]], [[3.65625]], [[1.4140625]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.45703125]], [[0.0]], [[0.0]], [[0.61328125]], [[0.0]], [[0.85546875]], [[1.265625]], [[2.015625]], [[0.0]], [[0.0]], [[0.0]], [[0.7578125]], [[1.015625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.94921875]], [[1.375]], [[1.28125]], [[0.8984375]], [[1.1171875]], [[1.0234375]], [[1.15625]], [[0.96875]], [[1.53125]], [[1.0]], [[0.83203125]], [[0.68359375]], [[0.9296875]], [[0.98046875]], [[0.0]], [[0.0]], [[1.21875]], [[0.83984375]], [[1.109375]], [[0.70703125]], [[0.91796875]], [[0.78515625]], [[0.78515625]], [[0.0]], [[0.0]], [[1.59375]], [[1.8359375]], [[3.921875]], [[2.5625]], [[1.125]], [[1.1171875]], [[2.203125]], [[2.8125]], [[1.65625]], [[1.3125]], [[1.6484375]], [[1.75]], [[1.6484375]], [[1.6875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.0234375]], [[0.0]], [[2.359375]], [[1.59375]], [[1.6875]], [[1.0546875]], [[1.15625]], [[2.3125]], [[1.3984375]], [[0.0]], [[1.1796875]], [[0.72265625]], [[1.828125]], [[0.7578125]], [[0.0]], [[0.0]], [[0.58203125]], [[1.421875]], [[0.953125]], [[1.5390625]], [[0.890625]], [[0.97265625]], [[0.84375]], [[0.9140625]], [[0.0]], [[0.734375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.0390625]], [[0.55859375]], [[1.9375]], [[2.359375]], [[2.21875]], [[1.46875]], [[2.265625]], [[1.84375]], [[1.5703125]], [[0.80078125]], [[1.453125]], [[1.0546875]], [[1.078125]], [[0.0]], [[0.0]], [[1.0]], [[1.0859375]], [[1.2265625]], [[0.0]], [[0.0]], [[0.0]], [[1.4140625]], [[1.3359375]], [[2.15625]], [[1.6171875]], [[1.984375]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.65625]], [[0.498046875]], [[0.6875]], [[0.0]], [[0.0]], [[0.0]], [[0.67578125]], [[2.40625]], [[2.265625]], [[2.203125]], [[0.7890625]], [[2.328125]], [[2.09375]], [[1.3359375]], [[1.3828125]], [[1.484375]], [[0.0]], [[1.53125]], [[1.796875]], [[1.421875]], [[0.0]], [[3.859375]], [[1.6953125]], [[2.140625]], [[0.5859375]], [[0.98046875]], [[2.546875]], [[0.6953125]], [[0.0]], [[1.3515625]], [[0.671875]], [[1.5234375]], [[1.3203125]], [[1.609375]], [[0.97265625]], [[1.546875]], [[0.0]], [[0.0]], [[0.0]], [[0.78515625]], [[1.140625]], [[1.234375]], [[0.0]], [[0.7109375]], [[1.8515625]], [[2.359375]], [[1.984375]], [[2.328125]], [[1.5546875]], [[0.0]], [[0.0]], [[1.375]], [[1.828125]], [[1.0859375]], [[2.125]], [[2.03125]], [[1.7109375]], [[1.640625]], [[1.265625]], [[1.0390625]], [[1.96875]], [[1.0078125]], [[1.4453125]], [[1.71875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1328125]], [[1.578125]], [[0.84375]], [[1.1796875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.38671875]], [[1.6953125]], [[1.2734375]], [[1.453125]], [[0.93359375]], [[1.609375]], [[0.859375]], [[0.9453125]], [[0.984375]], [[0.70703125]], [[0.0]], [[1.1015625]], [[0.0]], [[0.0]], [[0.9296875]], [[0.0]], [[0.0]], [[0.0]], [[0.81640625]], [[0.92578125]], [[0.765625]], [[1.1796875]], [[0.0]], [[0.0]], [[1.3046875]], [[0.78125]], [[0.68359375]], [[0.6328125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.95703125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.7734375]], [[0.0]], [[0.0]], [[0.0]], [[0.78515625]], [[0.79296875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.2109375]], [[0.625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.796875]], [[2.140625]], [[0.96484375]], [[0.0]], [[0.0]], [[1.4921875]], [[0.91796875]], [[1.1328125]], [[0.88671875]], [[0.0]], [[1.5]], [[1.2265625]], [[0.7421875]], [[0.0]], [[0.0]], [[0.0]], [[1.09375]], [[0.0]], [[0.0]], [[0.8359375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.78125]], [[1.4453125]], [[1.6796875]], [[1.421875]], [[3.828125]], [[1.546875]], [[1.2109375]], [[1.5078125]], [[1.5625]], [[1.0390625]], [[1.1640625]], [[2.828125]], [[1.203125]], [[1.4453125]], [[1.7421875]], [[0.921875]], [[2.78125]], [[1.3984375]], [[1.125]], [[1.734375]], [[1.328125]], [[2.109375]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.71875]], [[2.09375]], [[1.140625]], [[1.1015625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.2890625]], [[2.671875]], [[3.796875]], [[2.21875]], [[2.796875]], [[0.0]], [[1.328125]], [[0.85546875]], [[0.6953125]], [[0.58203125]], [[0.0]], [[0.64453125]], [[0.78515625]], [[1.015625]], [[0.890625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.66015625]], [[1.1953125]], [[0.78515625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.91796875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[1.1796875]], [[0.0]], [[0.0]], [[1.1328125]], [[0.0]], [[0.671875]], [[0.81640625]], [[0.0]], [[0.0]], [[0.91015625]], [[0.94921875]], [[0.0]], [[1.625]], [[0.0]], [[0.0]], [[0.0]], [[1.1328125]], [[0.0]], [[0.9453125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.79296875]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.95703125]], [[1.828125]], [[0.0]], [[0.0]], [[1.75]], [[0.0]], [[1.8828125]], [[1.90625]], [[1.8359375]], [[1.6875]], [[1.0625]], [[1.875]], [[1.8125]], [[2.375]], [[1.828125]], [[1.9765625]], [[1.90625]], [[0.0]], [[1.0390625]], [[0.0]], [[0.984375]], [[0.0]], [[1.0625]], [[1.28125]], [[1.2265625]], [[1.265625]], [[1.1953125]], [[1.6953125]], [[1.53125]], [[2.4375]], [[3.78125]], [[1.8828125]], [[2.5]], [[3.203125]], [[1.8984375]], [[2.484375]], [[1.859375]], [[0.0]], [[0.0]], [[0.0]], [[1.71875]], [[0.0]], [[2.09375]], [[1.21875]], [[3.515625]], [[1.03125]], [[2.328125]], [[2.21875]], [[1.4375]], [[1.6015625]], [[1.0234375]], [[1.2734375]], [[0.91015625]], [[2.4375]], [[0.0]], [[0.0]], [[0.0]], [[1.796875]], [[2.921875]], [[2.421875]], [[1.046875]], [[2.28125]], [[2.140625]], [[3.078125]], [[2.140625]], [[1.3515625]], [[1.5390625]], [[1.0625]], [[0.0]], [[0.0]], [[1.0859375]], [[1.4609375]], [[1.046875]], [[1.28125]], [[0.9921875]], [[0.0]], [[1.671875]], [[0.875]], [[0.0]], [[1.03125]], [[0.0]], [[0.0]], [[0.75390625]], [[0.890625]], [[1.5703125]], [[0.6875]], [[1.515625]], [[1.1015625]], [[0.77734375]], [[1.7890625]], [[0.796875]], [[1.0390625]], [[0.0]], [[0.0]], [[0.0]], [[0.98046875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.89453125]], [[0.8359375]], [[0.0]], [[0.7578125]], [[0.87109375]], [[0.0]], [[1.421875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x30def7bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 2419:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-29f1ac23-d8f7\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-29f1ac23-d8f7\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"noise\", \".\", \"@\", \"\\u00a0\", \" She\", \" indicated\", \" that\", \" she\", \" thought\", \" the\", \" victim\", \" was\", \"\\r\", \"\\n\", \"g\", \"agging\", \" on\", \" her\", \" own\", \" blood\", \".\", \"\\n\", \"Anthony\", \" Lopez\", \",\", \" who\", \" was\", \" living\", \" with\", \" Flores\", \"=\", \"s\", \"\\r\", \"\\n\", \"mother\", \" at\", \" the\", \" time\", \",\", \" testified\", \" that\", \" the\", \" victim\", \" was\", \" in\", \" and\", \" out\", \" of\", \" their\", \" house\", \" all\", \"\\r\", \"\\n\", \"the\", \" time\", \".\", \"\\u00a0\", \" He\", \" stated\", \" that\", \" he\", \" spent\", \" all\", \" of\", \"\\r\", \"\\n\", \"Super\", \" Bowl\", \" Sunday\", \" drinking\", \",\", \" a\", \" super\", \" bowl\", \" tradition\", \".\", \"\\u00a0\", \" He\", \" said\", \" he\", \" went\", \" to\", \" bed\", \" about\", \" 9\", \":\", \"30\", \" p\", \".\", \"m\", \".\", \"\\u00a0\", \" He\", \" indicated\", \" he\", \" was\", \" subsequently\", \" awakened\", \" by\", \"\\r\", \"\\n\", \"his\", \" daughter\", \" b\", \"anging\", \" on\", \" his\", \" bedroom\", \" door\", \".\", \"\\u00a0\", \"\\r\", \"\\n\", \"He\", \" said\", \" Flores\", \" came\", \" to\", \" his\", \" bedroom\", \"\\r\", \"\\n\", \"car\", \"rying\", \" a\", \" shotgun\", \" and\", \" saying\"], [\"this\", \" victory\", \".\", \"\\n\", \"\\n\", \"Also\", \" sal\", \"uting\", \" the\", \" late\", \" leaders\", \" of\", \" the\", \" Resistance\", \",\", \" She\", \"ikh\", \" Rag\", \"he\", \"b\", \" Har\", \"b\", \",\", \" Say\", \"y\", \"ed\", \" Abbas\", \" M\", \"ouss\", \"awi\", \",\", \" H\", \"aj\", \" Im\", \"ad\", \" M\", \"ogh\", \"nie\", \"h\", \",\", \" and\", \" abs\", \"ented\", \" Im\", \"am\", \" M\", \"ous\", \"sa\", \" Sad\", \"r\", \",\", \" Say\", \"y\", \"ed\", \" Nas\", \"r\", \"all\", \"ah\", \" assured\", \" that\", \" if\", \" it\", \" were\", \" not\", \" for\", \" these\", \" leaders\", \" who\", \" established\", \" the\", \" Resistance\", \" movement\", \",\", \" all\", \" the\", \" victories\", \" would\", \" not\", \" have\", \" been\", \" achieved\", \".\", \"\\n\", \"\\n\", \"July\", \" War\", \" Aim\", \":\", \" E\", \"lim\", \"inating\", \" the\", \" Resistance\", \"\\n\", \"The\", \" Resistance\", \" leader\", \" pointed\", \" out\", \" that\", \" the\", \" July\", \" war\", \" was\", \" a\", \" main\", \" part\", \" of\", \" a\", \" bigger\", \" plot\", \" to\", \" give\", \" birth\", \" to\", \" a\", \" \\\"\", \"New\", \" Middle\", \" East\", \"\\\".\", \"\\n\", \"\\n\", \"\\\"\", \"A\", \" lot\", \" has\", \" been\"], [\"be\", \" there\", \".\\\"\", \" He\", \" left\", \" when\", \" Young\", \" told\", \" him\", \" to\", \".\", \" When\", \" Young\", \" came\", \" out\", \" a\", \" few\", \" minutes\", \" later\", \",\", \" he\", \" said\", \" \\\"\", \"She\", \" liked\", \" it\", \".\\\"\", \" They\", \" called\", \" a\", \" cab\", \".\", \" Young\", \" had\", \" nothing\", \" in\", \" his\", \" hands\", \".\", \" Boston\", \" also\", \" stated\", \" that\", \" Young\", \" put\", \" nothing\", \" over\", \" the\", \" woman\", \"'s\", \" head\", \",\", \" just\", \" his\", \" hand\", \" over\", \" her\", \" mouth\", \" and\", \" told\", \" her\", \" to\", \" keep\", \" quiet\", \".\", \" Young\", \" was\", \" still\", \" holding\", \" the\", \" woman\", \" when\", \" Boston\", \" left\", \".\", \" Young\", \"'s\", \" version\", \" was\", \" that\", \" when\", \" the\", \" woman\", \" woke\", \" up\", \" she\", \" recognized\", \" him\", \" and\", \" smiled\", \".\", \" She\", \" put\", \" her\", \" arms\", \" around\", \" his\", \" neck\", \" and\", \" made\", \" no\", \" out\", \"cry\", \".\", \" He\", \" did\", \" not\", \" explain\", \" the\", \" scr\", \"atches\", \".\", \"\\n\", \"We\", \" find\", \" little\", \" in\", \" the\", \" statements\", \" of\", \" Bow\", \"ler\", \" and\", \" Boston\", \" to\", \" contradict\", \" his\", \" own\"], [\"                        \", \"                  \", \"3\", \"\\n\", \"\\f\", \"just\", \" did\", \" not\", \" get\", \" back\", \" up\", \"[\", \".\", \"]\\\"\", \" At\", \" that\", \" point\", \" (\", \"about\", \" 4\", \":\", \"30\", \" a\", \".\", \"m\", \".),\", \" Vict\", \"im\", \" \\\"\", \"was\", \" able\", \" to\", \" get\", \" out\", \" of\", \"\\n\", \"\\n\", \"the\", \" room\", \" and\", \" call\", \" the\", \" police\", \".\\\"\", \"\\n\\n\", \"        \", \"Spring\", \"field\", \" Police\", \" Officer\", \" Brandon\", \" Bow\", \"ling\", \" was\", \" dispatched\", \" to\", \" Vict\", \"im\", \"'s\", \" address\", \" at\", \"\\n\", \"\\n\", \"around\", \" 4\", \":\", \"40\", \" a\", \".\", \"m\", \".,\", \" where\", \" he\", \" found\", \" Vict\", \"im\", \" standing\", \" on\", \" the\", \" front\", \" porch\", \".\", \" \\\"\", \"She\", \" seemed\", \" shaken\", \",\", \"\\n\", \"\\n\", \"[\", \"and\", \" she\", \"]\", \" appeared\", \" as\", \" if\", \" she\", \"'d\", \" been\", \" crying\", \".\\\"\", \" Officer\", \" Bow\", \"ling\", \" found\", \" Defendant\", \" lying\", \" asleep\", \"\\n\", \"\\n\", \"on\", \" Vict\", \"im\", \"'s\", \" bedroom\", \" floor\", \".\", \" The\", \" officer\", \" awakened\", \" Defendant\", \" and\", \" placed\", \" him\", \" under\", \" arrest\", \".\", \"\\n\"], [\"pr\", \"ay\", \" for\", \" peace\", \" and\", \" communal\", \" am\", \"ity\", \" in\", \" the\", \" country\", \".\", \" She\", \" said\", \" thousands\", \" of\", \" people\", \" come\", \" to\", \" Delhi\", \" every\", \" year\", \" to\", \" go\", \" for\", \" the\", \" H\", \"aj\", \" pilgr\", \"image\", \".\", \" But\", \" all\", \" of\", \" them\", \" were\", \" not\", \" given\", \" permission\", \",\", \" as\", \" there\", \" was\", \" limited\", \" seats\", \" for\", \" Delhi\", \".\", \"\\n\", \"\\n\", \"New\", \" Delhi\", \",\", \" November\", \" 22\", \"\\n\", \"The\", \" M\", \"CD\", \" Standing\", \" Committee\", \",\", \" at\", \" its\", \" meeting\", \" today\", \",\", \" resolved\", \" to\", \" carry\", \" out\", \" a\", \" survey\", \" to\", \" identify\", \" 1\", \",\", \"000\", \" additional\", \" roads\", \" to\", \" notify\", \" them\", \" for\", \" commercial\", \" or\", \" mixed\", \" land\", \" use\", \".\", \" The\", \" survey\", \" would\", \" be\", \" completed\", \" within\", \" ten\", \" days\", \".\", \"\\n\", \"\\n\", \"The\", \" decision\", \" was\", \" taken\", \" after\", \" a\", \" resolution\", \" was\", \" t\", \"abled\", \" before\", \" the\", \" committee\", \" by\", \" the\", \" Leader\", \" of\", \" the\", \" House\", \",\", \" Mr\", \" J\", \"it\", \"ender\", \" Ko\", \"char\", \".\"], [\"c\", \"ities\", \" (\", \"M\", \"anchester\", \",\", \" Belfast\", \",\", \" Glasgow\", \" and\", \" Edinburgh\", \").\", \" She\", \" met\", \" council\", \" officials\", \" and\", \" media\", \" outlets\", \",\", \" and\", \" set\", \" up\", \" meetings\", \" with\", \" Eric\", \" Pick\", \"les\", \",\", \" secretary\", \" of\", \" state\", \" for\", \" communities\", \" and\", \" local\", \" government\", \",\", \" under\", \" secretary\", \" Don\", \" Foster\", \" and\", \" other\", \" officials\", \",\", \" all\", \",\", \" she\", \" says\", \",\", \" listed\", \" in\", \" her\", \" report\", \".\", \"\\n\", \"\\n\", \"The\", \" trouble\", \" started\", \" when\", \" R\", \"oln\", \"ik\", \" observed\", \" that\", \" the\", \" bedroom\", \" tax\", \" (\", \"where\", \" people\", \" must\", \" pay\", \" for\", \" \\\"\", \"sp\", \"are\", \"\\\"\", \" rooms\", \" through\", \" a\", \" deduction\", \" in\", \" their\", \" housing\", \" benefit\", \")\", \" is\", \" causing\", \" great\", \" hardship\", \" and\", \" distress\", \" to\", \" the\", \" most\", \" vulnerable\", \".\", \" Some\", \" people\", \" she\", \" spoke\", \" to\", \" were\", \" in\", \" tears\", \";\", \" some\", \" said\", \" they\", \" even\", \" contemplated\", \" suicide\", \",\", \" because\", \" they\", \" had\", \" nowhere\", \" to\", \" down\", \"size\", \" to\", \" \\u2013\", \" owing\", \" to\", \" a\"], [\"a\", \" call\", \" from\", \" an\", \" unknown\", \" number\", \",\", \" a\", \" really\", \" worried\", \" voice\", \" from\", \" a\", \" lady\", \" I\", \" didn\", \"\\u2019\", \"t\", \" know\", \",\\u201d\", \" he\", \" says\", \".\", \" \\u201c\", \"She\", \" said\", \",\", \" \\u2018\", \"My\", \" f\", \"iance\", \" Jam\", \"al\", \" K\", \"hash\", \"og\", \"gi\", \" went\", \" into\", \" the\", \" Saudi\", \" cons\", \"ulate\", \" and\", \" didn\", \"\\u2019\", \"t\", \" co\", \" me\", \" out\", \".'\", \"\\u201d\", \"\\n\", \"\\n\", \"Dr\", \" Yas\", \"in\", \" A\", \"kl\", \"ay\", \" Dr\", \" Yas\", \"in\", \" A\", \"kl\", \"ay\", \"\\n\", \"\\n\", \"Y\", \"as\", \"in\", \" swiftly\", \" called\", \" the\", \" head\", \" of\", \" Turkish\", \" intelligence\", \" and\", \" alerted\", \" the\", \" office\", \" of\", \" President\", \" Tay\", \"y\", \"ip\", \" Erd\", \"ogan\", \".\", \"\\n\", \"\\n\", \"By\", \" 18\", \":\", \"30\", \",\", \" the\", \" members\", \" of\", \" the\", \" hit\", \" squad\", \" were\", \" on\", \" a\", \" private\", \" jet\", \" to\", \" Ry\", \"i\", \"adh\", \",\", \" less\", \" than\", \" 24\", \" hours\", \" after\", \" they\", \" had\", \" arrived\", \".\", \"\\n\", \"\\n\", \"The\", \" next\", \" day\", \",\"], [\"and\", \" injuries\", \" to\", \" protest\", \"ors\", \".\", \" No\", \" official\", \" death\", \" total\", \" has\", \" been\", \" released\", \",\", \" but\", \" the\", \" latest\", \" reports\", \" today\", \" have\", \" two\", \" women\", \" being\", \" killed\", \" when\", \" hit\", \" in\", \" the\", \" head\", \" by\", \" tear\", \" gas\", \" and\", \" another\", \" died\", \" in\", \" Tah\", \"ir\", \" Square\", \".\", \" That\", \" would\", \" bring\", \" an\", \" unofficial\", \" death\", \" toll\", \" over\", \" the\", \" past\", \" four\", \" days\", \" to\", \" over\", \" 10\", \".\", \" In\", \" one\", \" instance\", \",\", \" Am\", \"nesty\", \" has\", \" learned\", \" that\", \" 22\", \"-\", \"year\", \"-\", \"old\", \" Ahmed\", \" A\", \"te\", \"f\", \" was\", \" killed\", \" yesterday\", \" in\", \" North\", \" S\", \"inai\", \" when\", \" security\", \" forces\", \" in\", \" the\", \" town\", \" of\", \" She\", \"ikh\", \" Z\", \"u\", \"we\", \"id\", \" opened\", \" fire\", \" on\", \" a\", \" crowd\", \" of\", \" more\", \" than\", \" 1000\", \" demonstr\", \"ators\", \".\", \"\\n\", \"\\n\", \"2\", \".\", \" Independent\", \" legal\", \" observers\", \" count\", \" the\", \" number\", \" of\", \" detained\", \" as\", \" of\", \" Thursday\", \" at\", \" around\", \" 1\", \",\", \"200\", \" people\", \".\"], [\"to\", \" form\", \" leaders\", \" capable\", \" of\", \" \\u201c\", \"responding\", \" to\", \" the\", \" demands\", \" of\", \" living\", \" in\", \" the\", \" American\", \" cultural\", \" context\", \" as\", \" a\", \" people\", \" of\", \" faith\", \",\\u201d\", \" and\", \" helping\", \" others\", \" do\", \" the\", \" same\", \".\", \"\\n\", \"\\n\", \"She\", \" is\", \" one\", \" of\", \" two\", \" MA\", \"FC\", \" students\", \" to\", \" join\", \" 298\", \" under\", \"grad\", \"uates\", \" and\", \" 7\", \"39\", \" graduates\", \" at\", \" the\", \" University\", \"\\u2019\", \"s\", \" 64\", \"th\", \" Comm\", \"ence\", \"ment\", \" Ce\", \"rem\", \"ony\", \" at\", \" Rel\", \"iant\", \" Arena\", \" on\", \" May\", \" 17\", \".\", \"\\n\", \"\\n\", \"Before\", \" graduating\", \",\", \" MF\", \"AC\", \" candidates\", \" must\", \" complete\", \" a\", \" pract\", \"icum\", \" that\", \" incorporates\", \" all\", \" they\", \" have\", \" studied\", \" into\", \" a\", \" community\", \"-\", \"oriented\", \",\", \" service\", \"-\", \"learning\", \" project\", \",\", \" one\", \" that\", \" illustrates\", \" the\", \" integration\", \" of\", \" faith\", \" development\", \" and\", \" civic\", \" responsibility\", \".\", \"\\n\", \"\\n\", \"For\", \" her\", \" pract\", \"icum\", \",\", \" E\", \"ge\", \"a\", \" chose\", \" to\", \" work\", \" for\", \" two\"], [\"again\", \" by\", \" their\", \" families\", \" or\", \" contacts\", \".\", \"\\n\", \"\\n\", \"P\", \"urg\", \"atory\", \" is\", \" minimally\", \" armed\", \" with\", \" G\", \"ARD\", \"IAN\", \" defenses\", \".\", \" Though\", \" a\", \" cruiser\", \"-\", \"weight\", \" ship\", \",\", \" it\", \" relies\", \" on\", \" the\", \" Blue\", \" Sun\", \"s\", \"'\", \" fighters\", \" to\", \" prevent\", \" any\", \" attacks\", \" bent\", \" on\", \" a\", \" jail\", \"break\", \" or\", \" similar\", \" events\", \".\", \"\\n\\n\\n\\n\\n\", \"\\n\", \"M\", \"ission\", \" Edit\", \"\\n\", \"\\n\", \"Upon\", \" arrival\", \" to\", \" the\", \" P\", \"urg\", \"atory\", \",\", \" She\", \"pard\", \" is\", \" informed\", \" that\", \" the\", \" \\\"\", \"package\", \"\\\"\", \" is\", \" being\", \" prepared\", \".\", \" W\", \"arden\", \" Kur\", \"il\", \" indicates\", \" that\", \" Cer\", \"ber\", \"us\", \" paid\", \" for\", \" Jack\", \"'s\", \" release\", \".\", \" She\", \"pard\", \" is\", \" directed\", \" to\", \" the\", \" Out\", \"processing\", \" area\", \" of\", \" the\", \" ship\", \".\", \" On\", \" the\", \" way\", \" to\", \" out\", \"processing\", \",\", \" She\", \"pard\", \" has\", \" the\", \" opportunity\", \" to\", \" stop\", \" the\", \" brutal\", \" interrogation\", \" of\", \" a\", \" prisoner\", \" called\", \" B\"]], \"activations\": [[[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.71875]], [[0.0]], [[0.0]], [[3.4375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.65625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.5625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.5625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.15625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.53125]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.796875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.265625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.46875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.46875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.71875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.859375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.4375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.4375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.4375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.4375]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[3.390625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[4.15625]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x32b3ef390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Or alternatively view with circuitvis\n",
    "def _list_decode(x):\n",
    "    if len(x.shape) == 0:\n",
    "        return pythia_tokenizer.decode(x, skip_special_tokens=True)\n",
    "    else:\n",
    "        return [_list_decode(y) for y in x]\n",
    "\n",
    "selected_token_strs_FKL = _list_decode(selected_token_idxs_FKL)\n",
    "for i in range(selected_activations_FKL.shape[0]):\n",
    "    feat_idx = top_k_indices[i]\n",
    "    print(f\"Feature {feat_idx}:\")\n",
    "    selected_activations_KL11 = [selected_activations_FKL[i, k, :, None, None] for k in range(k_inputs_per_feature)]\n",
    "    html_activations = text_neuron_activations(selected_token_strs_FKL[i], selected_activations_KL11)\n",
    "    display(html_activations)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
