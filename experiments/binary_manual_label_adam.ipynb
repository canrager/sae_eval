{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature labelling and prompt building\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "import datasets\n",
    "import anthropic\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import experiments.utils as utils\n",
    "from experiments.autointerp import (\n",
    "    get_max_activating_prompts,\n",
    "    highlight_top_activations,\n",
    "    compute_dla,\n",
    "    format_examples,\n",
    "    evaluate_binary_llm_output,\n",
    "    get_autointerp_inputs_for_all_saes,\n",
    ")\n",
    "from experiments.explainers.simple.prompt_builder import build_prompt\n",
    "from experiments.explainers.simple.prompts import build_system_prompt\n",
    "\n",
    "DEBUGGING = True\n",
    "\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = dict(scan=True, validate=True)\n",
    "else:\n",
    "    tracer_kwargs = dict(scan=False, validate=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict = {\n",
    "    \"accountant\": 0,\n",
    "    \"architect\": 1,\n",
    "    \"attorney\": 2,\n",
    "    \"chiropractor\": 3,\n",
    "    \"comedian\": 4,\n",
    "    \"composer\": 5,\n",
    "    \"dentist\": 6,\n",
    "    \"dietitian\": 7,\n",
    "    \"dj\": 8,\n",
    "    \"filmmaker\": 9,\n",
    "    \"interior_designer\": 10,\n",
    "    \"journalist\": 11,\n",
    "    \"model\": 12,\n",
    "    \"nurse\": 13,\n",
    "    \"painter\": 14,\n",
    "    \"paralegal\": 15,\n",
    "    \"pastor\": 16,\n",
    "    \"personal_trainer\": 17,\n",
    "    \"photographer\": 18,\n",
    "    \"physician\": 19,\n",
    "    \"poet\": 20,\n",
    "    \"professor\": 21,\n",
    "    \"psychologist\": 22,\n",
    "    \"rapper\": 23,\n",
    "    \"software_engineer\": 24,\n",
    "    \"surgeon\": 25,\n",
    "    \"teacher\": 26,\n",
    "    \"yoga_teacher\": 27,\n",
    "    \"male / female\": \"male / female\",\n",
    "    \"professor / nurse\": \"professor / nurse\",\n",
    "    \"male_professor / female_nurse\": \"male_professor / female_nurse\",\n",
    "    \"biased_male / biased_female\": \"biased_male / biased_female\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "\n",
    "dictionaries_path = \"../dictionary_learning/dictionaries/autointerp_test_data\"\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_topk_ctx128_0730\": {\"resid_post_layer_3\": {\"trainer_ids\": [2, 6, 10, 18]}},\n",
    "    \"gemma-2-2b_test_sae\": {\"resid_post_layer_12\": {\"trainer_ids\": [2]}},\n",
    "}\n",
    "pythia_sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "pythia_submodule_trainers = ae_sweep_paths[pythia_sweep_name]\n",
    "\n",
    "pythia_group_paths = utils.get_ae_group_paths(\n",
    "    dictionaries_path, pythia_sweep_name, pythia_submodule_trainers\n",
    ")\n",
    "pythia_ae_paths = utils.get_ae_paths(pythia_group_paths)\n",
    "\n",
    "gemma_sweep_name = list(ae_sweep_paths.keys())[1]\n",
    "gemma_submodule_trainers = ae_sweep_paths[gemma_sweep_name]\n",
    "\n",
    "gemma_group_paths = utils.get_ae_group_paths(\n",
    "    dictionaries_path, gemma_sweep_name, gemma_submodule_trainers\n",
    ")\n",
    "gemma_ae_paths = utils.get_ae_paths(gemma_group_paths)\n",
    "\n",
    "chosen_class_indices = [\n",
    "    \"male / female\",\n",
    "    \"professor / nurse\",\n",
    "    \"male_professor / female_nurse\",\n",
    "    \"biased_male / biased_female\",\n",
    "    \"accountant\",\n",
    "    \"architect\",\n",
    "    \"attorney\",\n",
    "    \"dentist\",\n",
    "    \"filmmaker\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = [0, 10, 100, 1000]\n",
    "class_indices_1 = [\"male / female\", \"professor / nurse\", \"accountant\", \"architect\"]\n",
    "class_indices_2 = [\"male_professor / female_nurse\", \"attorney\", \"dentist\", \"filmmaker\"]\n",
    "class_indices_3 = class_indices_1 + class_indices_2\n",
    "\n",
    "combinations = [\n",
    "    {\"sae\": pythia_ae_paths[0], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[1], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": pythia_ae_paths[2], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[3], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": gemma_ae_paths[0], \"class_indices\": class_indices_3},\n",
    "]\n",
    "\n",
    "\n",
    "def generate_combinations(sampled_indices, combinations):\n",
    "    result = []\n",
    "    for combo in combinations:\n",
    "        sae = combo[\"sae\"]\n",
    "        class_indices = combo[\"class_indices\"]\n",
    "        for class_index in class_indices:\n",
    "            for sampled_index in sampled_indices:\n",
    "                result.append(\n",
    "                    {\"sae\": sae, \"class_index\": class_index, \"sampled_index\": sampled_index}\n",
    "                )\n",
    "    return result\n",
    "\n",
    "\n",
    "combinations_list = generate_combinations(sampled_indices, combinations)\n",
    "print(f\"There are {len(combinations_list)} combinations to evaluate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia_model_eval_config = utils.ModelEvalConfig.from_sweep_name(pythia_sweep_name)\n",
    "pythia_model_name = pythia_model_eval_config.full_model_name\n",
    "pythia_tokenizer = AutoTokenizer.from_pretrained(pythia_model_name)\n",
    "\n",
    "gemma_model_eval_config = utils.ModelEvalConfig.from_sweep_name(gemma_sweep_name)\n",
    "gemma_model_name = gemma_model_eval_config.full_model_name\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run max activating examples once from all SAEs\n",
    "\n",
    "k_inputs_per_feature = 10\n",
    "example_ae_path = pythia_ae_paths[0]\n",
    "\n",
    "with open(os.path.join(example_ae_path, \"max_activating_inputs.pkl\"), \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find features relevant to a profession from the class_probe node_effects.pkl\n",
    "\n",
    "class_name = \"male / female\"\n",
    "k_features_per_concept = 3\n",
    "\n",
    "filename_counter = \"\"\n",
    "class_id = profession_dict[class_name]\n",
    "node_effects_filename = f\"{example_ae_path}/node_effects{filename_counter}.pkl\"\n",
    "\n",
    "with open(node_effects_filename, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "print(effects.shape)\n",
    "\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, k_features_per_concept)\n",
    "t.set_printoptions(sci_mode=False)\n",
    "print(top_k_values)\n",
    "print(top_k_indices)\n",
    "\n",
    "selected_token_idxs_FKL = max_token_idxs_FKL[top_k_indices]\n",
    "selected_activations_FKL = max_activations_FKL[top_k_indices]\n",
    "top_dla_token_idxs_FK = top_dla_token_idxs_FK[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format max_activating_inputs by << emphasizing>> max act examples\n",
    "\n",
    "num_top_emphasized_tokens = 5\n",
    "\n",
    "print(top_dla_token_idxs_FK.shape)\n",
    "\n",
    "example_prompts = format_examples(\n",
    "    pythia_tokenizer, selected_token_idxs_FKL, selected_activations_FKL, num_top_emphasized_tokens\n",
    ")\n",
    "\n",
    "top_dla_tokens_list = []\n",
    "\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_FK, pythia_tokenizer)\n",
    "tokens = tokens_list[0]\n",
    "\n",
    "print(\",\".join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "# Checking for features that didn't activate on at least displayed_prompts inputs\n",
    "\n",
    "displayed_prompts = 10\n",
    "for current_combination in combinations_list:\n",
    "    ae_path = current_combination[\"sae\"]\n",
    "    class_index = current_combination[\"class_index\"]\n",
    "    sampled_index = current_combination[\"sampled_index\"]\n",
    "\n",
    "    class_id = profession_dict[class_index]\n",
    "\n",
    "    if \"pythia\" in ae_path:\n",
    "        tokenizer = pythia_tokenizer\n",
    "    else:\n",
    "        tokenizer = gemma_tokenizer\n",
    "\n",
    "    inputs_path = os.path.join(ae_path, \"max_activating_inputs.pkl\")\n",
    "    node_effects_path = os.path.join(ae_path, \"node_effects.pkl\")\n",
    "\n",
    "    with open(inputs_path, \"rb\") as f:\n",
    "        max_activating_inputs = pickle.load(f)\n",
    "\n",
    "    with open(node_effects_path, \"rb\") as f:\n",
    "        node_effects = pickle.load(f)\n",
    "\n",
    "    max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "    max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "    top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]\n",
    "\n",
    "    effects = node_effects[class_id]\n",
    "\n",
    "    top_k_values, top_k_indices = t.topk(effects, 2000)\n",
    "\n",
    "    sae_feat_index = top_k_indices[sampled_index]\n",
    "\n",
    "    selected_token_idxs_1KL = max_token_idxs_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "    selected_activations_1KL = max_activations_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(\n",
    "        0\n",
    "    )\n",
    "    top_dla_token_idxs_K = top_dla_token_idxs_FK[sae_feat_index]\n",
    "\n",
    "    selected_activations_K = einops.reduce(selected_activations_1KL, \"1 K L -> K\", \"sum\")\n",
    "    selected_activations_nonzero = selected_activations_K[selected_activations_K != 0]\n",
    "\n",
    "    if selected_activations_nonzero.shape != selected_activations_K.shape:\n",
    "        print(\n",
    "            f\"Warning: {selected_activations_K.shape} activations, {selected_activations_nonzero.shape} non-zero activations\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANUAL LABELING BEGINS HERE\n",
    "\n",
    "Run manual inputs creation to view DLA and top 4 example prompts.\n",
    "\n",
    "Add scores / chain of thought to Label adding per example.\n",
    "\n",
    "Save as json once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_idx = 0\n",
    "\n",
    "displayed_prompts = 10\n",
    "num_top_emphasized_tokens = 5\n",
    "include_activations = True\n",
    "t.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual inputs creation\n",
    "\n",
    "current_combination = combinations_list[current_idx]\n",
    "ae_path = current_combination[\"sae\"]\n",
    "class_index = current_combination[\"class_index\"]\n",
    "sampled_index = current_combination[\"sampled_index\"]\n",
    "\n",
    "class_id = profession_dict[class_index]\n",
    "\n",
    "if \"pythia\" in ae_path:\n",
    "    tokenizer = pythia_tokenizer\n",
    "else:\n",
    "    tokenizer = gemma_tokenizer\n",
    "\n",
    "print(f\"current idx: {current_idx}\")\n",
    "print(f\"SAE path: {ae_path}\")\n",
    "print(f\"class index: {class_index}\")\n",
    "print(f\"sampled index: {sampled_index}\")\n",
    "\n",
    "inputs_path = os.path.join(ae_path, \"max_activating_inputs.pkl\")\n",
    "node_effects_path = os.path.join(ae_path, \"node_effects.pkl\")\n",
    "\n",
    "with open(inputs_path, \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "with open(node_effects_path, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]\n",
    "\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, 2000)\n",
    "\n",
    "sae_feat_index = top_k_indices[sampled_index]\n",
    "\n",
    "selected_token_idxs_1KL = max_token_idxs_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "selected_activations_1KL = max_activations_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "top_dla_token_idxs_K = top_dla_token_idxs_FK[sae_feat_index]\n",
    "\n",
    "example_prompts = format_examples(\n",
    "    tokenizer,\n",
    "    selected_token_idxs_1KL,\n",
    "    selected_activations_1KL,\n",
    "    num_top_emphasized_tokens,\n",
    "    include_activations,\n",
    ")\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_K, tokenizer)\n",
    "tokens_string = \",\".join(tokens_list)\n",
    "\n",
    "print(tokens_string)\n",
    "print(example_prompts[0])\n",
    "\n",
    "previous_idx = current_idx\n",
    "current_idx += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label adding\n",
    "\n",
    "per_class_scores = {\n",
    "    \"male / female\": 0,\n",
    "    \"professor / nurse\": 4,\n",
    "    \"male_professor / female_nurse\": 4,\n",
    "    \"accountant\": 0,\n",
    "    \"architect\": 0,\n",
    "    \"attorney\": 0,\n",
    "    \"dentist\": 0,\n",
    "    \"filmmaker\": 0,\n",
    "}\n",
    "\n",
    "chain_of_thought = \"\"\"The top promoted logits are not legible. The activating inputs are all related to medical terminology and cases.\n",
    "Thus, I will rate this as a 4 for the nurse profession.\"\"\"\n",
    "\n",
    "new_label = {\n",
    "    \"sae\": ae_path,\n",
    "    \"class_index\": class_index,\n",
    "    \"sampled_index\": sampled_index,\n",
    "    \"sae_feat_index\": sae_feat_index.item(),\n",
    "    \"example_prompts\": example_prompts,\n",
    "    \"tokens_string\": tokens_string,\n",
    "    \"per_class_scores\": per_class_scores,\n",
    "    \"chain_of_thought\": chain_of_thought,\n",
    "}\n",
    "\n",
    "manual_labels[previous_idx] = new_label\n",
    "\n",
    "print(f\"Add the following idx to manual_labels: {previous_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manual_labels.keys())\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def update_json_file(filename, new_data):\n",
    "    try:\n",
    "        # Read existing data\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, start with an empty dictionary\n",
    "        data = {}\n",
    "\n",
    "    # Convert all keys to strings (if they aren't already)\n",
    "    data = {str(k): v for k, v in data.items()}\n",
    "    new_data = {str(k): v for k, v in new_data.items()}\n",
    "\n",
    "    # Update data with new_data (this overwrites existing keys)\n",
    "    data.update(new_data)\n",
    "\n",
    "    # Write updated data back to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "\n",
    "filename = \"manual_labels.json\"\n",
    "update_json_file(filename, manual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = build_system_prompt(\n",
    "#     cot=False,\n",
    "#     concepts=list(profession_dict.keys()),\n",
    "#     logits=True\n",
    "# )\n",
    "\n",
    "# prompts = []\n",
    "# for example_prompt, top_dla_tokens_K in zip(example_prompts, top_dla_tokens_FK):\n",
    "#     message = build_prompt(\n",
    "#         examples=example_prompt,\n",
    "#         cot=False,\n",
    "#         top_logits=top_dla_tokens_K,\n",
    "#     )\n",
    "#     prompts.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(system_prompt[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat_examples in enumerate(example_prompts):\n",
    "    print(f\"############### Max act examples for Feature {top_k_indices[i]}:\")\n",
    "    print(feat_examples)\n",
    "    print(f\"############### Top dla tokens for Feature {top_k_indices[i]}:\")\n",
    "    print(top_dla_tokens_FK[i])\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render prompt for human labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or alternatively view with circuitvis\n",
    "def _list_decode(x):\n",
    "    if len(x.shape) == 0:\n",
    "        return pythia_tokenizer.decode(x, skip_special_tokens=True)\n",
    "    else:\n",
    "        return [_list_decode(y) for y in x]\n",
    "\n",
    "\n",
    "selected_token_strs_FKL = _list_decode(selected_token_idxs_FKL)\n",
    "for i in range(selected_activations_FKL.shape[0]):\n",
    "    feat_idx = top_k_indices[i]\n",
    "    print(f\"Feature {feat_idx}:\")\n",
    "    selected_activations_KL11 = [\n",
    "        selected_activations_FKL[i, k, :, None, None] for k in range(k_inputs_per_feature)\n",
    "    ]\n",
    "    html_activations = text_neuron_activations(\n",
    "        selected_token_strs_FKL[i], selected_activations_KL11\n",
    "    )\n",
    "    display(html_activations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
