{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature labelling and prompt building\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "import datasets\n",
    "import anthropic\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "import json\n",
    "\n",
    "import experiments.utils as utils\n",
    "from experiments.autointerp import (\n",
    "    get_max_activating_prompts,\n",
    "    highlight_top_activations,\n",
    "    compute_dla,\n",
    "    format_examples,\n",
    "    evaluate_binary_llm_output,\n",
    "    get_autointerp_inputs_for_all_saes,\n",
    ")\n",
    "from experiments.explainers.simple.prompt_builder import build_prompt\n",
    "from experiments.explainers.simple.prompts import build_system_prompt\n",
    "\n",
    "DEBUGGING = True\n",
    "\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = dict(scan=True, validate=True)\n",
    "else:\n",
    "    tracer_kwargs = dict(scan=False, validate=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict = {\n",
    "    \"accountant\": 0,\n",
    "    \"architect\": 1,\n",
    "    \"attorney\": 2,\n",
    "    \"chiropractor\": 3,\n",
    "    \"comedian\": 4,\n",
    "    \"composer\": 5,\n",
    "    \"dentist\": 6,\n",
    "    \"dietitian\": 7,\n",
    "    \"dj\": 8,\n",
    "    \"filmmaker\": 9,\n",
    "    \"interior_designer\": 10,\n",
    "    \"journalist\": 11,\n",
    "    \"model\": 12,\n",
    "    \"nurse\": 13,\n",
    "    \"painter\": 14,\n",
    "    \"paralegal\": 15,\n",
    "    \"pastor\": 16,\n",
    "    \"personal_trainer\": 17,\n",
    "    \"photographer\": 18,\n",
    "    \"physician\": 19,\n",
    "    \"poet\": 20,\n",
    "    \"professor\": 21,\n",
    "    \"psychologist\": 22,\n",
    "    \"rapper\": 23,\n",
    "    \"software_engineer\": 24,\n",
    "    \"surgeon\": 25,\n",
    "    \"teacher\": 26,\n",
    "    \"yoga_teacher\": 27,\n",
    "    \"male / female\": \"male / female\",\n",
    "    \"professor / nurse\": \"professor / nurse\",\n",
    "    \"male_professor / female_nurse\": \"male_professor / female_nurse\",\n",
    "    \"biased_male / biased_female\": \"biased_male / biased_female\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "\n",
    "dictionaries_path = \"../dictionary_learning/dictionaries/autointerp_test_data\"\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_topk_ctx128_0730\": {\"resid_post_layer_3\": {\"trainer_ids\": [2, 6, 10, 18]}},\n",
    "    \"gemma-2-2b_test_sae\": {\"resid_post_layer_12\": {\"trainer_ids\": [2]}},\n",
    "}\n",
    "pythia_sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "pythia_submodule_trainers = ae_sweep_paths[pythia_sweep_name]\n",
    "\n",
    "pythia_group_paths = utils.get_ae_group_paths(\n",
    "    dictionaries_path, pythia_sweep_name, pythia_submodule_trainers\n",
    ")\n",
    "pythia_ae_paths = utils.get_ae_paths(pythia_group_paths)\n",
    "\n",
    "gemma_sweep_name = list(ae_sweep_paths.keys())[1]\n",
    "gemma_submodule_trainers = ae_sweep_paths[gemma_sweep_name]\n",
    "\n",
    "gemma_group_paths = utils.get_ae_group_paths(\n",
    "    dictionaries_path, gemma_sweep_name, gemma_submodule_trainers\n",
    ")\n",
    "gemma_ae_paths = utils.get_ae_paths(gemma_group_paths)\n",
    "\n",
    "chosen_class_indices = [\n",
    "    \"male / female\",\n",
    "    \"professor / nurse\",\n",
    "    \"male_professor / female_nurse\",\n",
    "    \"biased_male / biased_female\",\n",
    "    \"accountant\",\n",
    "    \"architect\",\n",
    "    \"attorney\",\n",
    "    \"dentist\",\n",
    "    \"filmmaker\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = [0, 10, 100, 1000]\n",
    "class_indices_1 = [\"male / female\", \"professor / nurse\", \"accountant\", \"architect\"]\n",
    "class_indices_2 = [\"male_professor / female_nurse\", \"attorney\", \"dentist\", \"filmmaker\"]\n",
    "class_indices_3 = class_indices_1 + class_indices_2\n",
    "\n",
    "combinations = [\n",
    "    {\"sae\": pythia_ae_paths[0], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[1], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": pythia_ae_paths[2], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[3], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": gemma_ae_paths[0], \"class_indices\": class_indices_3},\n",
    "]\n",
    "\n",
    "\n",
    "def generate_combinations(sampled_indices, combinations):\n",
    "    result = []\n",
    "    for combo in combinations:\n",
    "        sae = combo[\"sae\"]\n",
    "        class_indices = combo[\"class_indices\"]\n",
    "        for class_index in class_indices:\n",
    "            for sampled_index in sampled_indices:\n",
    "                result.append(\n",
    "                    {\"sae\": sae, \"class_index\": class_index, \"sampled_index\": sampled_index}\n",
    "                )\n",
    "    return result\n",
    "\n",
    "\n",
    "orig_combinations_list = generate_combinations(sampled_indices, combinations)\n",
    "random.seed(1776)\n",
    "combinations_list = orig_combinations_list.copy()\n",
    "random.shuffle(combinations_list)\n",
    "print(f\"There are {len(combinations_list)} combinations to evaluate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combinations_list[2])\n",
    "assert combinations_list[0] == {'sae': '../dictionary_learning/dictionaries/autointerp_test_data/pythia70m_sweep_topk_ctx128_0730/resid_post_layer_3/trainer_6', 'class_index': 'dentist', 'sampled_index': 100}\n",
    "assert combinations_list[2] == {'sae': '../dictionary_learning/dictionaries/autointerp_test_data/pythia70m_sweep_topk_ctx128_0730/resid_post_layer_3/trainer_10', 'class_index': 'male / female', 'sampled_index': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia_model_eval_config = utils.ModelEvalConfig.from_sweep_name(pythia_sweep_name)\n",
    "pythia_model_name = pythia_model_eval_config.full_model_name\n",
    "pythia_tokenizer = AutoTokenizer.from_pretrained(pythia_model_name)\n",
    "\n",
    "gemma_model_eval_config = utils.ModelEvalConfig.from_sweep_name(gemma_sweep_name)\n",
    "gemma_model_name = gemma_model_eval_config.full_model_name\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run max activating examples once from all SAEs\n",
    "\n",
    "k_inputs_per_feature = 10\n",
    "example_ae_path = pythia_ae_paths[0]\n",
    "\n",
    "with open(os.path.join(example_ae_path, \"max_activating_inputs.pkl\"), \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find features relevant to a profession from the class_probe node_effects.pkl\n",
    "\n",
    "class_name = \"male / female\"\n",
    "k_features_per_concept = 3\n",
    "\n",
    "filename_counter = \"\"\n",
    "class_id = profession_dict[class_name]\n",
    "node_effects_filename = f\"{example_ae_path}/node_effects{filename_counter}.pkl\"\n",
    "\n",
    "with open(node_effects_filename, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "print(effects.shape)\n",
    "\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, k_features_per_concept)\n",
    "t.set_printoptions(sci_mode=False)\n",
    "print(top_k_values)\n",
    "print(top_k_indices)\n",
    "\n",
    "selected_token_idxs_FKL = max_token_idxs_FKL[top_k_indices]\n",
    "selected_activations_FKL = max_activations_FKL[top_k_indices]\n",
    "top_dla_token_idxs_FK = top_dla_token_idxs_FK[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format max_activating_inputs by << emphasizing>> max act examples\n",
    "\n",
    "num_top_emphasized_tokens = 5\n",
    "\n",
    "print(top_dla_token_idxs_FK.shape)\n",
    "\n",
    "example_prompts = format_examples(\n",
    "    pythia_tokenizer, selected_token_idxs_FKL, selected_activations_FKL, num_top_emphasized_tokens\n",
    ")\n",
    "\n",
    "top_dla_tokens_list = []\n",
    "\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_FK, pythia_tokenizer)\n",
    "tokens = tokens_list[0]\n",
    "\n",
    "print(\",\".join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "# Checking for features that didn't activate on at least displayed_prompts inputs\n",
    "\n",
    "displayed_prompts = 10\n",
    "for current_combination in combinations_list:\n",
    "    ae_path = current_combination[\"sae\"]\n",
    "    class_index = current_combination[\"class_index\"]\n",
    "    sampled_index = current_combination[\"sampled_index\"]\n",
    "\n",
    "    class_id = profession_dict[class_index]\n",
    "\n",
    "    if \"pythia\" in ae_path:\n",
    "        tokenizer = pythia_tokenizer\n",
    "    else:\n",
    "        tokenizer = gemma_tokenizer\n",
    "\n",
    "    inputs_path = os.path.join(ae_path, \"max_activating_inputs.pkl\")\n",
    "    node_effects_path = os.path.join(ae_path, \"node_effects.pkl\")\n",
    "\n",
    "    with open(inputs_path, \"rb\") as f:\n",
    "        max_activating_inputs = pickle.load(f)\n",
    "\n",
    "    with open(node_effects_path, \"rb\") as f:\n",
    "        node_effects = pickle.load(f)\n",
    "\n",
    "    max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "    max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "    top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]\n",
    "\n",
    "    effects = node_effects[class_id]\n",
    "\n",
    "    top_k_values, top_k_indices = t.topk(effects, 2000)\n",
    "\n",
    "    sae_feat_index = top_k_indices[sampled_index]\n",
    "\n",
    "    selected_token_idxs_1KL = max_token_idxs_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "    selected_activations_1KL = max_activations_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(\n",
    "        0\n",
    "    )\n",
    "    top_dla_token_idxs_K = top_dla_token_idxs_FK[sae_feat_index]\n",
    "\n",
    "    selected_activations_K = einops.reduce(selected_activations_1KL, \"1 K L -> K\", \"sum\")\n",
    "    selected_activations_nonzero = selected_activations_K[selected_activations_K != 0]\n",
    "\n",
    "    if selected_activations_nonzero.shape != selected_activations_K.shape:\n",
    "        print(\n",
    "            f\"Warning: {selected_activations_K.shape} activations, {selected_activations_nonzero.shape} non-zero activations\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANUAL LABELING BEGINS HERE\n",
    "\n",
    "Run manual inputs creation to view DLA and top 4 example prompts.\n",
    "\n",
    "Add scores / chain of thought to Label adding per example.\n",
    "\n",
    "Save as json once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"manual_labels.json\", \"r\") as f:\n",
    "    manual_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_idx = 7\n",
    "\n",
    "displayed_prompts = 10\n",
    "num_top_emphasized_tokens = 5\n",
    "include_activations = True\n",
    "t.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual inputs creation\n",
    "\n",
    "current_combination = combinations_list[current_idx]\n",
    "ae_path = current_combination[\"sae\"]\n",
    "class_index = current_combination[\"class_index\"]\n",
    "sampled_index = current_combination[\"sampled_index\"]\n",
    "\n",
    "class_id = profession_dict[class_index]\n",
    "\n",
    "if \"pythia\" in ae_path:\n",
    "    tokenizer = pythia_tokenizer\n",
    "else:\n",
    "    tokenizer = gemma_tokenizer\n",
    "\n",
    "print(f\"current idx: {current_idx}\")\n",
    "print(f\"SAE path: {ae_path}\")\n",
    "print(f\"class index: {class_index}\")\n",
    "print(f\"sampled index: {sampled_index}\")\n",
    "\n",
    "inputs_path = os.path.join(ae_path, \"max_activating_inputs.pkl\")\n",
    "node_effects_path = os.path.join(ae_path, \"node_effects.pkl\")\n",
    "\n",
    "with open(inputs_path, \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "with open(node_effects_path, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]\n",
    "\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, 2000)\n",
    "\n",
    "sae_feat_index = top_k_indices[sampled_index]\n",
    "\n",
    "selected_token_idxs_1KL = max_token_idxs_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "selected_activations_1KL = max_activations_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "top_dla_token_idxs_K = top_dla_token_idxs_FK[sae_feat_index]\n",
    "\n",
    "example_prompts = format_examples(\n",
    "    tokenizer,\n",
    "    selected_token_idxs_1KL,\n",
    "    selected_activations_1KL,\n",
    "    num_top_emphasized_tokens,\n",
    "    include_activations,\n",
    ")\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_K, tokenizer)\n",
    "tokens_string = \",\".join(tokens_list)\n",
    "\n",
    "# Show activations in HTML\n",
    "selected_token_strs_1KL = utils.list_decode(selected_token_idxs_1KL, tokenizer)\n",
    "highlighted_token_idxs_1KL = t.topk(selected_activations_1KL, num_top_emphasized_tokens, dim=-1).indices\n",
    "\n",
    "highlighted_token_values_1KL = t.zeros_like(selected_activations_1KL)\n",
    "highlighted_token_values_1KL.scatter_(-1, highlighted_token_idxs_1KL, selected_activations_1KL.gather(-1, highlighted_token_idxs_1KL))\n",
    "\n",
    "selected_activations_KL11 = [highlighted_token_values_1KL[0, k, :, None, None] for k in range(k_inputs_per_feature)]\n",
    "html_activations = text_neuron_activations(selected_token_strs_1KL[0], selected_activations_KL11)\n",
    "\n",
    "print(tokens_string)\n",
    "# print(example_prompts[0])\n",
    "display(html_activations)\n",
    "\n",
    "previous_idx = current_idx\n",
    "current_idx += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(previous_idx) in manual_labels:\n",
    "    print(f\"per_class_scores: {manual_labels[str(previous_idx)]['per_class_scores']}\")\n",
    "    print(f\"chain_of_thought: {manual_labels[str(previous_idx)]['chain_of_thought']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label adding\n",
    "\n",
    "per_class_scores = {\n",
    "    \"male / female\": 0,\n",
    "    \"professor / nurse\": 0,\n",
    "    \"male_professor / female_nurse\": 0,\n",
    "    \"accountant\": 1,\n",
    "    \"architect\": 0,\n",
    "    \"attorney\": 1,\n",
    "    \"dentist\": 0,\n",
    "    \"filmmaker\": 0,\n",
    "}\n",
    "\n",
    "chain_of_thought = \"\"\"The top promoted logits don't have an obvious pattern.\n",
    "The activating inputs are primarily on words like club, service, etc.\n",
    "This possibly relates to attornies and accountants.\n",
    "I will rate both classes as a 1.\"\"\"\n",
    "\n",
    "# chain_of_thought = \"\"\"The top promoted logits don't have an obvious pattern.\n",
    "# The activating inputs are primarily on spaces.\n",
    "# I don't see an obvious pattern.\n",
    "# I will rate all classes as a 0.\"\"\"\n",
    "\n",
    "new_label = {\n",
    "    \"sae\": ae_path,\n",
    "    \"class_index\": class_index,\n",
    "    \"sampled_index\": sampled_index,\n",
    "    \"sae_feat_index\": sae_feat_index.item(),\n",
    "    \"example_prompts\": example_prompts,\n",
    "    \"tokens_string\": tokens_string,\n",
    "    \"per_class_scores\": per_class_scores,\n",
    "    \"chain_of_thought\": chain_of_thought,\n",
    "}\n",
    "\n",
    "manual_labels[previous_idx] = new_label\n",
    "\n",
    "print(f\"Add the following idx to manual_labels: {previous_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manual_labels.keys())\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def update_json_file(filename, new_data):\n",
    "    try:\n",
    "        # Read existing data\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, start with an empty dictionary\n",
    "        data = {}\n",
    "\n",
    "    # Convert all keys to strings (if they aren't already)\n",
    "    data = {str(k): v for k, v in data.items()}\n",
    "    new_data = {str(k): v for k, v in new_data.items()}\n",
    "\n",
    "    print(f\"Existing keys: {data.keys()}\")\n",
    "    print(f\"New keys: {new_data.keys()}\")\n",
    "\n",
    "    # Update data with new_data (this overwrites existing keys)\n",
    "    data.update(new_data)\n",
    "\n",
    "    # Write updated data back to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "\n",
    "filename = \"manual_labels.json\"\n",
    "update_json_file(filename, manual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the JSON files\n",
    "with open('manual_labels.json', 'r') as f:\n",
    "    manual_labels = json.load(f)\n",
    "\n",
    "with open('manual_labels_can.json', 'r') as f:\n",
    "    manual_labels_can = json.load(f)\n",
    "\n",
    "# Function to create a bar chart for a single key\n",
    "def create_chart(key):\n",
    "    labels = manual_labels[key]['per_class_scores'].keys()\n",
    "    manual_scores = [manual_labels[key]['per_class_scores'][label] for label in labels]\n",
    "    if key not in manual_labels_can:\n",
    "        print(f\"Key {key} not found in manual_labels_can.\")\n",
    "        return\n",
    "    can_scores = [manual_labels_can[key]['per_class_scores'][label] for label in labels]\n",
    "\n",
    "    x = range(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar([i - width/2 for i in x], manual_scores, width, label='manual_labels')\n",
    "    ax.bar([i + width/2 for i in x], can_scores, width, label='manual_labels_can')\n",
    "\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(f'Comparison of Scores for Key {key}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f'comparison_chart_key_{key}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Create charts for all keys\n",
    "for key in manual_labels.keys():\n",
    "    create_chart(key)\n",
    "\n",
    "print(\"All charts have been generated and saved as PNG files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
