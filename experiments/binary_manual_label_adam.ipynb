{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature labelling and prompt building\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "import datasets\n",
    "import anthropic\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import ast\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import experiments.utils as utils\n",
    "from experiments.autointerp import (\n",
    "    get_max_activating_prompts, \n",
    "    highlight_top_activations,\n",
    "    compute_dla, \n",
    "    format_examples,\n",
    "    evaluate_binary_llm_output,\n",
    "    get_autointerp_inputs_for_all_saes,\n",
    ")\n",
    "from experiments.explainers.simple.prompt_builder import build_prompt\n",
    "from experiments.explainers.simple.prompts import build_system_prompt\n",
    "\n",
    "DEBUGGING = True\n",
    "\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = dict(scan=True, validate=True)\n",
    "else:\n",
    "    tracer_kwargs = dict(scan=False, validate=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_dict = {\n",
    "    \"accountant\": 0, \"architect\": 1, \"attorney\": 2, \"chiropractor\": 3,\n",
    "    \"comedian\": 4, \"composer\": 5, \"dentist\": 6, \"dietitian\": 7,\n",
    "    \"dj\": 8, \"filmmaker\": 9, \"interior_designer\": 10, \"journalist\": 11,\n",
    "    \"model\": 12, \"nurse\": 13, \"painter\": 14, \"paralegal\": 15,\n",
    "    \"pastor\": 16, \"personal_trainer\": 17, \"photographer\": 18, \"physician\": 19,\n",
    "    \"poet\": 20, \"professor\": 21, \"psychologist\": 22, \"rapper\": 23,\n",
    "    \"software_engineer\": 24, \"surgeon\": 25, \"teacher\": 26, \"yoga_teacher\": 27,\n",
    "    \"male / female\": \"male / female\", \"professor / nurse\": \"professor / nurse\",\n",
    "    \"male_professor / female_nurse\": \"male_professor / female_nurse\",\n",
    "    \"biased_male / biased_female\": \"biased_male / biased_female\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "\n",
    "dictionaries_path = \"../dictionary_learning/dictionaries/autointerp_test_data\"\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_topk_ctx128_0730\": {\"resid_post_layer_3\": {\"trainer_ids\": [2, 6, 10, 18]}},\n",
    "    \"gemma-2-2b_test_sae\": {\"resid_post_layer_12\": {\"trainer_ids\": [2]}}, \n",
    "}\n",
    "pythia_sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "pythia_submodule_trainers = ae_sweep_paths[pythia_sweep_name]\n",
    "\n",
    "pythia_group_paths = utils.get_ae_group_paths(dictionaries_path, pythia_sweep_name, pythia_submodule_trainers)\n",
    "pythia_ae_paths = utils.get_ae_paths(pythia_group_paths)\n",
    "\n",
    "gemma_sweep_name = list(ae_sweep_paths.keys())[1]\n",
    "gemma_submodule_trainers = ae_sweep_paths[gemma_sweep_name]\n",
    "\n",
    "gemma_group_paths = utils.get_ae_group_paths(dictionaries_path, gemma_sweep_name, gemma_submodule_trainers)\n",
    "gemma_ae_paths = utils.get_ae_paths(gemma_group_paths)\n",
    "\n",
    "chosen_class_indices = [\n",
    "        \"male / female\",\n",
    "        \"professor / nurse\",\n",
    "        \"male_professor / female_nurse\",\n",
    "        \"biased_male / biased_female\",\n",
    "        \"accountant\",\n",
    "        \"architect\",\n",
    "        \"attorney\",\n",
    "        \"dentist\",\n",
    "        \"filmmaker\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = [0, 10, 100, 1000]\n",
    "class_indices_1 = [\"male / female\", \"professor / nurse\", \"accountant\", \"architect\"]\n",
    "class_indices_2 = [\"male_professor / female_nurse\", \"attorney\", \"dentist\", \"filmmaker\"]\n",
    "class_indices_3 = class_indices_1 + class_indices_2\n",
    "\n",
    "combinations = [\n",
    "    {\"sae\": pythia_ae_paths[0], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[1], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": pythia_ae_paths[2], \"class_indices\": class_indices_1},\n",
    "    {\"sae\": pythia_ae_paths[3], \"class_indices\": class_indices_2},\n",
    "    {\"sae\": gemma_ae_paths[0], \"class_indices\": class_indices_3},\n",
    "]\n",
    "\n",
    "def generate_combinations(sampled_indices, combinations):\n",
    "    result = []\n",
    "    for combo in combinations:\n",
    "        sae = combo[\"sae\"]\n",
    "        class_indices = combo[\"class_indices\"]\n",
    "        for class_index in class_indices:\n",
    "            for sampled_index in sampled_indices:\n",
    "                result.append({\n",
    "                    \"sae\": sae,\n",
    "                    \"class_index\": class_index,\n",
    "                    \"sampled_index\": sampled_index\n",
    "                })\n",
    "    return result\n",
    "\n",
    "combinations_list = generate_combinations(sampled_indices, combinations)\n",
    "print(f\"There are {len(combinations_list)} combinations to evaluate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythia_model_eval_config = utils.ModelEvalConfig.from_sweep_name(pythia_sweep_name)\n",
    "pythia_model_name = pythia_model_eval_config.full_model_name\n",
    "pythia_tokenizer = AutoTokenizer.from_pretrained(pythia_model_name)\n",
    "\n",
    "gemma_model_eval_config = utils.ModelEvalConfig.from_sweep_name(gemma_sweep_name)\n",
    "gemma_model_name = gemma_model_eval_config.full_model_name\n",
    "gemma_tokenizer = AutoTokenizer.from_pretrained(gemma_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run max activating examples once from all SAEs\n",
    "\n",
    "k_inputs_per_feature = 10\n",
    "example_ae_path = pythia_ae_paths[0]\n",
    "\n",
    "with open(os.path.join(example_ae_path, \"max_activating_inputs.pkl\"), \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find features relevant to a profession from the class_probe node_effects.pkl\n",
    "\n",
    "class_name = \"male / female\"\n",
    "k_features_per_concept = 3 \n",
    "\n",
    "filename_counter = \"\"\n",
    "class_id = profession_dict[class_name]\n",
    "node_effects_filename = f\"{example_ae_path}/node_effects{filename_counter}.pkl\"\n",
    "\n",
    "with open(node_effects_filename, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "print(effects.shape)\n",
    "\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, k_features_per_concept)\n",
    "t.set_printoptions(sci_mode=False)\n",
    "print(top_k_values)\n",
    "print(top_k_indices)\n",
    "\n",
    "selected_token_idxs_FKL = max_token_idxs_FKL[top_k_indices]\n",
    "selected_activations_FKL = max_activations_FKL[top_k_indices]\n",
    "top_dla_token_idxs_FK = top_dla_token_idxs_FK[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format max_activating_inputs by << emphasizing>> max act examples\n",
    "\n",
    "num_top_emphasized_tokens = 5\n",
    "\n",
    "print(top_dla_token_idxs_FK.shape)\n",
    "\n",
    "example_prompts = format_examples(pythia_tokenizer, selected_token_idxs_FKL, selected_activations_FKL, num_top_emphasized_tokens)\n",
    "\n",
    "top_dla_tokens_list = []\n",
    "\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_FK, pythia_tokenizer)\n",
    "tokens = tokens_list[0]\n",
    "\n",
    "print(\",\".join(tokens))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANUAL LABELING BEGINS HERE\n",
    "\n",
    "Run manual inputs creation to view DLA and top 4 example prompts.\n",
    "\n",
    "Add scores / chain of thought to Label adding per example.\n",
    "\n",
    "Save as json once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_idx = 0\n",
    "\n",
    "displayed_prompts = 10\n",
    "num_top_emphasized_tokens = 5\n",
    "t.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual inputs creation\n",
    "\n",
    "current_combination = combinations_list[current_idx]\n",
    "ae_path = current_combination[\"sae\"]\n",
    "class_index = current_combination[\"class_index\"]\n",
    "sampled_index = current_combination[\"sampled_index\"]\n",
    "\n",
    "class_id = profession_dict[class_index]\n",
    "\n",
    "if \"pythia\" in ae_path:\n",
    "    tokenizer = pythia_tokenizer\n",
    "else:\n",
    "    tokenizer = gemma_tokenizer\n",
    "\n",
    "print(f\"current idx: {current_idx}\")\n",
    "print(f\"SAE path: {ae_path}\")\n",
    "print(f\"class index: {class_index}\")\n",
    "print(f\"sampled index: {sampled_index}\")\n",
    "\n",
    "inputs_path = os.path.join(ae_path, \"max_activating_inputs.pkl\")\n",
    "node_effects_path = os.path.join(ae_path, \"node_effects.pkl\")\n",
    "\n",
    "with open(inputs_path, \"rb\") as f:\n",
    "    max_activating_inputs = pickle.load(f)\n",
    "\n",
    "with open(node_effects_path, \"rb\") as f:\n",
    "    node_effects = pickle.load(f)\n",
    "\n",
    "max_token_idxs_FKL = max_activating_inputs[\"max_tokens_FKL\"]\n",
    "max_activations_FKL = max_activating_inputs[\"max_activations_FKL\"]\n",
    "top_dla_token_idxs_FK = max_activating_inputs[\"dla_results_FK\"]\n",
    "\n",
    "\n",
    "effects = node_effects[class_id]\n",
    "\n",
    "top_k_values, top_k_indices = t.topk(effects, 2000)\n",
    "\n",
    "sae_feat_index = top_k_indices[sampled_index]\n",
    "\n",
    "selected_token_idxs_1KL = max_token_idxs_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "selected_activations_1KL = max_activations_FKL[sae_feat_index, :displayed_prompts, :].unsqueeze(0)\n",
    "top_dla_token_idxs_K = top_dla_token_idxs_FK[sae_feat_index]\n",
    "\n",
    "example_prompts = format_examples(tokenizer, selected_token_idxs_1KL, selected_activations_1KL, num_top_emphasized_tokens)\n",
    "tokens_list = utils.list_decode(top_dla_token_idxs_K, tokenizer)\n",
    "tokens_string = \",\".join(tokens_list)\n",
    "\n",
    "print(tokens_string)\n",
    "print(example_prompts[0])\n",
    "\n",
    "previous_idx = current_idx\n",
    "current_idx += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label adding\n",
    "\n",
    "per_class_scores = {\n",
    "    \"male / female\": 4,\n",
    "    \"professor / nurse\": 0,\n",
    "    \"male_professor / female_nurse\": 0,\n",
    "    \"biased_male / biased_female\": 0,\n",
    "    \"accountant\": 1,\n",
    "    \"architect\": 0,\n",
    "    \"attorney\": 0,\n",
    "    \"dentist\": 0,\n",
    "    \"filmmaker\": 0,\n",
    "}\n",
    "\n",
    "chain_of_thought = \"\"\"The top promoted logits are female pronouns and female pronouns are in every sentence, thus this is a 4 for male / female.\n",
    "Two sentences mention companies and brokers, so this is a 1 for accountant. No other classes appear to be relevant.\"\"\"\n",
    "\n",
    "new_label = {\n",
    "    \"sae\": ae_path,\n",
    "    \"class_index\": class_index,\n",
    "    \"sampled_index\": sampled_index,\n",
    "    \"sae_feat_index\": sae_feat_index.item(),\n",
    "    \"example_prompts\": example_prompts,\n",
    "    \"tokens_string\": tokens_string,\n",
    "    \"per_class_scores\": per_class_scores,\n",
    "    \"chain_of_thought\": chain_of_thought,\n",
    "}\n",
    "\n",
    "manual_labels[previous_idx] = new_label\n",
    "\n",
    "print(f\"Add the following idx to manual_labels: {previous_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manual_labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"manual_labels.json\", \"w\") as f:\n",
    "    json.dump(manual_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = build_system_prompt(\n",
    "#     cot=False,\n",
    "#     concepts=list(profession_dict.keys()),\n",
    "#     logits=True\n",
    "# )\n",
    "\n",
    "# prompts = []\n",
    "# for example_prompt, top_dla_tokens_K in zip(example_prompts, top_dla_tokens_FK):\n",
    "#     message = build_prompt(\n",
    "#         examples=example_prompt,\n",
    "#         cot=False,\n",
    "#         top_logits=top_dla_tokens_K,\n",
    "#     )\n",
    "#     prompts.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(system_prompt[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat_examples in enumerate(example_prompts):\n",
    "    print(f'############### Max act examples for Feature {top_k_indices[i]}:')\n",
    "    print(feat_examples)\n",
    "    print(f'############### Top dla tokens for Feature {top_k_indices[i]}:')\n",
    "    print(top_dla_tokens_FK[i])\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render prompt for human labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or alternatively view with circuitvis\n",
    "def _list_decode(x):\n",
    "    if len(x.shape) == 0:\n",
    "        return pythia_tokenizer.decode(x, skip_special_tokens=True)\n",
    "    else:\n",
    "        return [_list_decode(y) for y in x]\n",
    "\n",
    "selected_token_strs_FKL = _list_decode(selected_token_idxs_FKL)\n",
    "for i in range(selected_activations_FKL.shape[0]):\n",
    "    feat_idx = top_k_indices[i]\n",
    "    print(f\"Feature {feat_idx}:\")\n",
    "    selected_activations_KL11 = [selected_activations_FKL[i, k, :, None, None] for k in range(k_inputs_per_feature)]\n",
    "    html_activations = text_neuron_activations(selected_token_strs_FKL[i], selected_activations_KL11)\n",
    "    display(html_activations)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
