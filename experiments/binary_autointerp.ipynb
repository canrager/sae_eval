{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autointerp for SHIFT evals\n",
    "LLM judge decides whether a neuron/latent is related to a natural language concept. Inputs to Autointerp LLM judge:\n",
    "- Max activating examples\n",
    "- DLA top promoted tokens\n",
    "\n",
    "\n",
    "### Functionality of this notebook\n",
    "Inputs: \n",
    "- model, datset, dictionaries\n",
    "- list of concepts to check whether it is related to sth.\n",
    "\n",
    "Outputs:\n",
    "- node_effects.pkl per dictionary per concept with binary yes/no decision on whether feature is related to prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch as t\n",
    "from nnsight import LanguageModel\n",
    "import datasets\n",
    "import anthropic\n",
    "from tqdm import tqdm\n",
    "\n",
    "import experiments.utils as utils\n",
    "from experiments.autointerp import (\n",
    "    get_max_activating_prompts, \n",
    "    compute_dla, \n",
    "    highlight_top_activations,\n",
    "    evaluate_binary_llm_output\n",
    ")\n",
    "\n",
    "\n",
    "DEBUGGING = True\n",
    "\n",
    "if DEBUGGING:\n",
    "    tracer_kwargs = dict(scan=True, validate=True)\n",
    "else:\n",
    "    tracer_kwargs = dict(scan=False, validate=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Securely input the API key\n",
    "api_key = input(\"Enter your API key: \")\n",
    "os.environ['ANTHROPIC_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "model_dtype = t.bfloat16\n",
    "model = LanguageModel(\n",
    "    model_name,\n",
    "    device_map=DEVICE,\n",
    "    dispatch=True,\n",
    "    attn_implementation=\"eager\",\n",
    "    torch_dtype=model_dtype,\n",
    ")\n",
    "model_unembed = model.embed_out # For direct logit attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "num_contexts = 10000\n",
    "context_length = 128\n",
    "batch_size = 250\n",
    "\n",
    "dataset = datasets.load_dataset(\"georgeyw/dsir-pile-100k\", streaming=False)\n",
    "data = model.tokenizer(dataset[\"train\"][\"contents\"][:num_contexts], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=context_length).to(DEVICE).data\n",
    "batched_data = utils.batch_inputs(data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary from ../dictionary_learning/dictionaries/pythia70m_sweep_standard_ctx128_0712/resid_post_layer_3/trainer_6\n"
     ]
    }
   ],
   "source": [
    "# Load dictionary\n",
    "\n",
    "dictionaries_path = \"../dictionary_learning/dictionaries\"\n",
    "\n",
    "# Current recommended way to generate graphs. You can copy paste ae_sweep_paths directly from bib_intervention.py\n",
    "ae_sweep_paths = {\n",
    "    \"pythia70m_sweep_standard_ctx128_0712\": {\"resid_post_layer_3\": {\"trainer_ids\": [6]}},\n",
    "    # \"pythia70m_sweep_gated_ctx128_0730\": {\"resid_post_layer_3\": {\"trainer_ids\": [9]}},\n",
    "    # \"pythia70m_sweep_topk_ctx128_0730\": {\"resid_post_layer_3\": {\"trainer_ids\": [10]}},\n",
    "    # \"gemma-2-2b_sweep_topk_ctx128_0817\": {\"resid_post_layer_12\": {\"trainer_ids\": [2]}}, \n",
    "}\n",
    "sweep_name = list(ae_sweep_paths.keys())[0]\n",
    "submodule_trainers = ae_sweep_paths[sweep_name]\n",
    "\n",
    "ae_group_paths = utils.get_ae_group_paths(dictionaries_path, sweep_name, submodule_trainers)\n",
    "ae_paths = utils.get_ae_paths(ae_group_paths)\n",
    "\n",
    "ae_path = ae_paths[0]\n",
    "submodule, dictionary, config = utils.load_dictionary(model, ae_path, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 40/40 [00:07<00:00,  5.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get max_activating_inputs \n",
    "# and direct logit attribution (DLA) scores per feature\n",
    "\n",
    "# all_latent_indices = t.arange(dictionary.dict_size)\n",
    "# all_latent_indices = t.tensor([0])\n",
    "all_latent_indices = t.arange(0, 10)\n",
    "k_inputs_per_feature = 10\n",
    "\n",
    "max_token_idxs_FKL, max_activations_FKL = get_max_activating_prompts(\n",
    "    model, \n",
    "    submodule, \n",
    "    batched_data, \n",
    "    all_latent_indices, \n",
    "    batch_size, \n",
    "    dictionary, \n",
    "    k=k_inputs_per_feature,\n",
    "    context_length=context_length\n",
    ")\n",
    "\n",
    "# TODO write out max activating prompts to a file\n",
    "\n",
    "top_dla_token_idxs_FK = compute_dla(\n",
    "    all_latent_indices,\n",
    "    dictionary.decoder.weight,\n",
    "    model_unembed.weight,\n",
    "    k_inputs_per_feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format max_activating_inputs by << emphasizing>> max act examples\n",
    "\n",
    "num_top_emphasized_tokens = 5\n",
    "\n",
    "example_prompts = []\n",
    "for feat_idx, (max_token_idxs_KL, max_activations_KL), in enumerate(zip(max_token_idxs_FKL, max_activations_FKL)):\n",
    "    decoded_tokens_KL = model.tokenizer.batch_decode(max_token_idxs_KL, skip_special_tokens=True)\n",
    "    formatted_sequences_K = highlight_top_activations(\n",
    "            decoded_tokens_KL, \n",
    "            max_activations_KL, \n",
    "            top_n=num_top_emphasized_tokens, \n",
    "            include_activations=False\n",
    "    )\n",
    "    formatted_sequences = [seq for seq in formatted_sequences_K if seq]\n",
    "    example_prompt = []\n",
    "    for i, seq in enumerate(formatted_sequences):\n",
    "        example_prompt.append(f\"Example {i+1}: {seq}\\n\\n\")\n",
    "    example_prompt = \"\".join(example_prompt)\n",
    "    example_prompts.append(example_prompt)\n",
    "\n",
    "top_dla_tokens_FK = model.tokenizer.batch_decode(top_dla_token_idxs_FK, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.explainers.simple.prompt_builder import build_prompt\n",
    "from collections import defaultdict\n",
    "\n",
    "prompts = defaultdict(list)\n",
    "for example_prompt, top_dla_tokens_K in zip(example_prompts, top_dla_tokens_FK):\n",
    "    system_prompt, message = build_prompt(\n",
    "        examples=example_prompt,\n",
    "        cot=False,\n",
    "        top_logits=top_dla_tokens_K,\n",
    "        concept=\"gender\",\n",
    "    )\n",
    "    prompts['system'].append(system_prompt)\n",
    "    prompts['message'].append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'system': [[{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}],\n",
       "              [{'type': 'text',\n",
       "                'text': \"You are a meticulous AI researcher conducting an important investigation into a certain neuron in a language model. Your task is to analyze the neuron and decide whether its behavior is related to the concept of gender.\\n\\n(Part 2) Tokens that the neuron boosts in the next token prediction\\n\\nYou will also be shown a list called Top_logits. The logits promoted by the neuron shed light on how the neuron's activation influences the model's predictions or outputs. Look at this list of Top_logits and refine your hypotheses from part 1. It is possible that this list is more informative than the examples from part 1.\\n\\nPay close attention to the words in this list and write down what they have in common. Then look at what they have in common, as well as patterns in the tokens you found in Part 1, to produce a single explanation for what features of text cause the neuron to activate. Propose your explanation in the following format:\\n[yes/no DECISION]: <your decision>\\n\\nGuidelines:\\n\\nYou will be given a list of text examples on which the neuron activates. The specific tokens which cause the neuron to activate will appear between delimiters like <<this>>. The activation value of the token is given after each token in parentheses like <<this>>(3).\\n\\n- Try to judge whether the neurons behavior is related to gender. Simply make a choice based on the text features that activate the neuron, and what its role might be based on the tokens it predicts.\\n- If part of the text examples or predicited tokens are incorrectly formatted, please ignore them.\\n- If you are not able to find any coherent description of the neurons behavior, decide that the neuron is not related to gender.\\n- The last line of your response must be your binary decision, yes or no.\"}]],\n",
       "             'message': [[{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1: let her crown rest in his lap.With a flick of a wrist, the holograms mu <<l>>tiplied and surrounded him in pairs of two, collecting the wavelength data of both counterparts.While he pressed several instructions into the screens, the king idly explained to both near men, \"Make sure no one interrupts me while I\\'m in this state of comatose, understood?\" Both gave a shaky nod of confirmation.With a series of deep breaths, Munto cleared his thoughts and attempted to even his rapid pulse. His hands hovered over each side of her vulnerable temple. He took one last glance at a particular grid, which\\n\\n\\n\\nTop_logits: ������                �\\n                                   �'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': \"\\nExample 1: for retrograd <<e>> cerebral perfusion were pl <<a>>c <<e>> <<d>> <<.>> With systemic temperature of 18°C, deep hypothermic circulatory arrest was initiated. Retrograde cerebral perfusion via the SVC cannula was established at 10\\u2009mL/kg/min. Upon direct inspection of the aorta, the intimal tear was noted to be at the sinotubular junction (STJ), with slight extension into the noncoronary sinus. The sinuses were not significantly dilated and the aortic valve demonstrated normal leaflet coaptation. The repair was performed with replacement of the ascending aorta and hemiarch from the STJ, with resuspension of aortic\\n\\nExample 2: Oxytocin affects utilization of noradrenaline << >>i <<n>> << >> <<d>> <<i>>stinct limbic-forebrain regions of the rat brain.\\nThe effects of oxytocin, administered intracerebroventricularly in doses of 1, 10, 100 and 1000 pmol, were studied on the disappearance of catecholamines induced by alpha-methyl-p-tyrosine in microdissected nuclei of the rat brain. Oxytocin dose-dependently decreased the utilization of noradrenaline in the lateral and medial septal nuclei and anterior hypothalamic area, whereas an enhanced utilization was observed in the nucleus supraopticus. Tendency towards a change\\n\\nExample 3: were equally round, reactive to light bilaterally, and he had n <<o>> p <<h>> <<o>> <<t>>ophobia  <<o>>r blurred vision. At the time, he was in a rigid, opisthotonic posture with his neck fixed backward and laterally. His consciousness was clear, and he was able to answer all questions; vital signs were 162/90 mmHg and 98 beats/min. Intravenous midazolam 2 mg was administered once, and about 5 minutes later the symptom began to abate and about 20 minutes later the dystonic reaction had completely resolved. Arterial blood gas analysis and other laboratory findings were within normal limits. The patient remained in the PACU\\n\\nExample 4: stabilization of characteristics is limited in a polycrystalline or amorphous thin film. A film thi <<c>>kness of at lea <<s>>t 200. <<A>> <<N>>G.  <<i>>s required in order to obtain a stable film, while the area of the capacitance part 3607 must also be increased in this case and hence it is impossible to cope with refinement of the device.\\n(Problems of Prior Art 17 and Prior Art 18)\\nFor example, a flash EPROM has a high data reading speed of about several 10 to 200 nsec. in general, while a data writing or erasing operation requires an extremely long time of several.mu.sec. to several msec\\n\\nExample 5: same size. The common weights are 0.6-ounce, 2-ounce,  <<a>>nd 8-ounce.\\n\\nTo det <<e>> <<r>>mine the amount of cake  <<y>>eas <<t>> you need from an active dry yeast amount in your recipe, use the following conversions:\\n\\n  1/4-ounce of active dry yeast equals 2/3-ounce of cake yeast\\n\\n  2 1/4 teaspoons of active dry yeast equals 2/3-ounce of cake yeast\\n\\n  3 packages of active dry yeast weighing 1/4 ounce each equal 2 ounces of cake yeast\\n\\n## Active dry yeast\\n\\nActive dry yeast is processed one step further than compressed yeast.\\n\\nExample 6: KHL players. The pra <<c>> <<t>>ical s <<i>>gnificance of those variables was also confirmed: it << >>was high for BF (kg) and i <<n>>termediate for FFM (kg). As for the other parameters, no statistically significant differences were observed.\\n\\nSegmental analysis of the ELH and KHL forwards revealed that fat was evenly distributed on the right and left extremities, with slightly more fat on lower extremities. There were no statistically or practically significant differences in fat distribution among individual segments, although the ELH forwards had more fat on their trunks (2.09 %).\\n\\nThe BM, BMI, FFMI, and FFM of the ELH defense\\n\\nExample 7: by the grand-children of Ulfríkr in commemoration of his rece <<i>> <<v>> <<i>>ng two danegelds in England.\\n\\nFurther paym <<e>> <<n>>ts were made in 1002, and especially in 1007 when Aethelred bought two years peace with the Danes for 36,000 pounds (13,436 kg) of silver. In 1012, following the capture and murder of the Archbishop of Canterbury, and the sack of Canterbury, the Danes were bought off with another 48,000 pounds (17,916 kg) of silver.\\n\\nIn 1016 Sweyn Forkbeard's son, Canute,\\n\\nExample 8: again isolated from a blood culture on day 37. Despite the co <<n>> <<t>> <<i>>nue <<d>> isolation of *S. rubidaea* from blood, the neon <<a>>te improved and, once afebrile (day 40), she was transferred to the nursery where she began to gain weight. On reaching a body weight of 1.8 kg (day 75 of life) she was discharged.\\n\\nA third patient (2199) on 7 July suggested either inadequate fumigation of the NICU or human-to-human contact transmission. The neonate was born through assisted vaginal delivery at 28 weeks of gestation. An sonogram performed 1 month prior to delivery suggested\\n\\nExample 9: China Plain in the summer maize gr <<o>>wing se <<a>> <<s>>ons  <<o>>f 2012 and 2013. The study field is located in a warm,  <<s>>emihumid region with a continental climate. The average annual rainfall is 786.3\\u2009mm, and 65.1% of the local rainfall is concentrated in the summer, which can satisfy the water requirement for all growth stages of summer maize. The soil of the experimental site is loamy (40% sand, 44% silt, and 16% clay) with 32.4% field water capacity \\\\[[@B26]\\\\]. In the 2012 and 2013 summer maize growing seasons, total rainfall was 337.1 and 461.\\n\\nExample 10: gout was diagnosed with gouty arthritis bas <<e>>d on recurring ar <<t>> <<h>>ri <<t>>is i <<n>> the first MTP joint of the left foot for 9 years. He was treated with non-steroidal anti-inflammatory drugs (NSAIDs) during episodes, but he was not treated for hyperuricemia. He took 45\\u200ag of alcohol every day and had overconsumption of purine-rich foods. In May 2017, he presented with arthralgia in the first MTP joints of both feet and in the left ankle. Despite treatment with NSAIDs, arthralgia expanded to the right knee and the right ankle in July 2017. He was referred\\n\\n\\n\\nTop_logits: �����                      \\n\\n               \\n                    \\n        \"}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user', 'content': '\\n\\n\\nTop_logits: �����������'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\n\\n\\nTop_logits: ာally�ုrangleတ”)ovascularhopsurious'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1: \\n602 F.3d 605 (2010 <<)>>\\n <<T>>yrone Lor <<e>>nzo ROBINSON, Plai <<n>>tiff-Appellant, a <<n>>d\\nTonya Ledell Robinson, Plaintiff,\\nv.\\nJoseph Franklin CLIPSE, Public Safety Trooper First Class, Defendant-Appellee, and\\nSouth Carolina Department of Public Safety; South Carolina Highway Patrol, Defendants.\\nNo. 08-6670.\\nUnited States Court of Appeals, Fourth Circuit.\\nArgued: March 23, 2010.\\nDecided: April 28, 2010.\\n*606 ARGUED: Christopher Vieira, Duke University School of Law, Durham, North Carolina, for\\n\\nExample 2: 315 F.3d 637\\n <<U>> <<N>> <<I>> <<T>>ED STATES of << >>America, Plaintiff-Appellee,v.Kenneth GREGORY; Lisa Lockhart, Defendants-Appellants.\\nNo. 01-5942.\\nNo. 01-6445.\\nUnited States Court of Appeals, Sixth Circuit.\\nArgued: December 9, 2002.\\nDecided and Filed: January 13, 2003.\\n\\nStuart J. Canale (argued and briefed), Assistant United States Attorney, Memphis, TN, for U.S.\\nStephen B. Shankman (argued and briefed), M. Dianne Smothers (\\n\\nExample 3: 45 F.3d 582\\n31 Fed.R.Serv.3d 728, 33 U.S.P.Q <<.>> <<2>> <<d>> 1634\\nALEXIS LICHINE & CIE. <<,>>  <<P>>laintiff, Appellee,v.SACHA A. LICHINE ESTATE SELECTIONS, LTD, and Sacha Lichine,Defendants, Appellants.\\nNo. 94-1918.\\nUnited States Court of Appeals,First Circuit.\\nHeard Dec. 8, 1994.Decided Jan. 30, 1995.\\n\\nStanley S. Arkin with whom Harry B. Feder, New\\n\\nExample 4: \\n117 F.Supp.2d 257  <<(>>2000) <<\\n>> <<C>> <<O>>NSOLIDATED EDISON COMPANY OF NEW YORK, INC., Plaintiff,\\nv.\\nGeorge E. PATAKI, in h <<i>>s official capacity as Governor of the State of New York; Maureen O. Helmer, in her official capacity as Chairman of the New York Public Service Commission; and Thomas J. Dunleavy, James D. Bennett, Leonard Weiss and Neal N. Galvin in their official capacities as commissioners of the New York Public Service Commission, Defendants.\\nSheldon Silver, Speaker of the New York State Assembly, and Richard L\\n\\nExample 5: \\n150 F.Supp. 864 (195 <<7>> <<)>>\\nHatsue Ishii GILLES, Plai <<n>>tiff,\\nv.\\nAlbert DEL GUERCIO, as District Di <<r>>ector, Immigration and Naturalization Service, Los Angeles, California, Defendant.\\nNo. 19918.\\nUnited States District Court S. D. California, Central Division.\\nMay 9, 1957.\\n*865 Theodore E. Bowen, Los Angeles, Cal., for plaintiff.\\nLaughlin E. Waters, U. S. Atty., Max F. Deutz, Arline Martin, Asst. U. S. Attys., Los\\n\\nExample 6: \\n116 Cal.App.3d 141 (19 <<8>> <<1>> <<)>>\\n171 Cal. Rpt <<r>>. 461\\nTHE PEOPLE, Plaintiff and Respondent,\\nv.\\n <<W>>ILLIE REYNOLDS, Defendant and Appellant.\\nDocket No. 20307.\\nCourt of Appeals of California, First District, Division Three.\\nFebruary 2, 1981.\\n*142 COUNSEL\\nJohn Raymond, under appointment by the Court of Appeal, for Defendant and Appellant.\\nGeorge Deukmejian, Attorney General, Robert H. Philibosian, Chief Assistant Attorney General, Edward P. O\\'Brien, Assistant Attorney General, Charles James\\n\\nExample 7: manufacturing company in western N <<e>>w York in order to become President << >>of the Macintosh- <<H>>emphill division of Gulf & Western Manufacturing Company (\"Mac-Hemp\"). Plaintiff became the division\\'s president and invested personal funds in Mac-Hemp, forming a corporation to do so. That corporation is now in bankruptcy, due mainly to liabilities which, plaintiff contends, the defendants knew or should have known of but failed to reveal to him. Plaintiff argues that defendants did not inform him of certain unfunded pension liabilities and vested retiree medical insurance benefits at the time he was hired as division president in 1982 and when he purchased Mac-H\\n\\nExample 8: book, no ca <<s>>h book, and no ledger. Plaintiff W. C. Jackson took an inventory of the merchandise in the build <<i>>ng on October 1, 1946, and the fire occurred on October 13. To the inventory was added the amount shown by invoices representing materials received between the first and the thirteenth of October, and amounts which Jackson testified represented materials withdrawn during that period were subtracted. He testified that he had personal knowledge of the withdrawals and did not depend upon records for his knowledge. The records were not introduced. Section 501, Title 12 Oklahoma Statutes 1941, provides in substance that upon an affirmative showing of their authenticity and correctness,\\n\\nExample 9: \\n839 P.2d 356 (199 <<2>>) <<\\n>>U <<N>> <<I>>ON P <<A>>CIFIC RESOURCES COMPANY, Appellant (Plaintiff),\\nv.\\nSTATE of Wyoming; Wyoming Department of Revenue; Earl Kabeiseman, in his official capacity as Director of the Wyoming Department of Revenue; Wyoming State Board of Equalization; Wyoming Tax Commission; Nancy D. Freudenthal, Marvin Applequist, II, and C.H. Brown, III, in their official capacities as members of the Wyoming State Board of Equalization and the Wyoming Tax Commission; Wyoming Department of Audit; Roger W. Dewey, in his capacity as Director of the Wyoming\\n\\nExample 10: 2009, Lysh <<e>>ll Wilson << >>filed her complaint, which states:\\n\\n      On December 22, 2007, Plaintiff Lyshell Wilson, a business invitee, entered\\n      Citi Trends located at 4547 North State Street, Jackson, Mississippi, for the\\n      purpose of shopping for clothing. While shopping on the premises of Citi\\n\\x0c       Trends, Lyshell Wilson was brutally injured when an employee of Citi Trends,\\n       Jocelyn Howard, maliciously, reckless, negligently, and violently attacked\\n       Lyshell Wilson with a pair of scissors.\\n\\nOn May 26, 2009, Howard\\n\\n\\n\\nTop_logits: �������ster����'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': \"\\nExample 1: the region’s tropical forests – the biggest lung of our world – and the vanquishing o <<f>> peo <<p>> <<l>> <<e>> <<s>> like the Awajún and Wampis would be a tragic loss for us all.\\n\\nOctober 11, 2017\\n\\n* Birgit Weiler is Director of the Area of Research at the University Antonio Ruiz de Montoya in Lima; collaborates closely with the Vicariate of Jaén (Catholic Church) and with the Awajún and Wampis; and contributes to CLALS’s project on religion and climate change.\\n\\nA ceremony at Mount Huaytapallana during the Andean\\n\\nExample 2: medical degree from Northeastern Ohio Uni <<v>>ersities College  <<o>>f Medicine and compl <<e>> <<t>>ed his residency in general sur <<g>>ery at Northeastern Ohio University College of Medicine, Akron General Medical Center in Akron, Ohio. He completed fellowships in trauma surgery research at Case Western Reserve University School of Medicine in Cleveland, surgical critical care and trauma surgery at University of North Carolina at Chapel Hill in Chapel Hill, N.C., and burn surgery at the North Carolina Jaycee Burn Center at University of North Carolina at Chapel Hill. He also completed the Charles Fox Traveling Burn Fellowship with the American Burn Association. In 2009, Guy received a Masters of Management in Health Care\\n\\nExample 3: Detective Nate Lahey, Jack Falahee as Connor Walsh, Aja Naomi  <<K>>ing as Michaela << >> <<P>>ratt, Matt McGorry as Asher Millst <<o>>ne, Karl <<a>> Souza as Laurel Castillo, Charlie Weber as Frank Delfino, Liza Weil as Bonnie Winterbottom, Conrad Ricamora as Oliver Hampton, Rome Flynn as Gabriel Maddox, Amirah Vann as Tegan Price and Timothy Hutton as Emmett Crawford.Guest starring is B.K. Cannon as Sophie Dolan, John Hensley as Interim D.A. Ronald Miller, Glynn Turman as Nate\\n\\nExample 4: be next.\\n\\nIn a Democracy Now! special, we spend the hour with four for <<m>> <<e>>r U.S.  <<i>>n <<t>> <<e>>lligence officials — all whistleblowers\\n\\nthemselves — who have just returned from visiting National Security Agency whistleblower Edward Snowden in Russia. They are former CIA analyst Ray McGovern, former FBI agent Coleen Rowley, former National Security Agency senior executive Thomas Drake, and former U.S. Justice…\\n\\nClick Link Below For Eid Prayer Information In Atlanta Area:…\\n\\nHer story is one of triumph, faith and perseverance- reminding us of the power of God's mercy and grace.\\n\\n\\nExample 5: scoring.\\n\\nAfter snagging the puck in the neut <<r>>a <<l>> zone and skating up the left wing, Gilbert Br <<u>>le sl <<i>>pped the puck to surg <<i>>ng defenceman Tom Gilbert, who surprised Smith from the mid-slot and gave the Oilers a 3-2 lead, their first of the game.\\n\\nEdmonton came within seconds of closing the game with a win, but a late goal by Tampa's Kurtis Foster tied the game at three. Although the Oilers were gifted a late powerplay thanks to a delay of game penalty to the Lightning, the club was unable to secure a game-winner in regulation and was forced\\n\\nExample 6: Bitcoin; the talks between  <<N>>orth and South Korea; Monday night’s Col <<l>>ege Football Championship between << >>Alabama and G <<e>>orgia; and << >>the NFL Playoffs were some of the most-talked-about stories on news/talk radio yesterday, according to ongoing research from TALKERS magazine.\\n\\nWABC’s John Batchelor to Broadcast from Qatar. Night host John Batchelor is broadcasting his WABC, New York talk show from Doha, Qatar this week after accepting an invitation from the Middle East nation. Batchelor is leading a delegation of visitors including former Michigan Congressman Thaddeus McCottter and New York\\n\\nExample 7: Kansas City Chiefs 2012 Draft Preview\\n\\nGeneral manager Scott Pioli dedicated mu <<c>>h of the Chie <<f>> <<s>>' resources in free << >>a <<g>>ency towards shoring up the league's second-worst scoring offense from last season, which could mean he'll be turning his attention to a defense that's somewhat thin in a few places during the draft. The depth issues are most prevalent along the front line, with Kansas City in need of a replacement for aging nose tackle Kelly Gregg and starting end Glenn Dorsey entering the final year of his contract, and the team could additionally use a third safety with starter's skills with young standout Eric Berry coming off a\\n\\nExample 8: was responsibl <<e>> for the study conception and design, interpretat <<i>>on of the ana <<l>>yses, as  <<w>>ell  <<a>>s critical revision and final approval of the manuscript. All authors read and approved the final manuscript.\\n\\nAcknowledgements\\n================\\n\\nThe authors thank all of the patients who participated in the study, as well as Mr Robert LeGros, BA for help with data collection, Mr Victor Dinglas, MPH for assistance with data management, and Pranita Tamma MD, MHS, for her editorial assistance. The four participating centers were Johns Hopkins Hospital and Johns Hopkins Bayview Medical Center, both part of Johns Hopkins University, the University of Maryland\\n\\nExample 9: own a giant U.S. theatric <<a>>l exhibition chain <<.>>) A << >>T <<V>>  <<n>>ews montage of the world going kablooey — Europe in crisis, cyberhackers shutting down power grids, Asian conflagrations and Middle East attacks, and Obama and Biden and Hillary Clinton trying to calm a nation’s frayed nerves — lets us know that things are not going swimmingly. And then Kim Jong-un’s army arrives.\\n\\nLuckily, a bunch of defiant Washington teens jump in a pickup truck, crash through some barricades, and make for a cabin in the woods, where they plot a guerrilla\\n\\nExample 10: and NSF, United States of America. I <<n>> addition, i <<n>>dividual groups and members ha <<v>> <<e>> received support from BCKDF, the << >>Canada Council, CANARIE, CRC, Compute Canada, FQRNT, and the Ontario Innovation Trust, Canada; EPLANET, ERC, ERDF, FP7, Horizon 2020 and Marie Skłodowska-Curie Actions, European Union; Investissements d'Avenir Labex and Idex, ANR, Région Auvergne and Fondation Partager le Savoir, France; DFG and AvH Foundation, Germany; Herakleitos,\\n\\n\\n\\nTop_logits: ��++,...](� member he matters etcications assured\"}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\n\\n\\nTop_logits: ������������ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\n\\n\\nTop_logits: ���������ansas'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1: Q:\\n\\nWorkplace is rescinding on a promis <<e>>  <<m>>ade upo <<n>> hire\\n\\n <<W>>e are in California in  <<c>>ase it helps when giving advice on her situation.\\nMy wife was hired at her workplace back in February. Part of her negotiation at hire was that they would accommodate her university schedule by allowing her to leave a little early on certain days so that she could make it to class on time. Every semester she leaves one hour early two days a week.\\nThe arrangement has been fine up until this past Thursday. Her new manager gave her an ultimatum to decide by Tuesday. She told her that they can no longer accommodate her\\n\\nExample 2: Q:\\n\\nWhen did ancient reli <<g>>i <<o>>n <<s>> start to exp <<e>>rience dropping numbers of adherents in Europe?\\n\\nI  <<a>>m talking about ancient Greek, Roman and Norwegian religions.\\nWhen did ancient religions start to lose ground to modern religions such as Catholicism in Europe?\\n\\nA:\\n\\nChristianity didn\\'t really begin to crowd out the other religions in Europe until after Constantine and Julian\\'s reigns in the Roman Empire, although well before that time (the 190s CE) the Empire had began an Imperial cult in which the Emperor was revered as a god, which probably resulted in a decline of the older religions. Per Wikipedia\\n\\nExample 3: Q:\\n\\nLecturer giving automatic top mark to the firs <<t>> person to submit\\n\\nA fr <<i>>en <<d>> << >>of m <<i>>ne is studying biology at a UK university and told me about this situation that happened last semester.\\nAn assignment was set on one of her courses, and as the deadline date approached, the lecturer sent out an email stating that the first person to submit their assignment would be guaranteed an automatic first (the top mark available).\\nShe felt this was unfair (what if the first person to submit rushed their work and completed the questions poorly, yet were rewarded for their haste?) but due to the intimidating nature of this particular lect\\n\\nExample 4: Q:\\n\\nDid baro <<q>>ue composers expect you to \"bring out\" the voice <<s>> in th <<e>>ir pieces, the  <<w>>ay today\\'s critics seem to enjoy in play <<e>>rs?\\n\\nSo, I recently had a, sadly, way too short conversation with a pianist on the train.\\nAccording to the guy, in the 17th and 18th century polyphonic keyboard works were not played in such a way that the individual voices would be emphasized, but rather in a way so that they would \"blend in\".\\nWith the music in front of him/her the listener would be able to admire the mastery of the composer in building the\\n\\nExample 5: 2011 Asian Karate Championships\\n\\nThe 2011 Asian Karate Championships are the 10th edition of the Asian Karate Champ <<i>> <<o>> <<n>>s <<h>>ips, an <<d>> were held in Haixia Sports Center, Quanzhou, China from July 21 to July 24, 2011.\\n\\nMedalists\\n\\nMen\\n\\nWomen\\n\\nMedal table\\n\\nReferences\\n Results\\n\\nExternal links\\n akf-karatedo.com\\n\\nAsian Championships\\nAsian Karate Championships\\nCategory:Asian Karate Championships\\nKarate ChampionshipsMonday, April 20, 2009\\n\\nCH Blue Run\\'s She\\'s a Caution\\n\\nAmber finished her championship with\\n\\nExample 6: Q:\\n\\nA corresponding riddle\\n\\nI\\'ve been keeping up a correspondence wit <<h>> a << >>friend, a time-travelling hi <<s>>to <<r>>ian. Her lat <<e>>st project has been visiting Camelot to understand the dynamics of King Arthur\\'s knights, and she\\'s been writing to me as the project continues.  \\nThe first missive told me she was preparing to set off with one of the knights. It sounded oddly like they were going to play golf, but that\\'s probably just me.  \\nThe second note was very abbreviated - even combined with what I knew from the first, she only just had time to tell me they were on\\n\\nExample 7: If this is your first visit, be sure to check out the FAQ b <<y>> << >>clicking  <<t>>h <<e>> << >>link above.\\nYou may have to register before you can post: click the register link above to proceed.\\nTo start viewing messages, select the forum that you want to visit from the selection below.\\n\\nFor those of you who missed it at Chessville, my interview with CJA\\nAward winning historian Olimpiu Urcan is now in The Chess Journalist,\\nthe magazine of the Chess Journalists of America. You may download the\\nSeptember 2006 issue he\\n\\nYou were alive in 1890?\\n\\n\\nExample 8: Q:\\n\\nInterpretation of s <<o>>me  <<l>>ines in The Dolphins by Ca <<r>>ol Ann Duffy\\n\\nIn the poem \"Th <<e>> << >>Dolphins\" (see the summary on Beaming Notes), what does the following line mean:\\n\\n\"for the world will not deepen to dream in\". \\n\\nI am unable to understand the usage of \"dream in\"\\nAlso, \\n\\n\"out of love reflects me for myself\" \\n\\nis really unclear to me.\\nI am not sure why the poet uses the word \"this\" in the third line where the dolphin says: \\n\\nOutside this world you cannot breathe for\\n\\nExample 9: (artist)\\nCategory:1972 albums\\nCategory:Columbia Records albu <<m>> <<s>> <<\\n>>Ca <<t>>ego <<r>>y:Repertoire Records albums\\nCategory:Vertigo Records albumsSF woman accused of stealing from girl charged\\n\\nMonday, July 21, 2014\\n\\nSAN FRANCISCO -- A woman who allegedly robbed an 8-year-old girl selling candy in San Francisco\\'s Western Addition neighborhood last week has been charged with robbery and child endangerment, the San Francisco District Attorney\\'s Office spokesman said.\\n\\nLadonna Christian, 46, of San Francisco, was arrested Thursday evening after she allegedly robbed and assaulted the young girl on\\n\\nExample 10: Pages\\n\\nMonday, October 1, 2012\\n\\nHas John Farrell Lost Control of the Clubho <<u>>se?\\n\\nAny time there are rum <<o>> <<u>>rs about the Blue  <<J>> <<a>>ys, the natural instinct is to brush them off. After all, Toronto is linked to dozens of rumours throughout the season. Most of the time it\\'s regarding free agents or trades, but this rumour is a different kind of animal altogether.Omar Vizquel\\'s comments from last week indicated John Farrell is running a loose ship as the Blue Jays manager. As far as I\\'m concerned, where\\'s smoke... there\\'s fire. As George Cost\\n\\n\\n\\nTop_logits: \".\"ikipediaenron.....��hline...?\"?\",dfrac\"?'}],\n",
       "              [{'role': 'user',\n",
       "                'content': '\\nExample 1:  and he was <<over the moon>> to find\\nExample 2:  we\\'ll be laughing <<till the cows come home>>! Pro\\nExample 3:  thought Scotland was boring, but really there\\'s more <<than meets the eye>>! I\\'d\\n\\nTop_logits: [\"elated\", \"joyful\", \"story\", \"thrilled\", \"spider\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"elated\", \"joyful\", \"thrilled\".\\n- The top logits list contains words that are strongly associated with positive emotions.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  a river is wide but the ocean is wid<<er>>. The ocean\\nExample 2:  every year you get tall<<er>>,\" she\\nExample 3:  the hole was small<<er>> but deep<<er>> than the\\n\\nTop_logits: [\"apple\", \"running\", \"book\", \"wider\", \"quickly\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: None\\n- The top logits list contains unrelated nouns and adverbs.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1:  something happening inside my <<house>>\", he\\nExample 2:  presumably was always contained in <<a box>>\", according\\nExample 3:  people were coming into the <<smoking area>>\".\\n\\nHowever he\\nExample 4:  Patrick: \"why are you getting in the << way?>>\" Later,\\n\\nTop_logits: [\"room\", \"end\", \"container, \"space\", \"plane\"]\\n'},\n",
       "               {'role': 'assistant',\n",
       "                'content': '\\n(Part 2)\\nSIMILAR TOKENS: \"room\", \"container\", \"space\".\\n- The top logits list suggests a focus on nouns representing physical or metaphorical spaces.\\n\\n[yes/no DECISION]: no\\n'},\n",
       "               {'role': 'user',\n",
       "                'content': '\\nExample 1: an <<d>> se <<c>>u <<r>>e administration of the correct dose. The product is approved in the US u <<n>>der the trade-name Paser®  <<a>>nd is currently used in Europe on a named patient basis. The positive opinion issued by the CHMP on November 21, 2013, is the concluding step of the European Medicinal Agencies review of the application for EU marketing authorization. The application will now be sent to the European Commission for formal approval of marketing authorization, which is normally expected within 60 days. The product has an orphan drug designation which, following marketing authorization, will render the product at least ten years of market exclusivity within the EU\\n\\nAbout Orphan\\n\\nExample 2: restricted generally to the recomm <<e>> <<n>>d <<e>>d gu <<i>>delines, what would the impact be on govern <<m>>ent drug expenditure? The aims of this study were to: (i) investigate trends in the duration and dose of PPI prescribing in a national community drug scheme in Ireland in a one year period 2007--2008; (ii) determine potential cost savings in a one year period (2007--2008) by examining different scenarios in prescribing patterns of PPIs according to clinical and cost-effectiveness guidelines and (iii) compare potential cost savings stratified by different age groups.\\n\\nMethods\\n=======\\n\\nStudy population\\n----------------\\n\\nThe National Shared Services Primary Care Reimbursement Service\\n\\nExample 3: Oxytocin affects utilization of noradre <<n>> <<a>> <<l>>ine in distinct limbic-forebrain regions o <<f>> << >>the rat brain.\\nThe effects of oxytocin, administered intracerebroventricularly in doses of 1, 10, 100 and 1000 pmol, were studied on the disappearance of catecholamines induced by alpha-methyl-p-tyrosine in microdissected nuclei of the rat brain. Oxytocin dose-dependently decreased the utilization of noradrenaline in the lateral and medial septal nuclei and anterior hypothalamic area, whereas an enhanced utilization was observed in the nucleus supraopticus. Tendency towards a change\\n\\nExample 4: Duri <<n>> <<g>> a clin <<i>>cal hig <<h>> dose rate  <<(>>HDR) brachytherapy procedure catheters are inserted into a target region within a person, wherein through the inserted catheters radiation sources are introduced into the target region in accordance with a treatment plan, which defines dwell times and dwell locations, for treating the target region. The treatment plan is determined in advance based on, inter alia, three-dimensional poses and shapes of the inserted catheters, wherein for determining the three-dimensional poses and shapes of the catheters within the person a user introduces sequentially a guidewire into the catheters, while the position of the tip of the guidewire within the\\n\\nExample 5: the roc <<k>> <<s>> be <<l>> <<o>>w. Adding an extra dose of intrigue was a view of the local oystermen nearby arranging their  <<n>>ets.\\n\\nBreakfast includes various omelets, freshly baked croissants, berber breads and pain perdu as well as jams and yogurt served with beghrir and meloui, traditional Moroccan pancakes, and toast with amlou — a splendid alternative to peanut butter, made with almonds, honey and argan oil. Guests are presented with a simple one-page international news update for easy reading.\\nLa Sultana offers multiple excursions including special boat\\n\\nExample 6: hospital clinic for headaches. Due << >>to hyperte <<n>>sion 170/100 and blood  <<g>>lucose 207, she was << >>i <<m>>mediately referred to maternity hospital. She was infused with magnesium sulfate. The first dose of hydralazine ampoule 5 mg was injected for the mother, and then 20 min later, the blood pressure was checked to be 160/100, the second dose of hydralazine was injected, which the blood pressure was 170/100 and then the third dose was injected that her blood pressure was 180/110. Eventually, the mother, with a diagnosis of severe preeclampsia and nonresponse to medication, was carried to operation room by wheelchair without\\n\\nExample 7: Veno-occlusive disease: cytokines, gene <<t>> <<i>>cs, and haemostasis.\\nHepatic veno-occlusive disease (VOD) is a major cause of morbidity and mortality following high dose cytotoxic therapy for stem cell transplantation (SCT). Pre-existing liver damage, SCT-related therapy, and genetic polymorphisms all appear to increase the risk of developing VOD. Studies of biological markers during SCT suggest that cytokines, haemostasis, and hepatic drug metabolism via the glutathione pathway are all involved in the pathogenesis of VOD. Until recently, treatment options were limited and experimental therapies directed at the pathogenesis of the disease were mostly\\n\\nExample 8: WEEKEND EDITION: Video-game Wars Heat Up With Explosive  <<2>> <<0>>08  <<T>>itles\\n\\nSAN FRANC <<I>>SCO (Dow Jones) - Video-game players who are accustomed to waiting for the holiday season to see the hottest new releases will get an early dose of yuletide joy this year -- in late April, to be exact.\\n\\nThat\\'s when \"Grand Theft Auto IV\" will hit store shelves -- likely on its way to racking up sales of 10 million units or more by the end of the year, according to most estimates.\\n\\nBut game fanatics worried about spoiling\\n\\nExample 9: to struggle. Lots of hair pulling and light slapping. Cowgirl and doggy style. Like see some sexy clothing le <<f>> <<t>> on hte models.\\n\\n2008-Apr-27 - Anthony Rosano, Lexi Love\\n\\nDr. Rosano examines a patient for an apparent case of sex addiction. He prescribes some tight rope bondage and shows Lexi Love how it\\'s done. She gets tied up and her clothes are ripped off her hot body, weights are hung from her perky tits and she gets a hard dose of spanking. This heats up her hungry cunt and she begs to be\\n\\nExample 10: breakdowns, as well as the data-informed speculation. -Joe from the Carolinas\\n\\nIn his f <<i>> <<r>> <<s>>t public appearance for several years, Rick Strassman shares the background, performance, and interpretation of his 1990s groundbreaking research at the University of New Mexico.\\n\\nIn this series of experiments—the first new American clinical research with psychedelic drugs in a generation—dozens of human volunteers received hundreds of doses of DMT, one of the most powerful psychedelics known to science.\\n\\nThe story of his research project, published as DMT: The Spirit Molecule, raises intriguing questions about\\n\\n\\n\\nTop_logits: �����������'}]]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM inference:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM inference:  50%|█████     | 5/10 [00:16<00:16,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping LLM inference early for testing\n",
      "Total number of LLM outputs: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[TextBlock(text='I apologize, but the Top_logits list appears to be corrupted or improperly formatted in this case. Without valid information for the Top_logits, I\\'ll base my analysis solely on the example provided in Part 1.\\n\\nFrom the given example, we can observe:\\n\\n1. The text appears to be part of a fantasy or science fiction narrative.\\n2. The neuron activates on the letter \"l\" in \"multiplied\", but this seems to be in the middle of a word and doesn\\'t provide much context.\\n3. The surrounding text doesn\\'t show any clear pattern related to gender.\\n\\nGiven the limited and unclear information, and the lack of a valid Top_logits list, it\\'s difficult to draw any concrete conclusions about this neuron\\'s behavior, especially in relation to gender.\\n\\n[yes/no DECISION]: no', type='text')],\n",
       " [TextBlock(text=\"I apologize, but the Top_logits list appears to be empty or corrupted in this case. Without that additional information, I'll have to base my analysis solely on the example sentences provided.\\n\\nLooking at the examples, I don't see any clear pattern related to gender. The neuron seems to activate on a wide variety of topics, including medical procedures, scientific experiments, baking, sports, history, and medical conditions. The activations occur on various parts of words, often in the middle or end of words, and don't seem to favor any particular grammatical constructions or word types that would indicate a gender-related function.\\n\\nGiven the lack of a coherent pattern related to gender and the wide variety of contexts in which the neuron activates, I cannot conclude that this neuron's behavior is related to gender.\\n\\n[yes/no DECISION]: no\", type='text')],\n",
       " [TextBlock(text='I apologize, but it appears the Top_logits information provided is corrupted or not properly formatted. Without valid data for the Top_logits, I cannot perform a meaningful analysis of the neuron\\'s behavior in relation to token prediction.\\n\\nBased solely on the examples provided in Part 1, which show the neuron activating on phrases like \"house\", \"a box\", \"smoking area\", and \"way\", there doesn\\'t seem to be a clear connection to gender. These activations appear to be related to various types of spaces or locations, but do not show any particular gender-related pattern.\\n\\nGiven the limited and potentially unreliable information available, I cannot confidently assert that this neuron\\'s behavior is related to gender.\\n\\n[yes/no DECISION]: no', type='text')],\n",
       " [TextBlock(text=\"I apologize, but the Top_logits list provided appears to be corrupted or improperly formatted. The tokens are not recognizable English words and contain unusual characters. Without clear and valid information, I cannot make an informed analysis about the neuron's behavior or its relation to gender.\\n\\nIn cases where the data is unclear or corrupted, it's best to err on the side of caution and not make unfounded assumptions.\\n\\n[yes/no DECISION]: no\", type='text')],\n",
       " [TextBlock(text=\"I apologize, but the Top_logits list appears to be corrupted or improperly formatted. Without valid information for the top logits, I'll base my analysis solely on the examples provided.\\n\\nLooking at the examples, I notice a pattern:\\n\\n1. Most examples appear to be legal case citations or descriptions of legal proceedings.\\n2. The neuron seems to activate on specific parts of names, titles, or legal terms, often at the beginning of words.\\n3. There's no clear gender-specific pattern in the activations.\\n\\nThe neuron appears to be recognizing and activating on structural elements of legal text, particularly the formatting of case names, court names, and legal terminology. It doesn't seem to be specifically related to gender in any way.\\n\\nGiven this analysis, my decision is:\\n\\n[yes/no DECISION]: no\", type='text')]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = anthropic.Anthropic()\n",
    "\n",
    "llm_outputs = []\n",
    "for i, (system_prompt, messages) in tqdm(\n",
    "    enumerate(zip(prompts['system'], prompts['message'])), \n",
    "    desc=\"LLM inference\", total=len(prompts['system'])):\n",
    "\n",
    "    # barrier for testing\n",
    "    if i == 5: \n",
    "        print(\"stopping LLM inference early for testing\")\n",
    "        break\n",
    "\n",
    "    llm_out = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=system_prompt,\n",
    "        messages=messages,\n",
    "    )\n",
    "    llm_outputs.append(llm_out.content)\n",
    "\n",
    "print(f'Total number of LLM outputs: {len(llm_outputs)}\\n')\n",
    "llm_outputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions = evaluate_binary_llm_output(llm_outputs)\n",
    "decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-4: tensor([ 0.0000e+00, -9.3937e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00, -1.4782e-04], dtype=torch.bfloat16),\n",
       " -2: tensor([0.0000e+00, 6.3419e-05, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.2970e-04], dtype=torch.bfloat16),\n",
       " 0: tensor([ 0.0000e+00, -4.4107e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00, -5.7936e-05], dtype=torch.bfloat16),\n",
       " 1: tensor([ 0.0000, -0.0001,  0.0000,  ...,  0.0000,  0.0000,  0.0006],\n",
       "        dtype=torch.bfloat16),\n",
       " 2: tensor([ 0.0000, -0.0003,  0.0000,  ...,  0.0000,  0.0000, -0.0008],\n",
       "        dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO scale LLM prompting to multiple classes to write out node_effects.pkl\n",
    "\n",
    "# Check structure of current pkl file.\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open(os.path.join(ae_path, \"node_effects.pkl\"), \"rb\") as f:\n",
    "#     node_effects = pickle.load(f)\n",
    "\n",
    "# node_effects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
