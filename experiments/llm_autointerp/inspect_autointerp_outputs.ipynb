{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from experiments.pipeline_config import PipelineConfig\n",
    "from experiments.llm_autointerp.llm_query import perform_llm_autointerp, construct_llm_features_prompts\n",
    "from typing import Dict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "model = LanguageModel('EleutherAI/pythia-70m-deduped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run autointerp with\n",
    "```python\n",
    "cd experiments\n",
    "python llm_autointerp/run_autointerp_can.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create run.sh script for above to run llm_query with custom args from this notebook\n",
    "# For now, manually copy hyperparameters here\n",
    "repo_dir = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "ae_path = \"dictionary_learning/dictionaries/autointerp_test_data/pythia70m_sweep_topk_ctx128_0730/resid_post_layer_3/trainer_2\"\n",
    "ae_path = os.path.abspath(os.path.join(repo_dir, ae_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the raw llm output when querying llm, set DEBUG=True\n",
    "with open(os.path.join(ae_path, \"raw_llm_outputs.json\"), \"r\") as f:\n",
    "    raw_llm_outputs = json.load(f)\n",
    "\n",
    "with open(os.path.join(ae_path, \"extracted_json_llm_outputs.json\"), \"r\") as f:\n",
    "    extracted_json_llm_outputs = json.load(f)\n",
    "\n",
    "with open(os.path.join(ae_path, \"node_effects.pkl\"), \"rb\") as f:\n",
    "    node_effects_classprobe = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(ae_path, \"node_effects_auto_interp.pkl\"), \"rb\") as f:\n",
    "    node_effects_autointerp = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(ae_path, \"max_activating_inputs.pkl\"), \"rb\") as f:\n",
    "    \n",
    "    tivating_inputs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show config\n",
    "cfg = PipelineConfig()\n",
    "for k, v in cfg.__dict__.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select topn features\n",
    "\n",
    "from experiments.bib_intervention import FeatureSelection, select_features\n",
    "\n",
    "some_class_idx = next(iter(node_effects_classprobe.keys()))\n",
    "dict_size = node_effects_classprobe[some_class_idx].shape[0]\n",
    "\n",
    "num_top_features = [20]\n",
    "T_max_sideeffect = 1e-4\n",
    "\n",
    "selected_feature_indices = select_features(\n",
    "    selection_method=cfg.feature_selection_method,\n",
    "    node_effects=node_effects_classprobe,\n",
    "    dict_size=dict_size,\n",
    "    T_effects=num_top_features,\n",
    "    T_max_sideeffect=T_max_sideeffect,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices\n",
    "print({k: sum(v) for k, v in selected_feature_indices[20] if isinstance(k, int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_indices[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_effects_autointerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print cfg.num_features_per_class for each class\n",
    "from experiments.utils_bib_dataset import profession_dict\n",
    "import torch as t\n",
    "\n",
    "top_feature_idxs_per_class = {}\n",
    "\n",
    "for cls in cfg.chosen_autointerp_class_names:\n",
    "    if cls in ['gender', 'professor', 'nurse', ]:\n",
    "        continue\n",
    "    else:\n",
    "        cls_idx = profession_dict[cls]\n",
    "\n",
    "    top_feature_vals, top_feature_idxs = t.topk(node_effects_classprobe[cls_idx], cfg.num_top_features_per_class)\n",
    "    top_feature_idxs_per_class[cls] = top_feature_idxs\n",
    "    autointerp_vals = node_effects_autointerp[cls_idx][top_feature_idxs]\n",
    "    extracted_jsons = [extracted_json_llm_outputs[str(j.item())] for j in top_feature_idxs]\n",
    "    # raw_outputs = [raw_llm_outputs[str(j.item())][0][-100:] for j in top_feature_idxs]\n",
    "    print(f\"{cls}:\")\n",
    "    print(f'feature_idx, probe_effect, autointerp_effects_val, autointerp_extracted_json')\n",
    "    for i in range(cfg.num_top_features_per_class):\n",
    "        if extracted_jsons[i] is not None:\n",
    "            print(f'{top_feature_idxs[i]}, {top_feature_vals[i]}, {autointerp_vals[i]}, {extracted_jsons[i][cls]}')#, raw_outputs[i])\n",
    "        else:\n",
    "            print(f'{top_feature_idxs[i]}, {top_feature_vals[i]}, {autointerp_vals[i]}, None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prompts = construct_llm_features_prompts(ae_path, model.tokenizer, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Are the outputs that have been set to 0 really not related at all\n",
    "\n",
    "for cls in cfg.chosen_autointerp_class_names:\n",
    "    if cls in ['gender', 'professor', 'nurse', ]:\n",
    "        continue\n",
    "    for top_feature_idx in top_feature_idxs_per_class[cls]:\n",
    "        idx = top_feature_idx.item()\n",
    "        if node_effects_autointerp[profession_dict[cls]][idx] == 0:\n",
    "            print(f'feature_idx: {idx}, class: {cls}')\n",
    "            print(f\"(high effect on the classprobe of this class). Autointerp scored with 0 for this class. Here is the prompt to autointerp:\\n\")\n",
    "            print(f'this is the rating from autointerp: {extracted_json_llm_outputs[str(idx)]}')\n",
    "            print(features_prompts[idx][:150])\n",
    "\n",
    "            # print border\n",
    "            print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat idx with obvious errors for further inspection\n",
    "\n",
    "err_idxs = [\n",
    "    (6036, 'architect'),\n",
    "    (14889, 'attorney'),\n",
    "]\n",
    "\n",
    "for idx, cls in err_idxs:\n",
    "    print(f'feature_idx: {idx}, class: {cls}')\n",
    "    print(f'prompts: {features_prompts[idx]}')\n",
    "    print(f'raw_llm_output: {raw_llm_outputs[str(idx)][0]}')\n",
    "\n",
    "    print(f'\\n\\n___________________________________\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_prompts[14889])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
